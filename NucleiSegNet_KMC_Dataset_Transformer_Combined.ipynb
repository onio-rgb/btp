{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoLrOHxN6CHJ"
      },
      "outputs": [],
      "source": [
        "# !pip install spams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRDU90IGOjWs",
        "outputId": "e6fed8c3-eaeb-4e7e-9567-e42866469dab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchstain\n",
            "  Downloading torchstain-1.3.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchstain) (1.25.2)\n",
            "Installing collected packages: torchstain\n",
            "Successfully installed torchstain-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchstain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an9NIVgxZtZy",
        "outputId": "3e9ad60f-2b18-4f45-a775-a327f5a40db7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.enable_eager_execution(\n",
        "    config=None, device_policy=None, execution_mode=None\n",
        ")\n",
        "tf.executing_eagerly()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HCf40oKvfQi"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall numpy\n",
        "# !pip install numpy==1.23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CEQVlUtr6wf",
        "outputId": "0d3d8e99-fe0b-464c-dcee-1789a07d366b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ipMvPnvHY7K",
        "outputId": "79167d75-267b-4cfb-a5d4-adc68b89e0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NucleiSegNet\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/NucleiSegNet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOzJPf3BHdAi",
        "outputId": "a6dd179f-dfb4-422c-da1b-4221f953593e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stain normalizing and cropping patches of train images and masks ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91/91 [01:33<00:00,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stain normalizing and cropping patches of validation images and masks ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 19/19 [00:44<00:00,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stain normalizing and cropping patches of test images ... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 3/3 [00:06<00:00,  2.01s/it]\n",
            "100%|██████████| 3/3 [00:00<00:00, 33.73it/s]\n",
            "100%|██████████| 19/19 [00:00<00:00, 37.79it/s]\n",
            "100%|██████████| 91/91 [00:01<00:00, 46.00it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "# %matplotlib inline\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import torchstain\n",
        "# import spams\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "import math\n",
        "\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "M_CHANNEL=1\n",
        "Res_HEIGHT = 512  # actual image height\n",
        "Res_WIDTH = 512   # actual image width\n",
        "#no of patches = (input image size/ crop size)^2  per image .\n",
        "pat = 4\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "np.random.seed = seed\n",
        "# path where you want to store the stain normalized images\n",
        "#----- # Test # ------#\n",
        "Path(\"/content/TestData\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/TestData/Bin\").mkdir(parents=True, exist_ok=True) # for masks\n",
        "Path(\"/content/TestData/tis\").mkdir(parents=True, exist_ok=True) # for tissues\n",
        "\n",
        "bin_p_ts = '/content/TestData/Bin'\n",
        "tis_p_ts = '/content/TestData/tis'\n",
        "#----- # Train # ------#\n",
        "Path(\"/content/TrainData\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/TrainData/Bin\").mkdir(parents=True, exist_ok=True) # for masks\n",
        "Path(\"/content/TrainData/tis\").mkdir(parents=True, exist_ok=True) # for tissues\n",
        "\n",
        "bin_p_tr = '/content/TrainData/Bin/'\n",
        "tis_p_tr = '/content/TrainData/tis/'\n",
        "#----- # Valid # ------#\n",
        "Path(\"/content/ValidData\").mkdir(parents=True, exist_ok=True)\n",
        "Path(\"/content/ValidData/Bin\").mkdir(parents=True, exist_ok=True) # for masks\n",
        "Path(\"/content/ValidData/tis\").mkdir(parents=True, exist_ok=True) # for tissues\n",
        "\n",
        "bin_p_vl = '/content/ValidData/Bin/'\n",
        "tis_p_vl = '/content/ValidData/tis/'\n",
        "\n",
        "# Give path to your dataset\n",
        "Train_image_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Train/data/'\n",
        "Train_mask_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Train/label/'\n",
        "\n",
        "val_image_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Validation/data/'\n",
        "val_mask_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Validation/label/'\n",
        "\n",
        "Test_image_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Test/data/'\n",
        "test_mask_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Test/label/'\n",
        "\n",
        "# Give a reference image path for stain normalization\n",
        "reference_image = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Test/data/0.png'\n",
        "\n",
        "\n",
        "# getting the train and test ids\n",
        "train_ids1 = next(os.walk(Train_image_path))[2]\n",
        "train_mask_ids1 = next(os.walk(Train_mask_path))[2]\n",
        "val_ids1 = next(os.walk(val_image_path))[2]\n",
        "val_mask_ids1 = next(os.walk(val_mask_path))[2]\n",
        "test_ids1 = next(os.walk(Test_image_path))[2]\n",
        "test_mask_ids1 = next(os.walk(test_mask_path))[2]\n",
        "\n",
        "# sorting the train and test ids\n",
        "train_ids = sorted(train_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "train_mask_ids = sorted(train_mask_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "test_ids = sorted(test_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "test_mask_ids = sorted(test_mask_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "val_ids = sorted(val_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "val_mask_ids = sorted(val_mask_ids1,key=lambda x: (os.path.splitext(x)[0]))\n",
        "\n",
        "\n",
        "train_ids[:] = [tup for tup in train_ids if os.path.isfile(Train_mask_path + (os.path.splitext(tup)[0])+'.png')]\n",
        "test_ids[:] = [tup for tup in test_ids if os.path.isfile(test_mask_path + (os.path.splitext(tup)[0])+'.png')]\n",
        "val_ids[:] = [tup for tup in val_ids if os.path.isfile(val_mask_path + (os.path.splitext(tup)[0])+'.png')]\n",
        "\n",
        "def stain_norm_patch():\n",
        "\n",
        "    def read_image(path):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # opencv default color space is BGR, change it to RGB\n",
        "        p = np.percentile(img, 90)\n",
        "        img = np.clip(img * 255.0 / p, 0, 255).astype(np.uint8)\n",
        "        return img\n",
        "\n",
        "    def vaha(SOURCE_PATH,TARGET_PATH):\n",
        "        source_image = read_image(SOURCE_PATH)\n",
        "        target_image = read_image(TARGET_PATH)\n",
        "        vhd = vahadane(LAMBDA1=0.01, LAMBDA2=0.01, fast_mode=1, getH_mode=0, ITER=20)\n",
        "        # vhd.show_config()\n",
        "\n",
        "        Ws, Hs = vhd.stain_separate(source_image)\n",
        "        vhd.fast_mode=0;vhd.getH_mode=0;\n",
        "        Wt, Ht = vhd.stain_separate(target_image)\n",
        "        img = vhd.SPCN(source_image, Ws, Hs, Wt, Ht)\n",
        "        return img\n",
        "\n",
        "    # def rein(src):\n",
        "    #     # stain_normalizer 'Vahadane'\n",
        "    #     target_img = reference_image\n",
        "    #     im_nmzd = vaha(src,target_img)\n",
        "    #     return im_nmzd\n",
        "\n",
        "    def rein(src):\n",
        "      target_img = reference_image\n",
        "      target = cv2.cvtColor(cv2.imread(target_img), cv2.COLOR_BGR2RGB)\n",
        "      to_transform = cv2.cvtColor(cv2.imread(src), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      T = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Lambda(lambda x: x*255)\n",
        "      ])\n",
        "\n",
        "      torch_normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
        "      torch_normalizer.fit(T(target))\n",
        "\n",
        "      t_to_transform = T(to_transform)\n",
        "      norm, H, E = torch_normalizer.normalize(I=t_to_transform, stains=True)\n",
        "      return norm\n",
        "\n",
        "    # Get and resize train images and masks\n",
        "    def train():\n",
        "        X_train = np.zeros((len(train_ids)*pat, IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.float32)\n",
        "        Y_train = np.zeros((len(train_ids)*pat, IMG_HEIGHT, IMG_WIDTH,1), dtype=bool)\n",
        "        print('stain normalizing and cropping patches of train images and masks ... ')\n",
        "        sys.stdout.flush()\n",
        "        for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "            path = Train_mask_path + (os.path.splitext(id_)[0])+'.png'\n",
        "            img = rein(Train_image_path + id_)\n",
        "            mask_ = cv2.imread(path,0)\n",
        "            _, mask_ = cv2.threshold(mask_, 128, 255, cv2.THRESH_BINARY)\n",
        "            mask_ = np.expand_dims(mask_, -1)\n",
        "            temp_list = []\n",
        "            temp_list_mask = []\n",
        "            for i in range (int(math.pow(pat,0.5))):\n",
        "                for j in range(int(math.pow(pat,0.5))):\n",
        "                    if i<(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img1 = img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask1 = mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_img1)\n",
        "                            temp_list_mask.append(crop_mask1)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img2 = img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask2 = mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_img2)\n",
        "                            temp_list_mask.append(crop_mask2)\n",
        "                    elif i==(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img3 = img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask3 = mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_img3)\n",
        "                            temp_list_mask.append(crop_mask3)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img4 = img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask4 = mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_img4)\n",
        "                            temp_list_mask.append(crop_mask4)\n",
        "            for t in range(0,pat):\n",
        "                X_train[n*pat+t] = temp_list[t]\n",
        "                Y_train[n*pat+t] = temp_list_mask[t]\n",
        "                # mask = np.maximum(mask, mask_)\n",
        "        return X_train, Y_train\n",
        "\n",
        "\n",
        "    def val():\n",
        "        X_val = np.zeros((len(val_ids)*pat, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "        Y_val = np.zeros((len(val_ids)*pat, IMG_HEIGHT, IMG_WIDTH,1), dtype=bool)\n",
        "        print('stain normalizing and cropping patches of validation images and masks ... ')\n",
        "        sys.stdout.flush()\n",
        "        for m, id_ in tqdm(enumerate(val_ids), total=len(val_ids)):\n",
        "\n",
        "            path = val_mask_path + (os.path.splitext(id_)[0])+'.png'\n",
        "            val_img = rein(val_image_path + id_)\n",
        "            val_mask_ = cv2.imread(path,0)\n",
        "            _, val_mask_ = cv2.threshold(val_mask_, 128, 255, cv2.THRESH_BINARY)\n",
        "            val_mask_ = np.expand_dims(val_mask_, -1)\n",
        "\n",
        "            temp_list = []\n",
        "            temp_list_mask = []\n",
        "            for i in range (int(math.pow(pat,0.5))):\n",
        "                for j in range(int(math.pow(pat,0.5))):\n",
        "                    if i<(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_val_img1 = val_img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask1 = val_mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_val_img1)\n",
        "                            temp_list_mask.append(crop_mask1)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_val_img2 = val_img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask2 = val_mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_val_img2)\n",
        "                            temp_list_mask.append(crop_mask2)\n",
        "                    elif i==(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_val_img3 = val_img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask3 = val_mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_val_img3)\n",
        "                            temp_list_mask.append(crop_mask3)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_val_img4 = val_img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask4 = val_mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_val_img4)\n",
        "                            temp_list_mask.append(crop_mask4)\n",
        "\n",
        "            for t in range(0,pat):\n",
        "                X_val[m*pat+t] = temp_list[t]\n",
        "                Y_val[m*pat+t] = temp_list_mask[t]\n",
        "                # mask = np.maximum(mask, mask_)\n",
        "        return X_val, Y_val\n",
        "\n",
        "\n",
        "    def test():\n",
        "        X_test = np.zeros((len(test_ids)*pat, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.float32)\n",
        "        Y_test = np.zeros((len(test_ids)*pat, IMG_HEIGHT, IMG_WIDTH,1), dtype=bool)\n",
        "        print('stain normalizing and cropping patches of test images ... ')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        for s, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "\n",
        "            path = test_mask_path + (os.path.splitext(id_)[0])+'.png'\n",
        "            img = rein(Test_image_path + id_)\n",
        "            test_mask_ = cv2.imread(path,0)\n",
        "            _, test_mask_ = cv2.threshold(test_mask_, 128, 255, cv2.THRESH_BINARY)\n",
        "            test_mask_ = np.expand_dims(test_mask_, -1)\n",
        "\n",
        "            temp_list = []\n",
        "            temp_list_mask = []\n",
        "            for i in range (int(math.pow(pat,0.5))):\n",
        "                for j in range(int(math.pow(pat,0.5))):\n",
        "                    if i<(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img1 = img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask1 = test_mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_img1)\n",
        "                            temp_list_mask.append(crop_mask1)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img2 = img[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask2 = test_mask_[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_img2)\n",
        "                            temp_list_mask.append(crop_mask2)\n",
        "                    elif i==(int(math.pow(pat,0.5))-1):\n",
        "                        if j<(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img3 = img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            crop_mask3 = test_mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH]\n",
        "                            temp_list.append(crop_img3)\n",
        "                            temp_list_mask.append(crop_mask3)\n",
        "                        elif j==(int(math.pow(pat,0.5))-1):\n",
        "                            crop_img4 = img[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            crop_mask4 = test_mask_[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0]\n",
        "                            temp_list.append(crop_img4)\n",
        "                            temp_list_mask.append(crop_mask4)\n",
        "\n",
        "            for t in range(0,pat):\n",
        "                X_test[s*pat+t] = temp_list[t]\n",
        "                Y_test[s*pat+t] = temp_list_mask[t]\n",
        "                # mask = np.maximum(mask, mask_)\n",
        "        return X_test, Y_test\n",
        "\n",
        "    train1 = train()\n",
        "    X_train = train1[0]\n",
        "    Y_train = train1[1]\n",
        "\n",
        "    val1 = val()\n",
        "    X_val = val1[0]\n",
        "    Y_val = val1[1]\n",
        "\n",
        "    test1 = test()\n",
        "    X_test = test1[0]\n",
        "    Y_test = test1[1]\n",
        "\n",
        "    # this will save the stain normalized patches into the created paths above\n",
        "    #------------------------#TEST#---------------------------------#\n",
        "\n",
        "    for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
        "        id_1 = os.path.splitext(id_)[0]\n",
        "        for j in range(pat):\n",
        "            j1 = \"{0:0=2d}\".format(j)\n",
        "            img_t = X_test[n*pat+j]\n",
        "            imgs_b = Y_test[n*pat+j]*255\n",
        "            # img_t = X_test[n]\n",
        "            # imgs_b = np.reshape(Y_test[n]*255,(IMG_WIDTH,IMG_HEIGHT))\n",
        "            filename1 = '{}/{}_{}.png'.format(tis_p_ts,id_1,j1)\n",
        "            cv2.imwrite(filename1, cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB))\n",
        "            filename2 = '{}/{}_{}.png'.format(bin_p_ts,id_1,j1)\n",
        "            cv2.imwrite(filename2, imgs_b)\n",
        "    #------------------------#VAL#-------------------------------#\n",
        "\n",
        "    for n, id_ in tqdm(enumerate(val_ids), total=len(val_ids)):\n",
        "        id_1 = os.path.splitext(id_)[0]\n",
        "\n",
        "        for j in range(pat):\n",
        "            j1 = \"{0:0=2d}\".format(j)\n",
        "            img_t = X_val[n*pat+j]\n",
        "            imgs_b = Y_val[n*pat+j]*255\n",
        "            filename1 = '{}/{}_{}.png'.format(tis_p_vl,id_1,j1)\n",
        "            cv2.imwrite(filename1,cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB))    #cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB)\n",
        "            filename2 = '{}/{}_{}.png'.format(bin_p_vl,id_1,j1)\n",
        "            cv2.imwrite(filename2, imgs_b)\n",
        "    #------------------------#TRAIN#-------------------------------#\n",
        "\n",
        "    for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "        id_1 = os.path.splitext(id_)[0]\n",
        "\n",
        "        for j in range(pat):\n",
        "            j1 = \"{0:0=2d}\".format(j)\n",
        "            img_t = X_train[n*pat+j]\n",
        "            imgs_b = Y_train[n*pat+j]*255\n",
        "            filename1 = '{}/{}_{}.png'.format(tis_p_tr,id_1,j1)\n",
        "            cv2.imwrite(filename1, cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB))  #cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB)\n",
        "            filename2 = '{}/{}_{}.png'.format(bin_p_tr,id_1,j1)\n",
        "            cv2.imwrite(filename2, imgs_b)\n",
        "\n",
        "def patch_join(out_im):\n",
        "    num_im = len(out_im)//pat\n",
        "    num_pat = int(pat**0.5)\n",
        "    out_concat = np.zeros((Res_HEIGHT, Res_WIDTH, 1), dtype=np.uint8)\n",
        "    # Y_concat = np.zeros((Res_HEIGHT, Res_WIDTH, 1), dtype=np.bool)\n",
        "\n",
        "    out_full = np.zeros((num_im,Res_HEIGHT, Res_WIDTH, 1), dtype=np.uint8)\n",
        "    # Y_full = np.zeros((num_im,Res_HEIGHT, Res_WIDTH, 1), dtype=np.bool)\n",
        "\n",
        "\n",
        "    for k in range(num_im):\n",
        "        sec1 = []\n",
        "        y_sec1 = []\n",
        "        for l in range(pat):\n",
        "\n",
        "            sec = out_im[k*pat+l]\n",
        "            sec1.append(sec)\n",
        "\n",
        "        for i in range(int(num_pat)):\n",
        "            for j in range(int(num_pat)):\n",
        "\n",
        "                if i<num_pat-1:\n",
        "                    if j<num_pat-1:\n",
        "                        out_concat[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH] = sec1[i*num_pat+j]\n",
        "\n",
        "                    elif j==num_pat-1:\n",
        "                        out_concat[i*IMG_HEIGHT:i*IMG_HEIGHT+IMG_HEIGHT, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0] = sec1[i*num_pat+j]\n",
        "\n",
        "                elif i==num_pat-1:\n",
        "                    if j<num_pat-1:\n",
        "                        out_concat[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH:j*IMG_WIDTH+IMG_WIDTH] = sec1[i*num_pat+j]\n",
        "\n",
        "                    elif j==num_pat-1:\n",
        "                        out_concat[i*IMG_HEIGHT-0:i*IMG_HEIGHT+IMG_HEIGHT-0, j*IMG_WIDTH-0:j*IMG_WIDTH+IMG_WIDTH-0] = sec1[i*num_pat+j]\n",
        "\n",
        "        out_full[k] = out_concat\n",
        "\n",
        "    return out_full,test_ids\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    stain_norm_patch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te391mbq3EZC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.backend import *\n",
        "\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "  ##### Metrices & Loss #####\n",
        "#------------- Metrice-------------\n",
        "def f1_score1(y_true,y_pred):\n",
        "    smooth=1\n",
        "    y_true_f = flatten(y_true)\n",
        "    y_pred_f = flatten(y_pred)\n",
        "    intersection = sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
        "#----------------------------------\n",
        "# -------------Loss----------------\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth=1\n",
        "    y_true_f = flatten(y_true)\n",
        "    y_pred_f = flatten(y_pred)\n",
        "    y_true_f = cast(y_true_f, dtype='float32')\n",
        "    y_pred_f = cast(y_pred_f, dtype='float32')\n",
        "    intersection = sum(y_true_f * y_pred_f)\n",
        "    return 1-(2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    def dice_coef_loss(y_true, y_pred):\n",
        "        return dice_loss(y_true, y_pred)\n",
        "\n",
        "    def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
        "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
        "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
        "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "        return (1 - jac) * smooth\n",
        "\n",
        "    return (jaccard_distance_loss(y_true, y_pred) * dice_coef_loss(y_true, y_pred))/(jaccard_distance_loss(y_true, y_pred) + dice_coef_loss(y_true, y_pred))\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "#-----------------------------------\n",
        "#####################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOAz4jZL01MZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from  tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import *\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.backend import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import *\n",
        "from loss_metric import loss,f1_score1,bce_dice_loss\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    ## Crop and Merge Layers ##\n",
        "    def CropAndMerge(Input1, Input2):\n",
        "            \"\"\"\n",
        "            Crop input1 so that it matches input2 and then\n",
        "            return the concatenation of both channels.\n",
        "            \"\"\"\n",
        "            Size1_x = (Input1).shape[1]\n",
        "            Size2_x = (Input2).shape[1]\n",
        "\n",
        "            Size1_y = (Input1).shape[2]\n",
        "            Size2_y = (Input2).shape[2]\n",
        "\n",
        "            diff_x = tf.divide(tf.subtract(Size1_x, Size2_x), 2)\n",
        "            diff_y = tf.divide(tf.subtract(Size1_y, Size2_y), 2)\n",
        "            diff_x = tf.cast(diff_x, tf.int32)\n",
        "            Size2_x = tf.cast(Size2_x, tf.int32)\n",
        "            diff_y = tf.cast(diff_y, tf.int32)\n",
        "            Size2_y = tf.cast(Size2_y, tf.int32)\n",
        "            crop = tf.slice(Input1, [0, diff_x, diff_y, 0], [-1, Size2_x, Size2_y, -1])\n",
        "            concat = tf.concat([crop, Input2], axis=3)\n",
        "\n",
        "            return concat\n",
        "    #-------------------------------------\n",
        "    ## Attention Mechanism ##\n",
        "    def attention_gt(input_x,input_g, fil_las):\n",
        "        input_size = input_x.shape\n",
        "        fil_int = fil_las//2\n",
        "\n",
        "        input_g = Conv2D(filters=fil_las,kernel_size=(1,1), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "            kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_g)\n",
        "\n",
        "        theta_x = Conv2D(filters=fil_int,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                      kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_x)\n",
        "\n",
        "        theta_x_size  =  theta_x.shape\n",
        "\n",
        "        phi_g = Conv2D(filters=fil_int,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_g)\n",
        "\n",
        "        phi_g_u = UpSampling2D(size=(2, 2), interpolation='bilinear')(phi_g)\n",
        "        f = relu(add([theta_x,phi_g_u]))\n",
        "\n",
        "        # psi_f = Conv2D(filters=fil_las,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  # kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(f)\n",
        "\n",
        "\n",
        "        psi_f = Conv2D(filters=fil_las, kernel_size=(1,1), strides=(1, 1),activation='relu',padding='same')(f)\n",
        "        psi_f = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(psi_f)\n",
        "\n",
        "        sigm_psi_f = sigmoid(psi_f)\n",
        "\n",
        "        expand = Reshape(target_shape=input_size[-3:])(sigm_psi_f)\n",
        "\n",
        "\n",
        "        y = multiply([expand , input_x])\n",
        "\n",
        "        return y\n",
        "    ## Conv Block\n",
        "    def conv_block(input, filters):\n",
        "\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "    ## Bottleneck Block\n",
        "    def bottleneck_block(input, filters):\n",
        "\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    ## Robust Residual block\n",
        "    def robust_residual_block(input, filters_inp):\n",
        "\n",
        "        x1 = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1), padding='same',activation='relu',\n",
        "                    use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x1 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x1)\n",
        "\n",
        "        x2 = SeparableConv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1),activation='relu',padding='same',\n",
        "                            use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',\n",
        "                            kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),depth_multiplier=1)(x1)\n",
        "        x2 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x2)\n",
        "\n",
        "        x3 = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1), padding='same',activation='relu',\n",
        "                    use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x2)\n",
        "        x3 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x3)\n",
        "\n",
        "        x = concatenate([input,x3],axis=-1)\n",
        "        x = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1),activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    # def skip_connection(input, filters_inp):\n",
        "    #     x1 = skip_connection_robust_residual(input, filters_inp)\n",
        "    #     x1 = skip_connection_robust\n",
        "\n",
        "    ## Attention Block ##\n",
        "    def attention_decoder_block(input, filt,conc):\n",
        "        atten_b = attention_gt(input_x=conc,input_g=input, fil_las=filt)\n",
        "        x_ct = Conv2DTranspose(filters=filt, kernel_size=(2, 2),activation='relu', strides=(2, 2), padding='same',kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),use_bias=True)(input)\n",
        "        x = CropAndMerge(Input1=x_ct,Input2=atten_b)\n",
        "        return x\n",
        "\n",
        "    def nuclei_segnet(\n",
        "        input_shape,\n",
        "        num_classes=1,\n",
        "        output_activation='sigmoid'):\n",
        "\n",
        "        inputs = Input(input_shape)\n",
        "\n",
        "        filters = [32,64,128,256,512]\n",
        "\n",
        "\n",
        "        # for l in range(num_layers):\n",
        "        x_conv1 = robust_residual_block(inputs, filters[0])\n",
        "        x_pool1 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv1)\n",
        "        x_conv2 = robust_residual_block(x_pool1, filters[1])\n",
        "        x_pool2 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv2)\n",
        "        x_conv3 = robust_residual_block(x_pool2, filters[2])\n",
        "        x_pool3 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv3)\n",
        "        x_conv4 = robust_residual_block(x_pool3, filters[3])\n",
        "        x_pool4 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv4)\n",
        "        x_conv5 = bottleneck_block(x_pool4, filters[4])\n",
        "\n",
        "    # upsampling in the form of convtranspose\n",
        "\n",
        "        x_tconv5 = attention_decoder_block(x_conv5, filters[3],x_conv4)\n",
        "        u_conv4 = conv_block(x_tconv5, filters[3])\n",
        "        x_tconv4 = attention_decoder_block(u_conv4, filters[2],x_conv3)\n",
        "        u_conv3 = conv_block(x_tconv4, filters[2])\n",
        "        x_tconv3 = attention_decoder_block(u_conv3, filters[1],x_conv2)\n",
        "        u_conv2 = conv_block(x_tconv3, filters[1])\n",
        "        x_tconv2 = attention_decoder_block(u_conv2, filters[0],x_conv1)\n",
        "        u_conv1 = conv_block(x_tconv2, filters[0])\n",
        "\n",
        "        outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='same') (u_conv1)\n",
        "\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        return model\n",
        "\n",
        "    model = nuclei_segnet(\n",
        "                  input_shape=(256,256,3),\n",
        "                  num_classes=1,\n",
        "                  output_activation='sigmoid')\n",
        "\n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(optimizer = adam,loss=loss,metrics=[f1_score1])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkY_Cod0PUr1",
        "outputId": "86fae36e-2f94-46cf-ed54-2699c3abcee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/611.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade keras"
      ],
      "metadata": {
        "id": "O2n7yFmay6gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "image_size = input_shape[0]\n",
        "patch_size_t = 8  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size_t) ** 2\n",
        "projection_dim = 256\n",
        "num_heads = 8\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 2\n",
        "mlp_head_units = [\n",
        "    512,\n",
        "    256,\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.keras.activations.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size_t):\n",
        "        super().__init__()\n",
        "        self.patch_size_t = patch_size_t\n",
        "\n",
        "    def call(self, images):\n",
        "        input_shape = tf.shape(images)  # Direct shape access\n",
        "        batch_size = input_shape[0]\n",
        "        height = input_shape[1]\n",
        "        width = input_shape[2]\n",
        "        channels = input_shape[3]\n",
        "\n",
        "        num_patches_h = height // self.patch_size_t\n",
        "        num_patches_w = width // self.patch_size_t\n",
        "\n",
        "        patches = tf.image.extract_patches(\n",
        "            images,\n",
        "            sizes=[1, self.patch_size_t, self.patch_size_t, 1],\n",
        "            strides=[1, self.patch_size_t, self.patch_size_t, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        print(patches)\n",
        "        patch_dims = patches.shape[-1]\n",
        "        # tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        patches = tf.reshape(\n",
        "            patches,\n",
        "            (batch_size, num_patches_h * num_patches_w, self.patch_size_t * self.patch_size_t * channels)\n",
        "        )\n",
        "\n",
        "        return patches\n",
        "\n",
        "    # def call(self, images):\n",
        "    #     input_shape = ops.shape(images)\n",
        "    #     batch_size = input_shape[0]\n",
        "    #     height = input_shape[1]\n",
        "    #     width = input_shape[2]\n",
        "    #     channels = input_shape[3]\n",
        "    #     num_patches_h = height // self.patch_size_t\n",
        "    #     num_patches_w = width // self.patch_size_t\n",
        "    #     patches = tf.keras.ops.image.extract_patches(images, size=self.patch_size_t)\n",
        "    #     # print(patches)\n",
        "    #     patches = ops.reshape(\n",
        "    #         patches,\n",
        "    #         (\n",
        "    #             batch_size,\n",
        "    #             num_patches_h * num_patches_w,\n",
        "    #             self.patch_size_t * self.patch_size_t * channels,\n",
        "    #         ),\n",
        "    #     )\n",
        "    #     return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"patch_size_t\": self.patch_size_t})\n",
        "        return config\n",
        "\n",
        "\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.expand_dims(\n",
        "            tf.range(start=0, limit=self.num_patches, delta=1), axis=0\n",
        "        )\n",
        "        projected_patches = self.projection(patch)\n",
        "        encoded = projected_patches + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_patches\": self.num_patches})\n",
        "        return config\n",
        "\n",
        "\n",
        "\n",
        "def vit(inputs):\n",
        "    # inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size_t)(inputs)\n",
        "    print(patches.shape)\n",
        "    # patches = layers.Conv2D(projection_dim, kernel_size=patch_size_t, strides=patch_size_t, padding='valid',name='patching')(inputs)\n",
        "    # patches = layers.Reshape((num_patches, projection_dim))(patches)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    # representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    # representation = layers.Flatten()(representation)\n",
        "    # representation = layers.Dropout(0.5)(representation)\n",
        "    # # # Add MLP.\n",
        "    # features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # # Classify outputs.\n",
        "    # logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    # model = tf.keras.Model(inputs=inputs, outputs=encoded_patches)\n",
        "    # model.summary()\n",
        "    return encoded_patches\n"
      ],
      "metadata": {
        "id": "F37DLcu4yHSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vit()"
      ],
      "metadata": {
        "id": "BGvwwIvm_KhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk7-lBoi6mQE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from  tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.activations import *\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.backend import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import *\n",
        "from loss_metric import loss,f1_score1,bce_dice_loss\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "\n",
        "def create_model_modified():\n",
        "\n",
        "    ## Crop and Merge Layers ##\n",
        "    def CropAndMerge(Input1, Input2):\n",
        "            \"\"\"\n",
        "            Crop input1 so that it matches input2 and then\n",
        "            return the concatenation of both channels.\n",
        "            \"\"\"\n",
        "            Size1_x = (Input1).shape[1]\n",
        "            Size2_x = (Input2).shape[1]\n",
        "\n",
        "            Size1_y = (Input1).shape[2]\n",
        "            Size2_y = (Input2).shape[2]\n",
        "\n",
        "            diff_x = tf.divide(tf.subtract(Size1_x, Size2_x), 2)\n",
        "            diff_y = tf.divide(tf.subtract(Size1_y, Size2_y), 2)\n",
        "            diff_x = tf.cast(diff_x, tf.int32)\n",
        "            Size2_x = tf.cast(Size2_x, tf.int32)\n",
        "            diff_y = tf.cast(diff_y, tf.int32)\n",
        "            Size2_y = tf.cast(Size2_y, tf.int32)\n",
        "            crop = tf.slice(Input1, [0, diff_x, diff_y, 0], [-1, Size2_x, Size2_y, -1])\n",
        "            concat = tf.concat([crop, Input2], axis=3)\n",
        "\n",
        "            return concat\n",
        "    #-------------------------------------\n",
        "    ## Attention Mechanism ##\n",
        "    def attention_gt(input_x,input_g, fil_las):\n",
        "        input_size = input_x.shape\n",
        "        fil_int = fil_las//2\n",
        "\n",
        "        input_g = Conv2D(filters=fil_las,kernel_size=(1,1), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "            kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_g)\n",
        "\n",
        "        theta_x = Conv2D(filters=fil_int,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                      kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_x)\n",
        "\n",
        "        theta_x_size  =  theta_x.shape\n",
        "\n",
        "        phi_g = Conv2D(filters=fil_int,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input_g)\n",
        "\n",
        "        phi_g_u = UpSampling2D(size=(2, 2), interpolation='bilinear')(phi_g)\n",
        "        f = relu(add([theta_x,phi_g_u]))\n",
        "\n",
        "        # psi_f = Conv2D(filters=fil_las,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  # kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(f)\n",
        "\n",
        "\n",
        "        psi_f = Conv2D(filters=fil_las, kernel_size=(1,1), strides=(1, 1),activation='relu',padding='same')(f)\n",
        "        psi_f = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(psi_f)\n",
        "\n",
        "        sigm_psi_f = sigmoid(psi_f)\n",
        "\n",
        "        expand = Reshape(target_shape=input_size[-3:])(sigm_psi_f)\n",
        "\n",
        "\n",
        "        y = multiply([expand , input_x])\n",
        "\n",
        "        return y\n",
        "    ## Conv Block\n",
        "    def conv_block(input, filters):\n",
        "\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "    ## Bottleneck Block\n",
        "    def bottleneck_block(input, filters):\n",
        "\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "        x = Conv2D(filters,kernel_size=(3,3), strides=(1, 1), activation='relu', padding='same',use_bias=True,\n",
        "                  kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.0),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    ## Robust Residual block\n",
        "    def robust_residual_block(input, filters_inp):\n",
        "\n",
        "        x1 = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1), padding='same',activation='relu',\n",
        "                    use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(input)\n",
        "        x1 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x1)\n",
        "\n",
        "        x2 = SeparableConv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1),activation='relu',padding='same',\n",
        "                            use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',\n",
        "                            kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),depth_multiplier=1)(x1)\n",
        "        x2 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x2)\n",
        "\n",
        "        x3 = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1), padding='same',activation='relu',\n",
        "                    use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x2)\n",
        "        x3 = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                                gamma_initializer=Constant(1.0),momentum=0.5)(x3)\n",
        "\n",
        "        x = concatenate([input,x3],axis=-1)\n",
        "        x = Conv2D(filters=filters_inp,kernel_size=(3,3), strides=(1, 1),activation='relu', padding='same',use_bias=True, kernel_initializer='glorot_normal',bias_initializer=Constant(0.1))(x)\n",
        "        x = BatchNormalization(epsilon=1e-3,beta_initializer=Constant(0.01),\n",
        "                              gamma_initializer=Constant(1.0),momentum=0.5)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    # def skip_connection(input, filters_inp):\n",
        "    #     x1 = skip_connection_robust_residual(input, filters_inp)\n",
        "    #     x1 = skip_connection_robust\n",
        "\n",
        "    ## Attention Block ##\n",
        "    def attention_decoder_block(input, filt,conc):\n",
        "        atten_b = attention_gt(input_x=conc,input_g=input, fil_las=filt)\n",
        "        x_ct = Conv2DTranspose(filters=filt, kernel_size=(2, 2),activation='relu', strides=(2, 2), padding='same',kernel_initializer='glorot_normal',bias_initializer=Constant(0.1),use_bias=True)(input)\n",
        "        x = CropAndMerge(Input1=x_ct,Input2=atten_b)\n",
        "        return x\n",
        "\n",
        "    def fuse(w_g, w_x, channel):\n",
        "        w_add = add([w_g, w_x])\n",
        "        w_c_avg_pool = GlobalAveragePooling2D()(w_add)\n",
        "        b = mlp(w_c_avg_pool, [2*channel, channel], 0.5)\n",
        "        b = sigmoid(b)\n",
        "        b = Reshape(target_shape = (1, 1, channel))(b)\n",
        "        n_w_g = multiply([w_g, b])\n",
        "        n_w_x = multiply([w_x, b])\n",
        "        f = add([n_w_g, n_w_x])\n",
        "        return f\n",
        "\n",
        "\n",
        "    def nuclei_segnet(\n",
        "        input_shape,\n",
        "        num_classes=1,\n",
        "        output_activation='sigmoid'):\n",
        "\n",
        "        image_size = input_shape[0]\n",
        "        inputs = Input(input_shape)\n",
        "\n",
        "        filters = [32,64,128,256,512]\n",
        "\n",
        "\n",
        "        # for l in range(num_layers):\n",
        "        g_conv4 = vit(inputs)\n",
        "        g_conv4 = layers.Reshape(target_shape = (int(image_size/8), int(image_size/8), filters[3]))(g_conv4)\n",
        "        print(g_conv4.shape)\n",
        "\n",
        "        x_conv1 = robust_residual_block(inputs, filters[0])\n",
        "        x_pool1 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv1)\n",
        "        x_conv2 = robust_residual_block(x_pool1, filters[1])\n",
        "        x_pool2 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv2)\n",
        "        x_conv3 = robust_residual_block(x_pool2, filters[2])\n",
        "        x_pool3 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv3)\n",
        "        x_conv4 = robust_residual_block(x_pool3, filters[3])\n",
        "        x_pool4 = MaxPooling2D((2, 2), strides=(2, 2),padding=\"same\")(x_conv4)\n",
        "        x_conv5 = bottleneck_block(x_pool4, filters[4])\n",
        "\n",
        "        x_g_conv4 = fuse(g_conv4, x_conv4, filters[3])\n",
        "\n",
        "        g_conv3 = Conv2DTranspose(filters = filters[2], kernel_size=(3, 3), strides=(2, 2), padding='same')(g_conv4)\n",
        "        x_g_conv3 = fuse(g_conv3, x_conv3, filters[2])\n",
        "\n",
        "        g_conv2 = Conv2DTranspose(filters = filters[1], kernel_size=(3, 3), strides=(2, 2), padding='same')(g_conv3)\n",
        "        x_g_conv2 = fuse(g_conv2, x_conv2, filters[1])\n",
        "\n",
        "        g_conv1 = Conv2DTranspose(filters = filters[0], kernel_size=(3, 3), strides=(2, 2), padding='same')(g_conv2)\n",
        "        x_g_conv1 = fuse(g_conv1, x_conv1, filters[0])\n",
        "\n",
        "\n",
        "    # upsampling in the form of convtranspose\n",
        "\n",
        "        x_tconv5 = attention_decoder_block(x_conv5, filters[3],x_g_conv4)\n",
        "        u_conv4 = conv_block(x_tconv5, filters[3])\n",
        "        x_tconv4 = attention_decoder_block(u_conv4, filters[2],x_g_conv3)\n",
        "        u_conv3 = conv_block(x_tconv4, filters[2])\n",
        "        x_tconv3 = attention_decoder_block(u_conv3, filters[1],x_g_conv2)\n",
        "        u_conv2 = conv_block(x_tconv3, filters[1])\n",
        "        x_tconv2 = attention_decoder_block(u_conv2, filters[0],x_g_conv1)\n",
        "        u_conv1 = conv_block(x_tconv2, filters[0])\n",
        "\n",
        "        outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='same') (u_conv1)\n",
        "\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        return model\n",
        "\n",
        "    model = nuclei_segnet(\n",
        "                  input_shape=(256,256,3),\n",
        "                  num_classes=1,\n",
        "                  output_activation='sigmoid')\n",
        "    model.summary()\n",
        "    adam = optimizers.Adam(lr = 0.001)\n",
        "    model.compile(optimizer = adam,loss=loss,metrics=[f1_score1])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVWsFf6YGaCS"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2\n",
        "#%matplotlib inline\n",
        "from albumentations import (Blur, Compose, HorizontalFlip, HueSaturationValue,\n",
        "                            IAAEmboss, IAASharpen, JpegCompression, OneOf,\n",
        "                            RandomBrightness, RandomBrightnessContrast,\n",
        "                            RandomContrast, RandomCrop, RandomGamma,\n",
        "                            RandomRotate90, RGBShift, ShiftScaleRotate,\n",
        "                            Transpose, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion)\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations import Resize, Crop\n",
        "# from  albumentations.augmentations.transforms import GaussianBlur\n",
        "\n",
        "def aug_with_crop(image_size = 256, crop_prob = 1):\n",
        "    return Compose([\n",
        "        RandomCrop(width = image_size, height = image_size, p=crop_prob),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        VerticalFlip(p=0.5),\n",
        "        RandomRotate90(p=0.5),\n",
        "        Transpose(p=0.5),\n",
        "        # ShiftScaleRotate(shift_limit=0.01, scale_limit=0.04, rotate_limit=0, p=0.25),\n",
        "        RandomBrightnessContrast(p=0.5),\n",
        "        # RandomGamma(p=0.25),\n",
        "        # IAAEmboss(p=0.25),\n",
        "        Blur(p=0.3, blur_limit = 3),\n",
        "        # GaussianBlur(p=0.5, blur_limit = 3),\n",
        "        # OneOf([\n",
        "        #     ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        #     GridDistortion(p=0.5),\n",
        "        #     OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "        # ], p=0.5)\n",
        "    ], p = 1)\n",
        "\n",
        "\n",
        "class DataGeneratorFolder(Sequence):\n",
        "    def __init__(self, root_dir=r'/data/val_test', image_folder='tis/', mask_folder='Bin/',\n",
        "                 batch_size=1, image_size=256, nb_y_features=1,\n",
        "                 augmentation=None,\n",
        "                 suffle=True):\n",
        "        self.image_filenames = sorted(os.listdir(os.path.join(root_dir, image_folder)))\n",
        "        self.mask_names = sorted(os.listdir(os.path.join(root_dir, mask_folder)))\n",
        "        self.batch_size = batch_size\n",
        "        self.currentIndex = 0\n",
        "        self.augmentation = augmentation\n",
        "        self.image_size = image_size\n",
        "        self.nb_y_features = nb_y_features\n",
        "        self.indexes = None\n",
        "        self.suffle = suffle\n",
        "        self.path1= root_dir\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Calculates size of batch\n",
        "        \"\"\"\n",
        "        return int(np.ceil(len(self.image_filenames) / (self.batch_size)))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.suffle==True:\n",
        "            self.image_filenames, self.mask_names = shuffle(self.image_filenames, self.mask_names)\n",
        "\n",
        "\n",
        "    def read_image_mask(self, image_name, mask_name,path1):\n",
        "        i_path=path1+\"/tis/\"\n",
        "        m_path = path1+\"/Bin/\"\n",
        "\n",
        "        img1 = cv2.imread(i_path+image_name)\n",
        "        img2 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        img2 = img2/255\n",
        "        mask1 = cv2.imread(m_path+mask_name,0)\n",
        "        mask1 = mask1.astype(np.uint8)\n",
        "\n",
        "        return img2, mask1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Generate one batch of data\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate indexes of the batch\n",
        "        data_index_min = int(index*self.batch_size)\n",
        "\n",
        "        # data_index_max = int(min((index+1)*self.batch_size, len(self.image_filenames)))\n",
        "        data_index_max = int((index+1)*self.batch_size)\n",
        "        indexes = self.image_filenames[data_index_min:data_index_max]\n",
        "\n",
        "        this_batch_size = len(indexes) # The last batch can be smaller than the others\n",
        "\n",
        "        # Defining dataset\n",
        "        X = np.zeros((this_batch_size, self.image_size, self.image_size, 3), dtype=np.float32)\n",
        "        y = np.zeros((this_batch_size, self.image_size, self.image_size, self.nb_y_features), dtype=bool)\n",
        "\n",
        "        for i, sample_index in enumerate(indexes):\n",
        "            # print(sample_index)\n",
        "            # print(index)\n",
        "            X_sample, y_sample = self.read_image_mask(self.image_filenames[index * self.batch_size + i],\n",
        "                                                    self.mask_names[index * self.batch_size + i],self.path1)\n",
        "\n",
        "            # if augmentation is defined, we assume its a train set\n",
        "            if self.augmentation is not None:\n",
        "\n",
        "                # Augmentation code\n",
        "                augmented = self.augmentation(self.image_size)(image=X_sample.astype(np.float32), mask=y_sample.astype(np.uint8))\n",
        "                image_augm = augmented['image']\n",
        "                mask_augm = augmented['mask'].reshape(self.image_size, self.image_size, self.nb_y_features)\n",
        "                X[i, ...] = np.clip(image_augm, a_min = 0, a_max=1).astype(np.float32)\n",
        "                y[i, ...] = mask_augm.astype(bool)\n",
        "\n",
        "            # if augmentation isnt defined, we assume its a test set.\n",
        "            # Because test images can have different sizes we resize it to be divisable by 32\n",
        "            elif self.augmentation is None and self.batch_size ==1:\n",
        "                X_sample, y_sample = self.read_image_mask(self.image_filenames[index * 1 + i],\n",
        "                                                      self.mask_names[index * 1 + i],self.path1)\n",
        "                # augmented = Resize(height=(X_sample.shape[0]//32)*32, width=(X_sample.shape[1]//32)*32)(image = X_sample, mask = y_sample)\n",
        "                augmented = RandomCrop(width = self.image_size, height = self.image_size, p=1)(image = X_sample, mask = y_sample)\n",
        "                X_sample, y_sample = augmented['image'], augmented['mask']\n",
        "\n",
        "                return X_sample.reshape(1, X_sample.shape[0], X_sample.shape[1], 3).astype(np.float32),\\\n",
        "                       y_sample.reshape(1, X_sample.shape[0], X_sample.shape[1], self.nb_y_features).astype(bool)\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3fEQ9i6-yY",
        "outputId": "988a28db-ebee-48e1-d7f9-f7cd6acaa527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"patches_8/ExtractImagePatches:0\", shape=(None, 32, 32, 192), dtype=float32)\n",
            "(None, 1024, 192)\n",
            "(None, 32, 32, 256)\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)         (None, 256, 256, 32)         896       ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_155 (B  (None, 256, 256, 32)         128       ['conv2d_200[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " separable_conv2d_20 (Separ  (None, 256, 256, 32)         1344      ['batch_normalization_155[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_156 (B  (None, 256, 256, 32)         128       ['separable_conv2d_20[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)         (None, 256, 256, 32)         9248      ['batch_normalization_156[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_157 (B  (None, 256, 256, 32)         128       ['conv2d_201[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.concat_40 (TFOpLambda)   (None, 256, 256, 35)         0         ['input_12[0][0]',            \n",
            "                                                                     'batch_normalization_157[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)         (None, 256, 256, 32)         10112     ['tf.concat_40[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_158 (B  (None, 256, 256, 32)         128       ['conv2d_202[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooli  (None, 128, 128, 32)         0         ['batch_normalization_158[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)         (None, 128, 128, 64)         18496     ['max_pooling2d_20[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_159 (B  (None, 128, 128, 64)         256       ['conv2d_203[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " separable_conv2d_21 (Separ  (None, 128, 128, 64)         4736      ['batch_normalization_159[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_160 (B  (None, 128, 128, 64)         256       ['separable_conv2d_21[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)         (None, 128, 128, 64)         36928     ['batch_normalization_160[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_161 (B  (None, 128, 128, 64)         256       ['conv2d_204[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.concat_41 (TFOpLambda)   (None, 128, 128, 96)         0         ['max_pooling2d_20[0][0]',    \n",
            "                                                                     'batch_normalization_161[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)         (None, 128, 128, 64)         55360     ['tf.concat_41[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_162 (B  (None, 128, 128, 64)         256       ['conv2d_205[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " patches_8 (Patches)         (None, 1024, 192)            0         ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooli  (None, 64, 64, 64)           0         ['batch_normalization_162[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " patch_encoder_8 (PatchEnco  (None, 1024, 256)            311552    ['patches_8[0][0]']           \n",
            " der)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)         (None, 64, 64, 128)          73856     ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " layer_normalization_34 (La  (None, 1024, 256)            512       ['patch_encoder_8[0][0]']     \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_163 (B  (None, 64, 64, 128)          512       ['conv2d_206[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (M  (None, 1024, 256)            2103552   ['layer_normalization_34[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_22 (Separ  (None, 64, 64, 128)          17664     ['batch_normalization_163[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " add_68 (Add)                (None, 1024, 256)            0         ['multi_head_attention_16[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'patch_encoder_8[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_164 (B  (None, 64, 64, 128)          512       ['separable_conv2d_22[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization_35 (La  (None, 1024, 256)            512       ['add_68[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)         (None, 64, 64, 128)          147584    ['batch_normalization_164[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_63 (Dense)            (None, 1024, 512)            131584    ['layer_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_165 (B  (None, 64, 64, 128)          512       ['conv2d_207[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_56 (Dropout)        (None, 1024, 512)            0         ['dense_63[0][0]']            \n",
            "                                                                                                  \n",
            " tf.concat_42 (TFOpLambda)   (None, 64, 64, 192)          0         ['max_pooling2d_21[0][0]',    \n",
            "                                                                     'batch_normalization_165[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_64 (Dense)            (None, 1024, 256)            131328    ['dropout_56[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)         (None, 64, 64, 128)          221312    ['tf.concat_42[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_57 (Dropout)        (None, 1024, 256)            0         ['dense_64[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_166 (B  (None, 64, 64, 128)          512       ['conv2d_208[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add_69 (Add)                (None, 1024, 256)            0         ['dropout_57[0][0]',          \n",
            "                                                                     'add_68[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooli  (None, 32, 32, 128)          0         ['batch_normalization_166[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " layer_normalization_36 (La  (None, 1024, 256)            512       ['add_69[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)         (None, 32, 32, 256)          295168    ['max_pooling2d_22[0][0]']    \n",
            "                                                                                                  \n",
            " multi_head_attention_17 (M  (None, 1024, 256)            2103552   ['layer_normalization_36[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_167 (B  (None, 32, 32, 256)          1024      ['conv2d_209[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add_70 (Add)                (None, 1024, 256)            0         ['multi_head_attention_17[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_69[0][0]']              \n",
            "                                                                                                  \n",
            " separable_conv2d_23 (Separ  (None, 32, 32, 256)          68096     ['batch_normalization_167[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " layer_normalization_37 (La  (None, 1024, 256)            512       ['add_70[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_168 (B  (None, 32, 32, 256)          1024      ['separable_conv2d_23[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_65 (Dense)            (None, 1024, 512)            131584    ['layer_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)         (None, 32, 32, 256)          590080    ['batch_normalization_168[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_58 (Dropout)        (None, 1024, 512)            0         ['dense_65[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_169 (B  (None, 32, 32, 256)          1024      ['conv2d_210[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_66 (Dense)            (None, 1024, 256)            131328    ['dropout_58[0][0]']          \n",
            "                                                                                                  \n",
            " tf.concat_43 (TFOpLambda)   (None, 32, 32, 384)          0         ['max_pooling2d_22[0][0]',    \n",
            "                                                                     'batch_normalization_169[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_59 (Dropout)        (None, 1024, 256)            0         ['dense_66[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)         (None, 32, 32, 256)          884992    ['tf.concat_43[0][0]']        \n",
            "                                                                                                  \n",
            " add_71 (Add)                (None, 1024, 256)            0         ['dropout_59[0][0]',          \n",
            "                                                                     'add_70[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_170 (B  (None, 32, 32, 256)          1024      ['conv2d_211[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_33 (Reshape)        (None, 32, 32, 256)          0         ['add_71[0][0]']              \n",
            "                                                                                                  \n",
            " add_72 (Add)                (None, 32, 32, 256)          0         ['reshape_33[0][0]',          \n",
            "                                                                     'batch_normalization_170[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooli  (None, 16, 16, 256)          0         ['batch_normalization_170[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_8  (None, 256)                  0         ['add_72[0][0]']              \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)         (None, 16, 16, 512)          1180160   ['max_pooling2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " dense_67 (Dense)            (None, 512)                  131584    ['global_average_pooling2d_8[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " batch_normalization_171 (B  (None, 16, 16, 512)          2048      ['conv2d_212[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_60 (Dropout)        (None, 512)                  0         ['dense_67[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)         (None, 16, 16, 512)          2359808   ['batch_normalization_171[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_68 (Dense)            (None, 256)                  131328    ['dropout_60[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_172 (B  (None, 16, 16, 512)          2048      ['conv2d_213[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_61 (Dropout)        (None, 256)                  0         ['dense_68[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)         (None, 16, 16, 512)          2359808   ['batch_normalization_172[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_28 (TFOpLa  (None, 256)                  0         ['dropout_61[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_173 (B  (None, 16, 16, 512)          2048      ['conv2d_214[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_34 (Reshape)        (None, 1, 1, 256)            0         ['tf.math.sigmoid_28[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_36 (Multiply)      (None, 32, 32, 256)          0         ['reshape_33[0][0]',          \n",
            "                                                                     'reshape_34[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_37 (Multiply)      (None, 32, 32, 256)          0         ['batch_normalization_170[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_34[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)         (None, 16, 16, 256)          131328    ['batch_normalization_173[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_73 (Add)                (None, 32, 32, 256)          0         ['multiply_36[0][0]',         \n",
            "                                                                     'multiply_37[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)         (None, 16, 16, 128)          295040    ['conv2d_215[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)         (None, 32, 32, 128)          295040    ['add_73[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_20 (UpSampli  (None, 32, 32, 128)          0         ['conv2d_217[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_80 (Add)                (None, 32, 32, 128)          0         ['conv2d_216[0][0]',          \n",
            "                                                                     'up_sampling2d_20[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_20 (TFOpLambda)  (None, 32, 32, 128)          0         ['add_80[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)         (None, 32, 32, 256)          33024     ['tf.nn.relu_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_174 (B  (None, 32, 32, 256)          1024      ['conv2d_218[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_26 (Conv2  (None, 64, 64, 128)          295040    ['reshape_33[0][0]']          \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_32 (TFOpLa  (None, 32, 32, 256)          0         ['batch_normalization_174[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_74 (Add)                (None, 64, 64, 128)          0         ['conv2d_transpose_26[0][0]', \n",
            "                                                                     'batch_normalization_166[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_29 (Conv2  (None, 32, 32, 256)          524544    ['batch_normalization_173[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_38 (Reshape)        (None, 32, 32, 256)          0         ['tf.math.sigmoid_32[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_9  (None, 128)                  0         ['add_74[0][0]']              \n",
            "  (GlobalAveragePooling2D)                                                                        \n",
            "                                                                                                  \n",
            " tf.slice_20 (TFOpLambda)    (None, 32, 32, 256)          0         ['conv2d_transpose_29[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_44 (Multiply)      (None, 32, 32, 256)          0         ['reshape_38[0][0]',          \n",
            "                                                                     'add_73[0][0]']              \n",
            "                                                                                                  \n",
            " dense_69 (Dense)            (None, 256)                  33024     ['global_average_pooling2d_9[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " tf.concat_44 (TFOpLambda)   (None, 32, 32, 512)          0         ['tf.slice_20[0][0]',         \n",
            "                                                                     'multiply_44[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)        (None, 256)                  0         ['dense_69[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)         (None, 32, 32, 256)          1179904   ['tf.concat_44[0][0]']        \n",
            "                                                                                                  \n",
            " dense_70 (Dense)            (None, 128)                  32896     ['dropout_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_175 (B  (None, 32, 32, 256)          1024      ['conv2d_219[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)        (None, 128)                  0         ['dense_70[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)         (None, 32, 32, 256)          590080    ['batch_normalization_175[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_29 (TFOpLa  (None, 128)                  0         ['dropout_63[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_176 (B  (None, 32, 32, 256)          1024      ['conv2d_220[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_35 (Reshape)        (None, 1, 1, 128)            0         ['tf.math.sigmoid_29[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_38 (Multiply)      (None, 64, 64, 128)          0         ['conv2d_transpose_26[0][0]', \n",
            "                                                                     'reshape_35[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_39 (Multiply)      (None, 64, 64, 128)          0         ['batch_normalization_166[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_35[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)         (None, 32, 32, 128)          32896     ['batch_normalization_176[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_75 (Add)                (None, 64, 64, 128)          0         ['multiply_38[0][0]',         \n",
            "                                                                     'multiply_39[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)         (None, 32, 32, 64)           73792     ['conv2d_221[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)         (None, 64, 64, 64)           73792     ['add_75[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_21 (UpSampli  (None, 64, 64, 64)           0         ['conv2d_223[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_81 (Add)                (None, 64, 64, 64)           0         ['conv2d_222[0][0]',          \n",
            "                                                                     'up_sampling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_21 (TFOpLambda)  (None, 64, 64, 64)           0         ['add_81[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)         (None, 64, 64, 128)          8320      ['tf.nn.relu_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_177 (B  (None, 64, 64, 128)          512       ['conv2d_224[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_27 (Conv2  (None, 128, 128, 64)         73792     ['conv2d_transpose_26[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_33 (TFOpLa  (None, 64, 64, 128)          0         ['batch_normalization_177[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_76 (Add)                (None, 128, 128, 64)         0         ['conv2d_transpose_27[0][0]', \n",
            "                                                                     'batch_normalization_162[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_30 (Conv2  (None, 64, 64, 128)          131200    ['batch_normalization_176[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_39 (Reshape)        (None, 64, 64, 128)          0         ['tf.math.sigmoid_33[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['add_76[0][0]']              \n",
            " 0 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " tf.slice_21 (TFOpLambda)    (None, 64, 64, 128)          0         ['conv2d_transpose_30[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_45 (Multiply)      (None, 64, 64, 128)          0         ['reshape_39[0][0]',          \n",
            "                                                                     'add_75[0][0]']              \n",
            "                                                                                                  \n",
            " dense_71 (Dense)            (None, 128)                  8320      ['global_average_pooling2d_10[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.concat_45 (TFOpLambda)   (None, 64, 64, 256)          0         ['tf.slice_21[0][0]',         \n",
            "                                                                     'multiply_45[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)        (None, 128)                  0         ['dense_71[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)         (None, 64, 64, 128)          295040    ['tf.concat_45[0][0]']        \n",
            "                                                                                                  \n",
            " dense_72 (Dense)            (None, 64)                   8256      ['dropout_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_178 (B  (None, 64, 64, 128)          512       ['conv2d_225[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_65 (Dropout)        (None, 64)                   0         ['dense_72[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)         (None, 64, 64, 128)          147584    ['batch_normalization_178[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_30 (TFOpLa  (None, 64)                   0         ['dropout_65[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_179 (B  (None, 64, 64, 128)          512       ['conv2d_226[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_36 (Reshape)        (None, 1, 1, 64)             0         ['tf.math.sigmoid_30[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_40 (Multiply)      (None, 128, 128, 64)         0         ['conv2d_transpose_27[0][0]', \n",
            "                                                                     'reshape_36[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_41 (Multiply)      (None, 128, 128, 64)         0         ['batch_normalization_162[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_36[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)         (None, 64, 64, 64)           8256      ['batch_normalization_179[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_77 (Add)                (None, 128, 128, 64)         0         ['multiply_40[0][0]',         \n",
            "                                                                     'multiply_41[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)         (None, 64, 64, 32)           18464     ['conv2d_227[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)         (None, 128, 128, 32)         18464     ['add_77[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_22 (UpSampli  (None, 128, 128, 32)         0         ['conv2d_229[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_82 (Add)                (None, 128, 128, 32)         0         ['conv2d_228[0][0]',          \n",
            "                                                                     'up_sampling2d_22[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_22 (TFOpLambda)  (None, 128, 128, 32)         0         ['add_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)         (None, 128, 128, 64)         2112      ['tf.nn.relu_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_180 (B  (None, 128, 128, 64)         256       ['conv2d_230[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_28 (Conv2  (None, 256, 256, 32)         18464     ['conv2d_transpose_27[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_34 (TFOpLa  (None, 128, 128, 64)         0         ['batch_normalization_180[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_78 (Add)                (None, 256, 256, 32)         0         ['conv2d_transpose_28[0][0]', \n",
            "                                                                     'batch_normalization_158[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_31 (Conv2  (None, 128, 128, 64)         32832     ['batch_normalization_179[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_40 (Reshape)        (None, 128, 128, 64)         0         ['tf.math.sigmoid_34[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 32)                   0         ['add_78[0][0]']              \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " tf.slice_22 (TFOpLambda)    (None, 128, 128, 64)         0         ['conv2d_transpose_31[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_46 (Multiply)      (None, 128, 128, 64)         0         ['reshape_40[0][0]',          \n",
            "                                                                     'add_77[0][0]']              \n",
            "                                                                                                  \n",
            " dense_73 (Dense)            (None, 64)                   2112      ['global_average_pooling2d_11[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.concat_46 (TFOpLambda)   (None, 128, 128, 128)        0         ['tf.slice_22[0][0]',         \n",
            "                                                                     'multiply_46[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_66 (Dropout)        (None, 64)                   0         ['dense_73[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)         (None, 128, 128, 64)         73792     ['tf.concat_46[0][0]']        \n",
            "                                                                                                  \n",
            " dense_74 (Dense)            (None, 32)                   2080      ['dropout_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_181 (B  (None, 128, 128, 64)         256       ['conv2d_231[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_67 (Dropout)        (None, 32)                   0         ['dense_74[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)         (None, 128, 128, 64)         36928     ['batch_normalization_181[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_31 (TFOpLa  (None, 32)                   0         ['dropout_67[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_182 (B  (None, 128, 128, 64)         256       ['conv2d_232[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_37 (Reshape)        (None, 1, 1, 32)             0         ['tf.math.sigmoid_31[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_42 (Multiply)      (None, 256, 256, 32)         0         ['conv2d_transpose_28[0][0]', \n",
            "                                                                     'reshape_37[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_43 (Multiply)      (None, 256, 256, 32)         0         ['batch_normalization_158[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)         (None, 128, 128, 32)         2080      ['batch_normalization_182[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_79 (Add)                (None, 256, 256, 32)         0         ['multiply_42[0][0]',         \n",
            "                                                                     'multiply_43[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)         (None, 128, 128, 16)         4624      ['conv2d_233[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)         (None, 256, 256, 16)         4624      ['add_79[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_23 (UpSampli  (None, 256, 256, 16)         0         ['conv2d_235[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_83 (Add)                (None, 256, 256, 16)         0         ['conv2d_234[0][0]',          \n",
            "                                                                     'up_sampling2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_23 (TFOpLambda)  (None, 256, 256, 16)         0         ['add_83[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)         (None, 256, 256, 32)         544       ['tf.nn.relu_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_183 (B  (None, 256, 256, 32)         128       ['conv2d_236[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_35 (TFOpLa  (None, 256, 256, 32)         0         ['batch_normalization_183[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_32 (Conv2  (None, 256, 256, 32)         8224      ['batch_normalization_182[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_41 (Reshape)        (None, 256, 256, 32)         0         ['tf.math.sigmoid_35[0][0]']  \n",
            "                                                                                                  \n",
            " tf.slice_23 (TFOpLambda)    (None, 256, 256, 32)         0         ['conv2d_transpose_32[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_47 (Multiply)      (None, 256, 256, 32)         0         ['reshape_41[0][0]',          \n",
            "                                                                     'add_79[0][0]']              \n",
            "                                                                                                  \n",
            " tf.concat_47 (TFOpLambda)   (None, 256, 256, 64)         0         ['tf.slice_23[0][0]',         \n",
            "                                                                     'multiply_47[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)         (None, 256, 256, 32)         18464     ['tf.concat_47[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_184 (B  (None, 256, 256, 32)         128       ['conv2d_237[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)         (None, 256, 256, 32)         9248      ['batch_normalization_184[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_185 (B  (None, 256, 256, 32)         128       ['conv2d_238[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)         (None, 256, 256, 1)          33        ['batch_normalization_185[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18188929 (69.39 MB)\n",
            "Trainable params: 18179137 (69.35 MB)\n",
            "Non-trainable params: 9792 (38.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "Tensor(\"model_11/patches_8/ExtractImagePatches:0\", shape=(None, None, None, None), dtype=float32)\n",
            "Tensor(\"model_11/patches_8/ExtractImagePatches:0\", shape=(None, None, None, None), dtype=float32)\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.0790 - f1_score1: 0.4510Tensor(\"model_11/patches_8/ExtractImagePatches:0\", shape=(None, None, None, None), dtype=float32)\n",
            "91/91 [==============================] - 79s 433ms/step - loss: 0.0790 - f1_score1: 0.4510 - val_loss: 0.0316 - val_f1_score1: 0.6071 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "91/91 [==============================] - 41s 440ms/step - loss: 0.0227 - f1_score1: 0.6658 - val_loss: 0.0141 - val_f1_score1: 0.7316 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "91/91 [==============================] - 41s 439ms/step - loss: 0.0125 - f1_score1: 0.7306 - val_loss: 0.0080 - val_f1_score1: 0.7734 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "91/91 [==============================] - 41s 440ms/step - loss: 0.0097 - f1_score1: 0.7489 - val_loss: 0.0075 - val_f1_score1: 0.7940 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "91/91 [==============================] - 38s 415ms/step - loss: 0.0064 - f1_score1: 0.7867 - val_loss: 0.0049 - val_f1_score1: 0.8176 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "91/91 [==============================] - 37s 395ms/step - loss: 0.0053 - f1_score1: 0.7997 - val_loss: 0.0042 - val_f1_score1: 0.8285 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "91/91 [==============================] - 41s 446ms/step - loss: 0.0048 - f1_score1: 0.8081 - val_loss: 0.0038 - val_f1_score1: 0.8350 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "91/91 [==============================] - 37s 403ms/step - loss: 0.0045 - f1_score1: 0.8117 - val_loss: 0.0039 - val_f1_score1: 0.8278 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "91/91 [==============================] - 38s 413ms/step - loss: 0.0042 - f1_score1: 0.8158 - val_loss: 0.0032 - val_f1_score1: 0.8415 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "91/91 [==============================] - 36s 389ms/step - loss: 0.0039 - f1_score1: 0.8196 - val_loss: 0.0049 - val_f1_score1: 0.7897 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "91/91 [==============================] - 36s 387ms/step - loss: 0.0037 - f1_score1: 0.8255 - val_loss: 0.0035 - val_f1_score1: 0.8289 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "91/91 [==============================] - 37s 394ms/step - loss: 0.0347 - f1_score1: 0.3392 - val_loss: 0.0346 - val_f1_score1: 0.0054 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "91/91 [==============================] - 40s 435ms/step - loss: 0.0331 - f1_score1: 0.0036 - val_loss: 0.0333 - val_f1_score1: 0.0028 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.0323 - f1_score1: 0.0017\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "91/91 [==============================] - 41s 444ms/step - loss: 0.0323 - f1_score1: 0.0017 - val_loss: 0.0328 - val_f1_score1: 0.0016 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "91/91 [==============================] - 36s 392ms/step - loss: 0.0321 - f1_score1: 0.0013 - val_loss: 0.0329 - val_f1_score1: 0.0017 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "91/91 [==============================] - 52s 275ms/step - loss: 0.0594 - f1_score1: 0.5148 - val_loss: 0.0168 - val_f1_score1: 0.7131 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "91/91 [==============================] - 24s 258ms/step - loss: 0.0156 - f1_score1: 0.7054 - val_loss: 0.0100 - val_f1_score1: 0.7633 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "91/91 [==============================] - 24s 256ms/step - loss: 0.0088 - f1_score1: 0.7645 - val_loss: 0.0079 - val_f1_score1: 0.7432 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "91/91 [==============================] - 24s 256ms/step - loss: 0.0068 - f1_score1: 0.7801 - val_loss: 0.0057 - val_f1_score1: 0.8026 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "91/91 [==============================] - 25s 270ms/step - loss: 0.0056 - f1_score1: 0.7938 - val_loss: 0.0039 - val_f1_score1: 0.8309 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "91/91 [==============================] - 24s 259ms/step - loss: 0.0046 - f1_score1: 0.8104 - val_loss: 0.0047 - val_f1_score1: 0.8112 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "91/91 [==============================] - 26s 274ms/step - loss: 0.0045 - f1_score1: 0.8099 - val_loss: 0.0029 - val_f1_score1: 0.8510 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "91/91 [==============================] - 25s 267ms/step - loss: 0.0041 - f1_score1: 0.8148 - val_loss: 0.0035 - val_f1_score1: 0.8370 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "91/91 [==============================] - 26s 273ms/step - loss: 0.0039 - f1_score1: 0.8189 - val_loss: 0.0032 - val_f1_score1: 0.8435 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "91/91 [==============================] - 25s 262ms/step - loss: 0.0041 - f1_score1: 0.8134 - val_loss: 0.0034 - val_f1_score1: 0.8351 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "91/91 [==============================] - 24s 256ms/step - loss: 0.0037 - f1_score1: 0.8213 - val_loss: 0.0028 - val_f1_score1: 0.8517 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "91/91 [==============================] - 25s 263ms/step - loss: 0.0036 - f1_score1: 0.8228 - val_loss: 0.0031 - val_f1_score1: 0.8449 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "91/91 [==============================] - 25s 265ms/step - loss: 0.0037 - f1_score1: 0.8214 - val_loss: 0.0028 - val_f1_score1: 0.8483 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "91/91 [==============================] - 25s 260ms/step - loss: 0.0035 - f1_score1: 0.8232 - val_loss: 0.0041 - val_f1_score1: 0.8049 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "91/91 [==============================] - 25s 263ms/step - loss: 0.0036 - f1_score1: 0.8206 - val_loss: 0.0033 - val_f1_score1: 0.8329 - lr: 0.0010\n",
            "Training complete =========>\n",
            "Writing the model weights and the history =========>\n",
            "Save complete =========>\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "\n",
        "\n",
        "# Path to the stain normalized patch\n",
        "valid_data_path = '/content/ValidData/'\n",
        "train_data_path = '/content/TrainData/'\n",
        "\n",
        "# path for the weight and the saved history scores( loss and metrices) over the epochs\n",
        "if not os.path.exists(\"/content/checkpoint\"):\n",
        "    os.mkdir(\"/content/checkpoint\")\n",
        "\n",
        "if not os.path.exists(\"/content/history\"):\n",
        "    os.mkdir(\"/content/history\")\n",
        "\n",
        "\n",
        "model_path = '/content/checkpoint'\n",
        "weight_name1 = 'nuclei_seg_og.h5'  # name of the weight for the final model\n",
        "weight_name2 = 'nuclei_seg_modified.h5'\n",
        "history_path = '/content/history'\n",
        "hist_name1 = 'nuclei_seg_og.csv'  # name of the csv file for storing all scores\n",
        "hist_name2 = 'nuclei_seg_modified.csv'\n",
        "\n",
        "patch_size = 256\n",
        "bs = 4 # batch size for training for validation it is taken 1\n",
        "eps = 15 # epochs\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "val_generator = DataGeneratorFolder(root_dir = valid_data_path,\n",
        "                                    image_folder = 'tis/',\n",
        "                                    mask_folder = 'Bin/',\n",
        "                                    batch_size=1,augmentation = None,\n",
        "                                    image_size=patch_size,\n",
        "                                    nb_y_features = 1)\n",
        "\n",
        "train_generator = DataGeneratorFolder(root_dir = train_data_path,\n",
        "                                      image_folder = 'tis/',\n",
        "                                      mask_folder = 'Bin/',\n",
        "                                      augmentation = aug_with_crop,\n",
        "                                      batch_size=bs,\n",
        "                                      image_size=patch_size,\n",
        "                                      nb_y_features = 1)\n",
        "\n",
        "\n",
        "# reduces learning rate on plateau\n",
        "lr_reducer = ReduceLROnPlateau(factor=0.1,patience=5,\n",
        "                               cooldown= 5,\n",
        "                               min_lr=0.1e-5,verbose=1)\n",
        "# # model autosave callbacks\n",
        "# mode_autosave = ModelCheckpoint(\"kidney_mod_kumar.h5\",\n",
        "#                                 monitor='val_f1-score',\n",
        "#                                 mode='max', save_best_only=True, verbose=1, save_freq=65)\n",
        "\n",
        "# # stop learining as metric on validatopn stop increasing\n",
        "# early_stopping = EarlyStopping(patience=5, verbose=1, mode = 'auto')\n",
        "\n",
        "# # tensorboard for monitoring logs\n",
        "# tensorboard = TensorBoard(log_dir='./logs/tenboard', histogram_freq=0,\n",
        "#                           write_graph=True, write_images=False)\n",
        "\n",
        "cbks = [lr_reducer]\n",
        "\n",
        "\n",
        "model2 = create_model_modified()\n",
        "history2 = model2.fit(train_generator, shuffle =True,\n",
        "                  epochs=eps, workers=4, use_multiprocessing=True,\n",
        "                  validation_data = val_generator,\n",
        "                  verbose = 1,callbacks=cbks)\n",
        "\n",
        "model1 = create_model()\n",
        "history1 = model1.fit(train_generator, shuffle =True,\n",
        "                  epochs=eps, workers=4, use_multiprocessing=True,\n",
        "                  validation_data = val_generator,\n",
        "                  verbose = 1,callbacks=cbks)\n",
        "\n",
        "\n",
        "print('Training complete =========>')\n",
        "# saving model last weight and the history of the scores\n",
        "print('Writing the model weights and the history =========>')\n",
        "model1.save(os.path.join(model_path,weight_name1))\n",
        "model2.save(os.path.join(model_path,weight_name2))\n",
        "hist_df1 = pd.DataFrame(history1.history)\n",
        "hist_csv_file = os.path.join(history_path,hist_name1)\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df1.to_csv(f)\n",
        "\n",
        "hist_df2 = pd.DataFrame(history2.history)\n",
        "hist_csv_file = os.path.join(history_path,hist_name2)\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df2.to_csv(f)\n",
        "print('Save complete =========>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-N89RdxYg1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "4e7677e1-84b8-4ad8-8f14-2a67b20f9576"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJi0lEQVR4nOzdd3RUdf7/8dckIZ0k1IRAKNJCD1JCQMX9gYYiENaC6ErR1VWpAn4BV4qVZRUrCoK7YGNFVBBZQIEVC0QRAgoSikoTSACBBAIpJPf3x3WGDKRnkptJno9z7pmbO587874TSl75lGszDMMQAAAAAKBUPKwuAAAAAAAqA8IVAAAAALgA4QoAAAAAXIBwBQAAAAAuQLgCAAAAABcgXAEAAACACxCuAAAAAMAFCFcAAAAA4AKEKwAAAABwAcIVAFRyI0aMUOPGjUt07syZM2Wz2VxbECqdxYsXy2az6eDBg1aXAgCWIlwBgEVsNluRto0bN1pdqiVGjBihwMBAq8sosuXLl6tv376qXbu2vL29FR4erjvuuEP/+9//rC4NAFBObIZhGFYXAQBV0bvvvuv09dtvv61169bpnXfecTp+0003KTQ0tMTvk5WVpZycHPn4+BT73EuXLunSpUvy9fUt8fuX1IgRI/Thhx/q/Pnz5f7exWEYhu69914tXrxYHTt21G233aawsDAdP35cy5cv17Zt27Rp0yZ1797d6lLLTHZ2trKysuTj40NPJ4AqzcvqAgCgqvrLX/7i9PW3336rdevWXXX8ShcuXJC/v3+R36datWolqk+SvLy85OXFfxUFmTNnjhYvXqzx48frhRdecAoXf//73/XOO+9U2s8wLS1NAQEB8vT0lKenp9XlAIDlGBYIABXYjTfeqLZt22rbtm264YYb5O/vr8cee0yS9Mknn6h///4KDw+Xj4+PmjZtqqeeekrZ2dlOr3HlnKuDBw/KZrPp+eef14IFC9S0aVP5+PioS5cu+v77753OzWvOlc1m0+jRo7VixQq1bdtWPj4+atOmjdauXXtV/Rs3blTnzp3l6+urpk2b6o033nD5PK5ly5apU6dO8vPzU+3atfWXv/xFR48edWqTlJSkkSNHqkGDBvLx8VG9evU0aNAgpzlCW7duVWxsrGrXri0/Pz81adJE9957b4HvffHiRc2aNUuRkZF6/vnn87yue+65R127dnV8/euvv+r2229XzZo15e/vr27duum///2v0zkbN26UzWbTBx98oCeeeEL169dX9erVddtttyklJUUZGRkaP3686tatq8DAQI0cOVIZGRlOr2H/Pr333ntq2bKlfH191alTJ3311VdO7Q4dOqSHH35YLVu2lJ+fn2rVqqXbb7/9qvlT9nlVX375pR5++GHVrVtXDRo0cHquuJ9nWlqaJk6cqIiICPn4+Khly5Z6/vnndeWgmuL8mQMAK1XOX6UBQCXy+++/q2/fvrrzzjv1l7/8xTFEcPHixQoMDNSECRMUGBio//3vf5o+fbpSU1P13HPPFfq6S5Ys0blz5/S3v/1NNptN//znP/XnP/9Zv/76a6G9Xd98840+/vhjPfzww6pevbpeeeUV3XrrrTp8+LBq1aolSdq+fbv69OmjevXq6YknnlB2draefPJJ1alTp/Qfyh8WL16skSNHqkuXLpo1a5aSk5P18ssva9OmTdq+fbtCQkIkSbfeeqt++uknjRkzRo0bN9aJEye0bt06HT582PH1zTffrDp16mjKlCkKCQnRwYMH9fHHHxf6OZw+fVrjx48vUs9NcnKyunfvrgsXLmjs2LGqVauW3nrrLQ0cOFAffvihBg8e7NR+1qxZ8vPz05QpU/Tzzz/r1VdfVbVq1eTh4aEzZ85o5syZ+vbbb7V48WI1adJE06dPdzr/yy+/1NKlSzV27Fj5+Pjo9ddfV58+fbRlyxa1bdtWkvT9999r8+bNuvPOO9WgQQMdPHhQ8+bN04033qjdu3df1Uv68MMPq06dOpo+fbrS0tLyvM6ifJ6GYWjgwIH64osvdN999ykqKkqfffaZHn30UR09elQvvvjiVZ91YX/mAMByBgCgQhg1apRx5T/LPXv2NCQZ8+fPv6r9hQsXrjr2t7/9zfD39zfS09Mdx4YPH240atTI8fWBAwcMSUatWrWM06dPO45/8sknhiTj008/dRybMWPGVTVJMry9vY2ff/7ZceyHH34wJBmvvvqq49iAAQMMf39/4+jRo45j+/fvN7y8vK56zbwMHz7cCAgIyPf5zMxMo27dukbbtm2NixcvOo6vWrXKkGRMnz7dMAzDOHPmjCHJeO655/J9reXLlxuSjO+//77QunJ7+eWXDUnG8uXLi9R+/PjxhiTj66+/dhw7d+6c0aRJE6Nx48ZGdna2YRiG8cUXXxiSjLZt2xqZmZmOtkOHDjVsNpvRt29fp9eNiYlx+h4bhvl9kmRs3brVcezQoUOGr6+vMXjwYMexvP4cxcfHG5KMt99+23Fs0aJFhiTjuuuuMy5duuTU3v7cgQMHDMMo2ue5YsUKQ5Lx9NNPOx2/7bbbDJvN5vTnq6h/5gDAagwLBIAKzsfHRyNHjrzquJ+fn2P/3LlzOnXqlK6//npduHBBe/bsKfR1hwwZoho1aji+vv766yWZw9YK07t3bzVt2tTxdfv27RUUFOQ4Nzs7W+vXr1dcXJzCw8Md7Zo1a6a+ffsW+vpFsXXrVp04cUIPP/yw04Ib/fv3V2RkpGOonZ+fn7y9vbVx40adOXMmz9ey93CtWrVKWVlZRa4hNTVVklS9evUitV+9erW6du2q6667znEsMDBQDzzwgA4ePKjdu3c7tR82bJhTL2J0dLRjAY3coqOjdeTIEV26dMnpeExMjDp16uT4umHDhho0aJA+++wzx/DR3H+OsrKy9Pvvv6tZs2YKCQlRQkLCVddw//33F9pLV5TPc/Xq1fL09NTYsWOdjk+cOFGGYWjNmjVOxwv7MwcAFQHhCgAquPr168vb2/uq4z/99JMGDx6s4OBgBQUFqU6dOo7FMFJSUgp93YYNGzp9bQ9a+QWQgs61n28/98SJE7p48aKaNWt2Vbu8jpXEoUOHJEktW7a86rnIyEjH8z4+Ppo9e7bWrFmj0NBQ3XDDDfrnP/+ppKQkR/uePXvq1ltv1RNPPKHatWtr0KBBWrRo0VXzmK4UFBQkyQy3Ra05r3pbtWrldE12V37OwcHBkqSIiIirjufk5Fz1fW/evPlV79WiRQtduHBBJ0+elGTOG5s+fbpj3lPt2rVVp04dnT17Ns8/R02aNCnsMov0eR46dEjh4eFXBdOifhaS8585AKgICFcAUMHl7lmwO3v2rHr27KkffvhBTz75pD799FOtW7dOs2fPliTl5OQU+rr59T4YRbhDR2nOtcL48eO1b98+zZo1S76+vpo2bZpatWql7du3SzIXTPjwww8VHx+v0aNH6+jRo7r33nvVqVOnApeCj4yMlCTt3LmzTOrO73N25ec/ZswYPfPMM7rjjjv0wQcf6PPPP9e6detUq1atPP8c5fXn8Uol/TwL4m5/5gBUTYQrAHBDGzdu1O+//67Fixdr3LhxuuWWW9S7d2+nYX5Wqlu3rnx9ffXzzz9f9Vxex0qiUaNGkqS9e/de9dzevXsdz9s1bdpUEydO1Oeff65du3YpMzNTc+bMcWrTrVs3PfPMM9q6davee+89/fTTT3r//ffzreG6665TjRo19J///OeqVRrzqzmveu3DOK+subT2799/1bF9+/bJ39/fsbDIhx9+qOHDh2vOnDm67bbbdNNNN+m6667T2bNnS/3+BX2ejRo10rFjx67q9SurzwIAygPhCgDckP23+Ll/a5+ZmanXX3/dqpKceHp6qnfv3lqxYoWOHTvmOP7zzz9fNZempDp37qy6detq/vz5TsPN1qxZo8TERPXv31+SeV+w9PR0p3ObNm2q6tWrO847c+bMVT0gUVFRklTg0EB/f39NnjxZiYmJmjx5cp69KO+++662bNkiSerXr5+2bNmi+Ph4x/NpaWlasGCBGjdurNatWxfjEyhcfHy807ypI0eO6JNPPtHNN9/s+DPk6el5Vd2vvvpqkcJiforyefbr10/Z2dmaO3euU7sXX3xRNpvNZXPzAKA8sRQ7ALih7t27q0aNGho+fLjGjh0rm82md955p0INkZo5c6Y+//xz9ejRQw899JDjB+m2bdtqx44dRXqNrKwsPf3001cdr1mzph5++GHNnj1bI0eOVM+ePTV06FDHUuyNGzfWI488IsnsqenVq5fuuOMOtW7dWl5eXlq+fLmSk5N15513SpLeeustvf766xo8eLCaNm2qc+fOaeHChQoKClK/fv0KrPHRRx/VTz/9pDlz5uiLL77QbbfdprCwMCUlJWnFihXasmWLNm/eLEmaMmWK/vOf/6hv374aO3asatasqbfeeksHDhzQRx99JA8P1/7Os23btoqNjXVail2SnnjiCUebW265Re+8846Cg4PVunVrxcfHa/369aVa3rwon+eAAQP0pz/9SX//+9918OBBdejQQZ9//rk++eQTjR8/3mnxCgBwF4QrAHBDtWrV0qpVqzRx4kQ9/vjjqlGjhv7yl7+oV69eio2Ntbo8SVKnTp20Zs0aTZo0SdOmTVNERISefPJJJSYmFmk1Q8nsjZs2bdpVx5s2baqHH35YI0aMkL+/v/7xj39o8uTJCggI0ODBgzV79mzHinUREREaOnSoNmzYoHfeeUdeXl6KjIzUBx98oFtvvVWSuQDDli1b9P777ys5OVnBwcHq2rWr3nvvvUIXcPDw8NDbb7+tQYMGacGCBXr++eeVmpqqOnXqOBbPiImJkSSFhoZq8+bNmjx5sl599VWlp6erffv2+vTTTx09ba7Us2dPxcTE6IknntDhw4fVunVrLV68WO3bt3e0efnll+Xp6an33ntP6enp6tGjh9avX1+qP0dF+Tw9PDy0cuVKTZ8+XUuXLtWiRYvUuHFjPffcc5o4cWKprx0ArGAzKtKvOQEAlV5cXJx++umnPOcDwXVsNptGjRp11bA7AEDZYc4VAKDMXLx40enr/fv3a/Xq1brxxhutKQgAgDLEsEAAQJm55pprNGLECF1zzTU6dOiQ5s2bJ29vb/3f//2f1aUBAOByhCsAQJnp06eP/vOf/ygpKUk+Pj6KiYnRs88+m+fNbQEAcHfMuQIAAAAAF2DOFQAAAAC4AOEKAAAAAFyAOVd5yMnJ0bFjx1S9enXZbDarywEAAABgEcMwdO7cOYWHhxd6s3fCVR6OHTumiIgIq8sAAAAAUEEcOXJEDRo0KLAN4SoP1atXl2R+gEFBQRZXAwAAAMAqqampioiIcGSEghCu8mAfChgUFES4AgAAAFCk6UIsaAEAAAAALkC4AgAAAAAXIFwBAAAAgAsw5woAAMBNGIahS5cuKTs72+pSgErD09NTXl5eLrkFE+EKAADADWRmZur48eO6cOGC1aUAlY6/v7/q1asnb2/vUr0O4QoAAKCCy8nJ0YEDB+Tp6anw8HB5e3u75LfsQFVnGIYyMzN18uRJHThwQM2bNy/0RsEFIVwBAABUcJmZmcrJyVFERIT8/f2tLgeoVPz8/FStWjUdOnRImZmZ8vX1LfFrsaAFAACAmyjNb9QB5M9Vf7f4GwoAAAAALmB5uHrttdfUuHFj+fr6Kjo6Wlu2bCmw/bJlyxQZGSlfX1+1a9dOq1evdnr+/PnzGj16tBo0aCA/Pz+1bt1a8+fPL8tLAAAAAABrw9XSpUs1YcIEzZgxQwkJCerQoYNiY2N14sSJPNtv3rxZQ4cO1X333aft27crLi5OcXFx2rVrl6PNhAkTtHbtWr377rtKTEzU+PHjNXr0aK1cubK8LgsAAABlpHHjxnrppZeK3H7jxo2y2Ww6e/ZsmdVUVc2cOVNRUVGleg2bzaYVK1a4pJ6KwGYYhmHVm0dHR6tLly6aO3euJDkmao4ZM0ZTpky5qv2QIUOUlpamVatWOY5169ZNUVFRjt6ptm3basiQIZo2bZqjTadOndS3b189/fTTedaRkZGhjIwMx9epqamKiIhQSkqKgoKCXHKtAAAAJZWenq4DBw6oSZMmpZpsX54KW81wxowZmjlzZrFf9+TJkwoICCjywh6ZmZk6ffq0QkNDy3SFxY0bN+pPf/qTzpw5o5CQkDJ7H1dZvHixRo4cedVxHx8fpaenF+k1zp8/r4yMDNWqVavQtjNnztSKFSu0Y8cOp+NJSUmqUaOGfHx8ivSeZaWgv2OpqakKDg4uUjawrOcqMzNT27ZtU+/evS8X4+Gh3r17Kz4+Ps9z4uPjndpLUmxsrFP77t27a+XKlTp69KgMw9AXX3yhffv26eabb863llmzZik4ONixRURElPLqAAAAqrbjx487tpdeeklBQUFOxyZNmuRoa785clHUqVOnWCsment7KywsjKXr83Dl9+T48eM6dOhQkc8PDAwsUrAqSFhYmOXBypUsC1enTp1Sdna2QkNDnY6HhoYqKSkpz3OSkpIKbf/qq6+qdevWatCggby9vdWnTx+99tpruuGGG/KtZerUqUpJSXFsR44cKcWVAQAAlC3DkNLSrNmKOuYpLCzMsQUHB8tmszm+3rNnj6pXr641a9aoU6dO8vHx0TfffKNffvlFgwYNUmhoqAIDA9WlSxetX7/e6XWvHBZos9n05ptvavDgwfL391fz5s2dpoNcOSxw8eLFCgkJ0WeffaZWrVopMDBQffr00fHjxx3nXLp0SWPHjlVISIhq1aqlyZMna/jw4YqLiyvpt0xnzpzRsGHDVKNGDfn7+6tv377av3+/4/lDhw5pwIABqlGjhgICAtSmTRvH2gJnzpzR3XffrTp16sjPz0/NmzfXokWLSlyLXe7viX2z/6x98uRJhYWF6dlnn3W037x5s7y9vbVhwwZJVw8L3Lhxo7p27aqAgACFhISoR48eOnTokBYvXqwnnnhCP/zwg2w2m2w2mxYvXuyowT4s8ODBg7LZbPr444/1pz/9Sf7+/urQocNVHS8LFy503JZg8ODBeuGFFypMb6HlC1q42quvvqpvv/1WK1eu1LZt2zRnzhyNGjXqqr+Yufn4+CgoKMhpAwAAqKguXJACA63ZLlxw3XVMmTJF//jHP5SYmKj27dvr/Pnz6tevnzZs2KDt27erT58+GjBggA4fPlzg6zzxxBO644479OOPP6pfv366++67dfr06QI+vwt6/vnn9c477+irr77S4cOHnXrSZs+erffee0+LFi3Spk2blJqaWup5QSNGjNDWrVu1cuVKxcfHyzAM9evXT1lZWZKkUaNGKSMjQ1999ZV27typ2bNnKzAwUJI0bdo07d69W2vWrFFiYqLmzZun2rVrl6qewtSpU0f//ve/NXPmTG3dulXnzp3TPffco9GjR6tXr15Xtb906ZLi4uLUs2dP/fjjj4qPj9cDDzwgm82mIUOGaOLEiWrTpo2jh2zIkCH5vvff//53TZo0STt27FCLFi00dOhQR8/mpk2b9OCDD2rcuHHasWOHbrrpJj3zzDNl9jkUl2U3Ea5du7Y8PT2VnJzsdDw5OVlhYWF5nhMWFlZg+4sXL+qxxx7T8uXL1b9/f0lS+/bttWPHDj3//PNXDSkEAACAdZ588knddNNNjq9r1qypDh06OL5+6qmntHz5cq1cuVKjR4/O93VGjBihoUOHSpKeffZZvfLKK9qyZYv69OmTZ/usrCzNnz9fTZs2lSSNHj1aTz75pOP5V199VVOnTtXgwYMlSXPnzr1qheri2L9/v1auXKlNmzape/fukqT33ntPERERWrFihW6//XYdPnxYt956q9q1aydJuuaaaxznHz58WB07dlTnzp0lmb13rpCSkuIIcHbXX3+91qxZI0nq16+f7r//ft19993q3LmzAgICNGvWrDxfKzU1VSkpKbrlllscn2urVq0czwcGBsrLyyvfn/NzmzRpkuNn+SeeeEJt2rTRzz//rMjISL366qvq27evIwy3aNFCmzdvdlqTwUqW9Vx5e3urU6dOjm5FyVzQYsOGDYqJicnznJiYGKf2krRu3TpH+6ysLGVlZV11EzBPT0/l5OS4+ArKydat0uLF0u+/W10JAACoIPz9pfPnrdmKMd2pUPawYHf+/HlNmjRJrVq1UkhIiAIDA5WYmFhoz1X79u0d+wEBAQoKCsp39WlJ8vf3dwQASapXr56jfUpKipKTk9W1a1fH856enurUqVOxri23xMREeXl5KTo62nGsVq1aatmypRITEyVJY8eO1dNPP60ePXpoxowZ+vHHHx1tH3roIb3//vuKiorS//3f/2nz5s35vtd7772nwMBAx/b111/n27Z69erasWOH0/bmm286tXn++ed16dIlLVu2TO+9916+86Nq1qypESNGKDY2VgMGDNDLL7/sNNSyOHJ/P+vVqydJju/P3r17nb43kq762kqWDgucMGGCFi5cqLfeekuJiYl66KGHlJaW5li5ZNiwYZo6daqj/bhx47R27VrNmTNHe/bscXRT2n+TERQUpJ49e+rRRx/Vxo0bdeDAAS1evFhvv/224zcPbueee6SRI6Vt26yuBAAAVBA2mxQQYM3mynUhAgICnL6eNGmSli9frmeffVZff/21duzYoXbt2ikzM7PA16lWrdoVn4+twF+s59XewgW0JUl//etf9euvv+qee+7Rzp071blzZ7366quSpL59++rQoUN65JFHdOzYMfXq1ctpGGNuAwcOdApLVwbY3Dw8PNSsWTOnrX79+k5tfvnlFx07dkw5OTk6ePBggdewaNEixcfHq3v37lq6dKlatGihb7/9tngfhJy/P/aFSNylo8TScDVkyBA9//zzmj59uqKiorRjxw6tXbvWMZHu8OHDTom3e/fuWrJkiRYsWKAOHTroww8/1IoVK9S2bVtHm/fff19dunTR3XffrdatW+sf//iHnnnmGT344IPlfn0uYe9O/eO3GgAAAJXVpk2bNGLECA0ePFjt2rVTWFhYoT/Qu1pwcLBCQ0P1/fffO45lZ2crISGhxK/ZqlUrXbp0Sd99953j2O+//669e/eqdevWjmMRERF68MEH9fHHH2vixIlauHCh47k6depo+PDhevfdd/XSSy9pwYIFeb5X9erVncKSn59fievOzMzUX/7yFw0ZMkRPPfWU/vrXvxbYIyhJHTt21NSpU7V582a1bdtWS5YskWSOWsvOzi5xLXYtW7Z0+t5IuuprK1k258pu9OjR+Y6h3bhx41XHbr/9dt1+++35vl5YWJhLVk+pMFq1kpYvJ1wBAIBKr3nz5vr44481YMAA2Ww2TZs2zZIeizFjxmjWrFlq1qyZY57PmTNnirSc+86dO1W9enXH1zabTR06dNCgQYN0//3364033lD16tU1ZcoU1a9fX4MGDZIkjR8/Xn379lWLFi105swZffHFF445S9OnT1enTp3Upk0bZWRkaNWqVU7zmUrKMIw8V+muW7euPDw89Pe//10pKSl65ZVXFBgYqNWrV+vee+/Nc37TgQMHtGDBAg0cOFDh4eHau3ev9u/fr2HDhkky54kdOHBAO3bsUIMGDVS9evUSLcE+ZswY3XDDDXrhhRc0YMAA/e9//9OaNWsqzFL7locrFML+2wzCFQAAqOReeOEF3Xvvverevbtq166tyZMnKzU1tdzrmDx5spKSkjRs2DB5enrqgQceUGxsrDw9PQs998rb/3h6eurSpUtatGiRxo0bp1tuuUWZmZm64YYbtHr1ascQuOzsbI0aNUq//fabgoKC1KdPH7344ouSzF6fqVOn6uDBg/Lz89P111+v999/v9TXmZqa6pjTlNvx48e1Z88evfTSS/riiy8cK2m/88476tChg+bNm6eHHnrI6Rx/f3/t2bNHb731ln7//XfVq1dPo0aN0t/+9jdJ0q233upYYv3s2bNatGiRRowYUeyae/Toofnz5+uJJ57Q448/rtjYWD3yyCOaO3du8T+AMmAzrB5gWgEV5y7MZS4hQerUSapTRyqkGxYAAFRO6enpOnDggJo0aSJfX1+ry6lycnJy1KpVK91xxx166qmnrC4HV7j//vu1Z8+eAhfvKExBf8eKkw3ouaroWrY0H0+eNFcMLOVdsAEAAFCwQ4cO6fPPP1fPnj2VkZGhuXPn6sCBA7rrrrusLg0yVzC86aabFBAQoDVr1uitt97S66+/bnVZkirhTYQrnYAAqVEjc5+hgQAAAGXOw8NDixcvVpcuXdSjRw/t3LlT69evd8k8J5Teli1bdNNNN6ldu3aaP3++XnnlFf31r3+1uixJ9Fy5h1atpEOHzHB13XVWVwMAAFCpRUREaNOmTVaXgXx88MEHVpeQL3qu3IH9tyS7d1tbBwAAAIB8Ea7cAfe6AgAAACo8wpU7IFwBAAAAFR7hyh3Yw9Xhw9L589bWAgAAACBPhCt3UKuWeZ8rSdq719paAAAAAOSJcOUuGBoIAAAAVGiEK3dBuAIAAFDjxo310ksvFbn9xo0bZbPZdPbs2TKrCRXf4sWLFRISUubvQ7hyF4QrAADgRmw2W4HbzJkzS/S633//vR544IEit+/evbuOHz+u4ODgEr1fUblbiFu8eLHje+Hh4aEGDRpo5MiROnHihNWluTVuIuwuWrc2HwlXAADADRw/ftyxv3TpUk2fPl17c80dDwwMdOwbhqHs7Gx5eRX+o2kd+zz0IvL29lZYWFixzqkqgoKCtHfvXuXk5OiHH37QyJEjdezYMX322WdXtc3OznYEMeSPT8dd2Huufv5ZysqythYAAGAtw5DS0qzZDKNIJYaFhTm24OBg2Ww2x9d79uxR9erVtWbNGnXq1Ek+Pj765ptv9Msvv2jQoEEKDQ1VYGCgunTpovXr1zu97pXDAm02m958800NHjxY/v7+at68uVauXOl4/soeJfvwsM8++0ytWrVSYGCg+vTp4xQGL126pLFjxyokJES1atXS5MmTNXz4cMXFxZX4W3bmzBkNGzZMNWrUkL+/v/r27av9+/c7nj906JAGDBigGjVqKCAgQG3atNHq1asd5959992qU6eO/Pz81Lx5cy1atKjEtdjZvyfh4eHq27evxo4dq/Xr1+vixYuOz2nlypVq3bq1fHx8dPjw4UKvw37eihUr1Lx5c/n6+io2NlZHjhxxeu958+apadOm8vb2VsuWLfXOO+84njMMQzNnzlTDhg3l4+Oj8PBwjR071vF8RkaGJk2apPr16ysgIEDR0dHauHGj0+svXrxYDRs2lL+/vwYPHqzff/+91J9XURCu3EX9+lL16tKlS2bAAgAAVdeFC1JgoDXbhQsuu4wpU6boH//4hxITE9W+fXudP39e/fr104YNG7R9+3b16dNHAwYM0OHDhwt8nSeeeEJ33HGHfvzxR/Xr10933323Tp8+XcDHd0HPP/+83nnnHX311Vc6fPiwJk2a5Hh+9uzZeu+997Ro0SJt2rRJqampWrFiRamudcSIEdq6datWrlyp+Ph4GYahfv36KeuPX5qPGjVKGRkZ+uqrr7Rz507Nnj3b0bs3bdo07d69W2vWrFFiYqLmzZun2rVrl6qevPj5+SknJ0eXLl2SZH5Os2fP1ptvvqmffvpJdevWLfQ67Oc988wzevvtt7Vp0yadPXtWd955p+P55cuXa9y4cZo4caJ27dqlv/3tbxo5cqS++OILSdJHH32kF198UW+88Yb279+vFStWqF27do7zR48erfj4eL3//vv68ccfdfvtt6tPnz6OkPfdd9/pvvvu0+jRo7Vjxw796U9/0tNPP+3yzytPBq6SkpJiSDJSUlKsLsVZly6GIRnGRx9ZXQkAAChHFy9eNHbv3m1cvHjRPHD+vPkzgRXb+fPFrn/RokVGcHCw4+svvvjCkGSsWLGi0HPbtGljvPrqq46vGzVqZLz44ouOryUZjz/+uOPr8+fPG5KMNWvWOL3XmTNnHLVIMn7++WfHOa+99poRGhrq+Do0NNR47rnnHF9funTJaNiwoTFo0KB867zyfXLbt2+fIcnYtGmT49ipU6cMPz8/44MPPjAMwzDatWtnzJw5M8/XHjBggDFy5Mh837skrvye7Nu3z2jRooXRuXNnx/OSjB07dhTrOuznffvtt442iYmJhiTju+++MwzDMLp3727cf//9TvXcfvvtRr9+/QzDMIw5c+YYLVq0MDIzM6+q+9ChQ4anp6dx9OhRp+O9evUypk6dahiGYQwdOtTxWnZDhgxxut4rXfV3LJfiZAN6rtwJi1oAAABJ8veXzp+3ZvP3d9lldO7c2enr8+fPa9KkSWrVqpVCQkIUGBioxMTEQnuu2rdv79gPCAhQUFBQgQsz+Pv7q2nTpo6v69Wr52ifkpKi5ORkde3a1fG8p6enOnXqVKxryy0xMVFeXl6Kjo52HKtVq5ZatmypxD9+rhs7dqyefvpp9ejRQzNmzNCPP/7oaPvQQw/p/fffV1RUlP7v//5Pmzdvzve93nvvPQUGBjq2r7/+Ot+2KSkpCgwMlL+/v1q2bKnQ0FC99957jue9vb2dPtuiXIckeXl5qUuXLo6vIyMjFRIS4miTmJioHj16ONXSo0cPx/O33367Ll68qGuuuUb333+/li9f7uhN27lzp7Kzs9WiRQun6/zyyy/1yy+/OF4/d42SFBMTk+/n4EosaOFO7OFq925r6wAAANay2aSAAKurKLWAK65h0qRJWrdunZ5//nk1a9ZMfn5+uu2225SZmVng61SrVs3pa5vNppycnGK1N4o4l6ys/PWvf1VsbKz++9//6vPPP9esWbM0Z84cjRkzRn379tWhQ4e0evVqrVu3Tr169dKoUaP0/PPPX/U6AwcOdAoW9evXz/c9q1evroSEBHl4eKhevXry8/Nzet7Pz082m811F1lEERER2rt3r9avX69169bp4Ycf1nPPPacvv/xS58+fl6enp7Zt2yZPT0+n83IvkmIVeq7cCT1XAACgEtu0aZNGjBihwYMHq127dgoLC9PBgwfLtYbg4GCFhobq+++/dxzLzs5WQkJCiV+zVatWunTpkr777jvHsd9//1179+5Va/uK0DJDxYMPPqiPP/5YEydO1MKFCx3P1alTR8OHD9e7776rl156SQsWLMjzvapXr65mzZo5tisDU24eHh5q1qyZrrnmmgLbFfc6Ll26pK1btzq+3rt3r86ePatWf/ws26pVK23atMnptTdt2uT0Gn5+fhowYIBeeeUVbdy4UfHx8dq5c6c6duyo7OxsnThxwuk6mzVr5lgVslWrVk41StK3335b6PW5Aj1X7sQervbskXJyJJbCBAAAlUjz5s318ccfa8CAAbLZbJo2bVqBPVBlZcyYMZo1a5aaNWumyMhIvfrqqzpz5kyRenF27typ6tWrO7622Wzq0KGDBg0apPvvv19vvPGGqlevrilTpqh+/foaNGiQJGn8+PHq27evWrRooTNnzuiLL75whJHp06erU6dOatOmjTIyMrRq1SrHc+WpefPmhV6HZPYMjhkzRq+88oq8vLw0evRodevWzTHU8tFHH9Udd9yhjh07qnfv3vr000/18ccfO1aGXLx4sbKzsxUdHS1/f3+9++678vPzU6NGjVSrVi3dfffdGjZsmObMmaOOHTvq5MmT2rBhg9q3b6/+/ftr7Nix6tGjh55//nkNGjRIn332mdauXVsunxE/nbuTa66RvL2lixelQsYeAwAAuJsXXnhBNWrUUPfu3TVgwADFxsbq2muvLfc6Jk+erKFDh2rYsGGKiYlRYGCgYmNj5evrW+i5N9xwgzp27OjY7HO1Fi1apE6dOumWW25RTEyMDMPQ6tWrHUMUs7OzNWrUKLVq1Up9+vRRixYt9Prrr0sy5z5NnTpV7du31w033CBPT0+9//77ZfcBFKCw65DMOW2TJ0/WXXfdpR49eigwMFBLly51PB8XF6eXX35Zzz//vNq0aaM33nhDixYt0o033ihJCgkJ0cKFC9WjRw+1b99e69ev16effqpatWo5ahg2bJgmTpyoli1bKi4uTt9//70aNmwoSerWrZsWLlyol19+WR06dNDnn3+uxx9/vFw+H5th9QDTCig1NVXBwcFKSUlRUFCQ1eU4a9tW+uknafVqqW9fq6sBAADlID09XQcOHFCTJk2K9AM+XCsnJ0etWrXSHXfcoaeeesrqciq0xYsXa/z48Y77irmLgv6OFScb0HPlbph3BQAAUKYOHTqkhQsXat++fdq5c6ceeughHThwQHfddZfVpaGCI1y5G8IVAABAmfLw8NDixYvVpUsX9ejRQzt37tT69estmecE98KCFu6GcAUAAFCmIiIirlrNDkUzYsQIjRgxwuoyLEPPlbuxL1GZmGjeJx0AAABAhUC4cjctWpg3Djx9Wjp50upqAABAOWIdMqBsuOrvFuHK3fj5SU2amPsMDQQAoEqwL3N94cIFiysBKif7363cS8qXBHOu3FGrVtKvv5rhqmdPq6sBAABlzNPTUyEhITpx4oQk8z5CRbmhLYCCGYahCxcu6MSJEwoJCZGnp2epXo9w5Y5atZL++196rgAAqELCwsIkyRGwALhOSEiI4+9YaRCu3BErBgIAUOXYbDbVq1dPdevWVVZWltXlAJVGtWrVSt1jZUe4ckf2cLV7t7V1AACAcufp6emyHwQBuBYLWrgje7g6elRKTbW2FgAAAACSCFfuKSREso8J3bPH0lIAAAAAmAhX7op5VwAAAECFQrhyV4QrAAAAoEIhXLkrwhUAAABQoRCu3BXhCgAAAKhQCFfuyh6ufvlFysiwthYAAAAAhCu3Va+eFBws5eRI+/dbXQ0AAABQ5RGu3JXNxtBAAAAAoAIhXLkzwhUAAABQYRCu3BnhCgAAAKgwKkS4eu2119S4cWP5+voqOjpaW7ZsKbD9smXLFBkZKV9fX7Vr106rV692et5ms+W5Pffcc2V5GeWPcAUAAABUGJaHq6VLl2rChAmaMWOGEhIS1KFDB8XGxurEiRN5tt+8ebOGDh2q++67T9u3b1dcXJzi4uK0a9cuR5vjx487bf/+979ls9l06623ltdllQ97uNqzR8rOtrYWAAAAoIqzGYZhWFlAdHS0unTporlz50qScnJyFBERoTFjxmjKlClXtR8yZIjS0tK0atUqx7Fu3bopKipK8+fPz/M94uLidO7cOW3YsKFINaWmpio4OFgpKSkKCgoqwVWVk+xsKSDAXIr955+lpk2trggAAACoVIqTDSztucrMzNS2bdvUu3dvxzEPDw/17t1b8fHxeZ4THx/v1F6SYmNj822fnJys//73v7rvvvvyrSMjI0OpqalOm1vw9JRatjT3GRoIAAAAWMrScHXq1CllZ2crNDTU6XhoaKiSkpLyPCcpKalY7d966y1Vr15df/7zn/OtY9asWQoODnZsERERxbwSCzHvCgAAAKgQLJ9zVdb+/e9/6+6775avr2++baZOnaqUlBTHduTIkXKssJQIVwAAAECF4GXlm9euXVuenp5KTk52Op6cnKywsLA8zwkLCyty+6+//lp79+7V0qVLC6zDx8dHPj4+xay+giBcAQAAABWCpT1X3t7e6tSpk9NCEzk5OdqwYYNiYmLyPCcmJuaqhSnWrVuXZ/t//etf6tSpkzp06ODawiuS3OHK2rVJAAAAgCrN8mGBEyZM0MKFC/XWW28pMTFRDz30kNLS0jRy5EhJ0rBhwzR16lRH+3Hjxmnt2rWaM2eO9uzZo5kzZ2rr1q0aPXq00+umpqZq2bJl+utf/1qu11PuWrSQPDyklBQpn3lnAAAAAMqepcMCJXNp9ZMnT2r69OlKSkpSVFSU1q5d61i04vDhw/LwuJwBu3fvriVLlujxxx/XY489pubNm2vFihVq27at0+u+//77MgxDQ4cOLdfrKXc+PuYS7Pv3m71X9epZXREAAABQJVl+n6uKyG3uc2U3aJC0cqU0d640apTV1QAAAACVhtvc5wouwqIWAAAAgOUIV5UB4QoAAACwHOGqMiBcAQAAAJYjXFUGkZHm4/Hj0tmzlpYCAAAAVFWEq8ogKEiqX9/cp/cKAAAAsAThqrJgaCAAAABgKcJVZUG4AgAAACxFuKosCFcAAACApQhXlQXhCgAAALAU4aqysIerAwekixetrQUAAACogghXlUXdulKNGpJhSPv2WV0NAAAAUOUQrioLm42hgQAAAICFCFeVSevW5iPhCgAAACh3hKvKhJ4rAAAAwDKEq8qEcAUAAABYhnBVmdjD1b590qVL1tYCAAAAVDGEq8qkYUPJ31/KzJR+/dXqagAAAIAqhXBVmXh4SC1bmvsMDQQAAADKFeGqsmHeFQAAAGAJwlVlQ7gCAAAALEG4qmwIVwAAAIAlCFeVjT1c7dkjGYa1tQAAAABVCOGqsmnWTPL0lM6dk44etboaAAAAoMogXFU23t5mwJIYGggAAACUI8JVZcS8KwAAAKDcEa4qo9atzUfCFQAAAFBuCFeVET1XAAAAQLkjXFVGhCsAAACg3BGuKqPISPPxxAnp9GlrawEAAACqCMJVZRQQIDVsaO7TewUAAACUC8JVZWUfGrh7t7V1AAAAAFUE4aqyYt4VAAAAUK4IV5UV4QoAAAAoV4SryopwBQAAAJQrwlVlZQ9Xhw5JaWnW1gIAAABUAYSryqp2bXOTpL17ra0FAAAAqAIIV5UZQwMBAACAckO4qswIVwAAAEC5IVxVZq1bm4+EKwAAAKDMEa4qM3quAAAAgHJDuKrM7OFq/34pK8vaWgAAAIBKjnBVmTVoIAUGSpcuSb/8YnU1AAAAQKVGuKrMbDYpMtLcZ2ggAAAAUKYIV5WdfWjg7t3W1gEAAABUcoSryo5FLQAAAIByYXm4eu2119S4cWP5+voqOjpaW7ZsKbD9smXLFBkZKV9fX7Vr106rV6++qk1iYqIGDhyo4OBgBQQEqEuXLjp8+HBZXULFRrgCAAAAyoWl4Wrp0qWaMGGCZsyYoYSEBHXo0EGxsbE6ceJEnu03b96soUOH6r777tP27dsVFxenuLg47dq1y9Hml19+0XXXXafIyEht3LhRP/74o6ZNmyZfX9/yuqyKxR6u9uyRcnKsrQUAAACoxGyGYRhWvXl0dLS6dOmiuXPnSpJycnIUERGhMWPGaMqUKVe1HzJkiNLS0rRq1SrHsW7duikqKkrz58+XJN15552qVq2a3nnnnRLXlZqaquDgYKWkpCgoKKjEr1MhXLok+fubS7EfPCg1amR1RQAAAIDbKE42sKznKjMzU9u2bVPv3r0vF+Phod69eys+Pj7Pc+Lj453aS1JsbKyjfU5Ojv773/+qRYsWio2NVd26dRUdHa0VK1YUWEtGRoZSU1OdtkrDy0tq3tzcZ2ggAAAAUGYsC1enTp1Sdna2QkNDnY6HhoYqKSkpz3OSkpIKbH/ixAmdP39e//jHP9SnTx99/vnnGjx4sP785z/ryy+/zLeWWbNmKTg42LFFRESU8uoqGOZdAQAAAGXO8gUtXCnnjzlFgwYN0iOPPKKoqChNmTJFt9xyi2PYYF6mTp2qlJQUx3bkyJHyKrlIcnJKOV2KcAUAAACUOcvCVe3ateXp6ank5GSn48nJyQoLC8vznLCwsALb165dW15eXmrdurVTm1atWhW4WqCPj4+CgoKctooiLk4KCZFyrdlRfIQrAAAAoMxZFq68vb3VqVMnbdiwwXEsJydHGzZsUExMTJ7nxMTEOLWXpHXr1jnae3t7q0uXLtq7d69Tm3379qmRmy7kkJoqnTsnff99KV7EHjYJVwAAAECZsXRY4IQJE7Rw4UK99dZbSkxM1EMPPaS0tDSNHDlSkjRs2DBNnTrV0X7cuHFau3at5syZoz179mjmzJnaunWrRo8e7Wjz6KOPaunSpVq4cKF+/vlnzZ07V59++qkefvjhcr8+V+jSxXwsVbhq2VKy2aTff5dOnnRJXQAAAACceVn55kOGDNHJkyc1ffp0JSUlKSoqSmvXrnUsWnH48GF5eFzOf927d9eSJUv0+OOP67HHHlPz5s21YsUKtW3b1tFm8ODBmj9/vmbNmqWxY8eqZcuW+uijj3TdddeV+/W5QufO5mOpwpWfn9S4sXTggNl7VaeOK0oDAAAAkIul97mqqCrSfa4OHpSaNDFXVD93TirxvZD795dWr5bmz5f+9jdXlggAAABUWm5xnysUTaNGUu3a5r2Af/yxFC9kX9Ri926X1AUAAADAGeGqgrPZXDTvihUDAQAAgDJFuHIDhCsAAACg4iNcuQGXhqvffjMnbwEAAABwKcKVG7CHq8TEUuSiGjWkP1Zh1J49LqkLAAAAwGWEKzcQGipFREiGISUklOKFGBoIAAAAlBnClZtg3hUAAABQsRGu3AThCgAAAKjYCFduonNn85FwBQAAAFRMhCs3YQ9XBw5Ip06V8EVatzYff/lFysx0SV0AAAAATIQrNxESIjVvbu5v21bCF6lXTwoKkrKzpf37XVUaAAAAABGu3Eqp513ZbAwNBAAAAMoI4cqNsKgFAAAAUHERrtyIS8PV7t2lrgcAAADAZYQrN9Kxo+TpKR0/Lh09WsIXoecKAAAAKBOEKzfi7y+1aWPul7j3yh6u9u41F7YAAAAA4BKEKzdT6qGBTZpIPj5Serp06JDL6gIAAACqOsKVmyl1uPL0lFq0MPcZGggAAAC4DOHKzdhvJrx1q2QYJXwR5l0BAAAALke4cjPt2kne3tKZM9Ivv5TwRQhXAAAAgMsRrtyMt7cUFWXul3pRC8IVAAAA4DKEKzdkn3e1dWsJXyB3uCrx2EIAAAAAuRGu3FCpF7Vo0ULy8JDOnpWSk11VFgAAAFClEa7ckD1cJSSU8FZVvr7SNdeY+wwNBAAAAFyCcOWGWraUAgOltLRSZCPmXQEAAAAuRbhyQ56eUqdO5j6LWgAAAAAVA+HKTZV63pU9XO3e7ZJ6AAAAgKqOcOWmXBau6LkCAAAAXIJw5aY6dzYff/hBysgowQtERpqPx49LKSkuqwsAAACoqghXbqpJE6lWLSkrS/rxxxK8QHCwFB5u7tN7BQAAAJQa4cpN2WyXe68YGggAAABYj3DlxuzzrrZuLeELEK4AAAAAlyFcuTEWtQAAAAAqDsKVG7OHq927zRsKFxvhCgAAAHAZwpUbq1dPql9fysmREhJK8AL2cHXggJSe7tLaAAAAgKqGcOXmSjU0MDRUCgkx09m+fa4sCwAAAKhyCFdurlThymaTWrc29xkaCAAAAJQK4crNsagFAAAAUDEQrtyc/V5Xv/winT5dghcgXAEAAAAuQbhyczVqSE2bmvslut8V4QoAAABwCcJVJVCqoYH2cLV3r3TpkstqAgAAAKoawlUlUKpw1aiR5OcnZWaaS7IDAAAAKBHCVSVgD1clGhbo4SG1bGnuMzQQAAAAKDHCVSVw7bVmRjp6VDp+vAQvwLwrAAAAoNQqRLh67bXX1LhxY/n6+io6OlpbtmwpsP2yZcsUGRkpX19ftWvXTqtXr3Z6fsSIEbLZbE5bnz59yvISLBUQcPl2VaWad0W4AgAAAErM8nC1dOlSTZgwQTNmzFBCQoI6dOig2NhYnThxIs/2mzdv1tChQ3Xfffdp+/btiouLU1xcnHbt2uXUrk+fPjp+/Lhj+89//lMel2MZlyxqQbgCAAAASszycPXCCy/o/vvv18iRI9W6dWvNnz9f/v7++ve//51n+5dffll9+vTRo48+qlatWumpp57Stddeq7lz5zq18/HxUVhYmGOrUaNGeVyOZVwWrgzDZTUBAAAAVYml4SozM1Pbtm1T7969Hcc8PDzUu3dvxcfH53lOfHy8U3tJio2Nvar9xo0bVbduXbVs2VIPPfSQfv/993zryMjIUGpqqtPmbnKHq2Lno+bNJU9P6dw56dgxl9cGAAAAVAWWhqtTp04pOztboaGhTsdDQ0OVlJSU5zlJSUmFtu/Tp4/efvttbdiwQbNnz9aXX36pvn37Kjs7O8/XnDVrloKDgx1bREREKa+s/LVrJ3l7S6dPl2BFdW/vy3ciZmggAAAAUCKWDwssC3feeacGDhyodu3aKS4uTqtWrdL333+vjRs35tl+6tSpSklJcWxHjhwp34JdwMdHat/e3GfeFQAAAFD+LA1XtWvXlqenp5KTk52OJycnKywsLM9zwsLCitVekq655hrVrl1bP//8c57P+/j4KCgoyGlzR6Wad2VfbpBwBQAAAJSIpeHK29tbnTp10oYNGxzHcnJytGHDBsXExOR5TkxMjFN7SVq3bl2+7SXpt99+0++//6569eq5pvAKihUDAQAAAOtYPixwwoQJWrhwod566y0lJibqoYceUlpamkaOHClJGjZsmKZOnepoP27cOK1du1Zz5szRnj17NHPmTG3dulWjR4+WJJ0/f16PPvqovv32Wx08eFAbNmzQoEGD1KxZM8XGxlpyjeXFHq4SEqR8ppflj3AFAAAAlIqX1QUMGTJEJ0+e1PTp05WUlKSoqCitXbvWsWjF4cOH5eFxOQN2795dS5Ys0eOPP67HHntMzZs314oVK9S2bVtJkqenp3788Ue99dZbOnv2rMLDw3XzzTfrqaeeko+PjyXXWF5atTJvKHz+vLR37+WRfkUSGWk+Jiebq2LUrFkmNQIAAACVlc0wuLHRlVJTUxUcHKyUlBS3m391ww3S119LixdLw4cX8+SGDaUjR6RvvpF69CiL8gAAAAC3UpxsYPmwQLgW864AAAAAaxCuKhnCFQAAAGANwlUlYw9XO3ZImZnFPJlwBQAAAJQY4aqSueYaqUYNM1jt3FnMkwlXAAAAQIkRrioZm03q3NncL/bQQHu4OnRIunDBpXUBAAAAlR3hqhIq8byrOnWkWrUkwzDXcgcAAABQZISrSohFLQAAAIDyR7iqhOzh6qefpLS0Yp5MuAIAAABKhHBVCdWvL9WrJ+XkmKsGFkvr1uYj4QoAAAAoFsJVJVXioYH0XAEAAAAlQriqpEodrvbvl7KyXFoTAAAAUJkRriqpEoeriAgpIMAMVr/84vK6AAAAgMqKcFVJ2e91tX+/dPZsMU602aTISHOfoYEAAABAkRGuKqlataRrrjH3t24t5snMuwIAAACKjXBVidl7r1jUAgAAACh7hKtKjBUDAQAAgPJDuKrESh2u9uwxb5YFAAAAoFCEq0rs2mvN9Sl++01KSirGiU2bSl5eUlqaeTIAAACAQhGuKrHq1S93QhVrUYtq1aTmzc19hgYCAAAARUK4quSYdwUAAACUD8JVJUe4AgAAAMoH4aqSyx2uDKMYJ7ZubT4SrgAAAIAiIVxVch06mFOoTp2SDh0qxon0XAEAAADFQriq5Hx8pPbtzf1iDQ1s2dJcavDUKenkyTKpDQAAAKhMCFdVQInmXfn7S40amfv0XgEAAACFIlxVAZ07m48sagEAAACUHcJVFWDvudq2TcrJKcaJhCsAAACgyAhXVUDr1pKfn3TunLR3bzFOJFwBAAAARUa4qgK8vKRrrzX3izU0kHAFAAAAFBnhqoqwDw3curUYJ9nD1ZEj0vnzLq8JAAAAqExKFK6OHDmi3377zfH1li1bNH78eC1YsMBlhcG1SrRiYM2aUt265v6ePS6vCQAAAKhMShSu7rrrLn3xxReSpKSkJN10003asmWL/v73v+vJJ590aYFwDXu42rFDysoqxokMDQQAAACKpEThateuXeratask6YMPPlDbtm21efNmvffee1q8eLEr64OLNGsmhYRI6enSrl3FOJFwBQAAABRJicJVVlaWfHx8JEnr16/XwIEDJUmRkZE6fvy466qDy9hsJbzfFeEKAAAAKJIShas2bdpo/vz5+vrrr7Vu3Tr16dNHknTs2DHVqlXLpQXCdUo074pwBQAAABRJicLV7Nmz9cYbb+jGG2/U0KFD1aFDB0nSypUrHcMFUfGUqOeqdWvz8eefpcxMl9cEAAAAVBY2wzCMkpyYnZ2t1NRU1ahRw3Hs4MGD8vf3V137CnNuKjU1VcHBwUpJSVFQUJDV5bjMkSNSw4aSp6eUmir5+xfhJMOQgoPNOxD/9NPlsAUAAABUAcXJBiXqubp48aIyMjIcwerQoUN66aWXtHfvXrcPVpVZgwZSaKiUnW2uGlgkNtvloYG7d5dVaQAAAIDbK1G4GjRokN5++21J0tmzZxUdHa05c+YoLi5O8+bNc2mBcB2bjXlXAAAAQFkpUbhKSEjQ9ddfL0n68MMPFRoaqkOHDuntt9/WK6+84tIC4Vr2cLV1azFOIlwBAAAAhSpRuLpw4YKqV68uSfr888/15z//WR4eHurWrZsOHTrk0gLhWvRcAQAAAGWjROGqWbNmWrFihY4cOaLPPvtMN998syTpxIkTlWoBiMrIHq727pVSUop4kj1c7d0r5eSUSV0AAACAuytRuJo+fbomTZqkxo0bq2vXroqJiZFk9mJ17NjRpQXCtWrXlho3Nve3bSviSU2aSN7e0sWLEj2TAAAAQJ5KFK5uu+02HT58WFu3btVnn33mON6rVy+9+OKLLisOZaPYQwO9vKQWLcx9hgYCAAAAeSpRuJKksLAwdezYUceOHdNvv/0mSeratasiIyNdVhzKBvOuAAAAANcrUbjKycnRk08+qeDgYDVq1EiNGjVSSEiInnrqKeWUYE7Oa6+9psaNG8vX11fR0dHasmVLge2XLVumyMhI+fr6ql27dlq9enW+bR988EHZbDa99NJLxa6rsurc2XwkXAEAAACuU6Jw9fe//11z587VP/7xD23fvl3bt2/Xs88+q1dffVXTpk0r1mstXbpUEyZM0IwZM5SQkKAOHTooNjZWJ06cyLP95s2bNXToUN13333avn274uLiFBcXp127dl3Vdvny5fr2228VHh5eksustDp1Mu95dfiwlM/HfDXCFQAAAFAgm2EYRnFPCg8P1/z58zVw4ECn45988okefvhhHT16tMivFR0drS5dumju3LmSzF6xiIgIjRkzRlOmTLmq/ZAhQ5SWlqZVq1Y5jnXr1k1RUVGaP3++49jRo0cVHR2tzz77TP3799f48eM1fvz4ItWUmpqq4OBgpaSkVNrVD1u1kvbskVatkvr3L8IJP/wgRUVJNWpIv/9upjMAAACgkitONihRz9Xp06fznFsVGRmp06dPF/l1MjMztW3bNvXu3ftyQR4e6t27t+Lj4/M8Jz4+3qm9JMXGxjq1z8nJ0T333KNHH31Ubdq0KbSOjIwMpaamOm2VXbHnXbVoIXl4SGfOFKO7CwAAAKg6ShSuOnTo4Ohpym3u3Llq3759kV/n1KlTys7OVmhoqNPx0NBQJSUl5XlOUlJSoe1nz54tLy8vjR07tkh1zJo1S8HBwY4tIiKiyNfgroodrvz8zCXZJYYGAgAAAHnwKslJ//znP9W/f3+tX7/ecY+r+Ph4HTlypMDFJcrDtm3b9PLLLyshIUG2Ig5dmzp1qiZMmOD4OjU1tdIHLHu42rpVMowijvJr1Ur65RczXN14Y1mWBwAAALidEvVc9ezZU/v27dPgwYN19uxZnT17Vn/+85/1008/6Z133iny69SuXVuenp5KTk52Op6cnKywsLA8zwkLCyuw/ddff60TJ06oYcOG8vLykpeXlw4dOqSJEyeqsf3uuVfw8fFRUFCQ01bZRUWZt686cUI6cqSIJ9kXtdi9u6zKAgAAANxWie9zFR4ermeeeUYfffSRPvroIz399NM6c+aM/vWvfxX5Nby9vdWpUydt2LDBcSwnJ0cbNmxw9IhdKSYmxqm9JK1bt87R/p577tGPP/6oHTt2OLbw8HA9+uijTjc8rup8faV27cz9Ig8NZMVAAAAAIF8lGhboShMmTNDw4cPVuXNnde3aVS+99JLS0tI0cuRISdKwYcNUv359zZo1S5I0btw49ezZU3PmzFH//v31/vvva+vWrVqwYIEkqVatWqpVq5bTe1SrVk1hYWFq2bJl+V5cBdeli7R9uxmubr21CCcQrgAAAIB8WR6uhgwZopMnT2r69OlKSkpSVFSU1q5d61i04vDhw/LwuNzB1r17dy1ZskSPP/64HnvsMTVv3lwrVqxQ27ZtrboEt9Wli7RgQQl6ro4dk1JSpODgMqsNAAAAcDclus9Vfn744Qdde+21ys7OdtVLWqIq3OdKunzrqqAgc4V1j6IMEg0Pl44fl779VoqOLusSAQAAAEsVJxsUq+fqz3/+c4HPnz17tjgvB4u1bm3OvUpNlfbvl4o0arJVKzNcJSYSrgAAAIBcihWuggsZBhYcHKxhw4aVqiCUn2rVpI4dpfh4c2hgkcPV//7HvCsAAADgCsUKV4sWLSqrOmCRLl0uh6u//KUIJ7CoBQAAAJCnEi/FjsrBfjNhlmMHAAAASodwVcXZw9X27dKlS0U4wR6ufv1VSk8vs7oAAAAAd0O4quKaNzdXC0xPl376qQgnhIWZS7Dn5JirYAAAAACQRLiq8jw8pM6dzf0iDQ202cxlBiWGBgIAAAC5EK7AvCsAAADABQhXKHm42r27TOoBAAAA3BHhCo5wtXNnEdeooOcKAAAAuArhCoqIkOrUMVcL3LGjCCfYw9W+fVJ2dlmWBgAAALgNwhVksxVzaGCjRpKvr5SRIR04UKa1AQAAAO6CcAVJxQxXnp5Sy5bmPkMDAQAAAEmEK/yBFQMBAACA0iFcQdLlcLV3r5SaWoQTCFcAAACAE8IVJEl160oNG0qGISUkFOEEwhUAAADghHAFh2INDcwdrgyjzGoCAAAA3AXhCg7FClfNm0seHuYYwuPHy7QuAAAAwB0QruBQrHDl4yM1bWruMzQQAAAAIFzhsk6dzMeDB6WTJ4twQuvW5iPhCgAAACBc4bLgYKlFC3N/69YinMCiFgAAAIAD4QpOSrSoxe7dZVYPAACowFavlt5/X/rpJykry+pqAMt5WV0AKpYuXaT33ivBioEAAKBq2bJF6t//8tfVqkktW0rt2klt215+bNTIXAQLqAIIV3CSu+fKMCSbrYDGkZHmY3KydOaMVKNGmdcHAAAqiBUrzMfataWMDOncOWnXLnPLLTBQatPGDFq5Q1fduoX8oAG4H8IVnERFSZ6eZl767TcpIqKAxtWrSw0amA0TE6Xu3curTAAAYLX//td8fOkl6a67pMOHL4ernTvNx8RE6fx56bvvzC232rUvBy176GrTRgoKKvdLAVyFcAUn/v7mv28//GAualFguJLMoYGEKwAAqpbffpN+/NHseYqNNR8bNTK33EMFL12S9u93Dly7dkk//yydOiV98YW55daw4dWhKzLSvA0MUMERrnCVLl3McPX999LgwYU0btVKWreOeVcAAFQlq1ebj926mT1Q+fHyMn9WaNVKuv32y8cvXDB/drgydB09avaAHT58uWdMMofVtGhx9dDCa64xnwMqCMIVrtKli/TmmyxqAQAA8mEPPrl7qYrD39+8wab9Jpt2p0+bKw/mDlw7d0pnz5o/ayQmSsuWXW7v52fed/PK0BUeznwuWIJwhavYF7XYurUIi1oQrgAAqFoyMqT16839fv1c+9o1a0rXX29udoYhHTvm3Mu1c6d5K5iLF6Vt28wttxo1Lgeu3KGLxbdQxmyGYRhWF1HRpKamKjg4WCkpKQqqgpMqs7LMtSoyMqR9+6TmzQtofOKEFBpqJrC0NPM3SAAAoPL6/HNznlV4uDn3yqoeouxs6ddfr+7l2r/ffC4v9etfHbhatTJ70oB8FCcb0HOFq1SrZq4a+N135tDAAsNVnTrmb5lOn5b27jVPBAAAlZd9SGC/ftYOvfP0NH9Iad5c+vOfLx9PT5f27Ll65cLDh805XUePSp99drm9zSY1a2bO6QoLM5eIDw29+rFmTeZ3oVCEK+SpS5fL4equuwpoaLOZv/HZtMkcGki4AgCgcrMvZuHqIYGu4utr/jxy5c8kKSnmfK7coWvnTun3383erv37C35dDw/zl8r5ha/cj3XrmnWgyiFcIU+5byZcqNatL4crAABQee3bZy6jXq2a1Lu31dUUT3CweduY3LeOMQzz5p67dplDDE+cML++8vH0aSknx9xPTjZDWWGCggoPYfbH4GAW4KgkCFfIkz1cJSSYt6jwKuhPCotaAABQNdiHBPbsaU7Qdnc2mzkUMCys4HZZWdLJk/mHr9yPJ06Y7VNTza2wHjFJ8vYuPITZ92vXLuQHM1iJ7wzy1LKl+W/muXPmYjzt2xfQ2B6udu8ul9oAAIBFKvqQwLJSrZq5gEd4eOFtDcNcOr6wEGZ/PHdOysw0Fwf57bfCX99mk2rVyj+I1alj3nC5WrW8Ny+v/J+rVo15ZaVEuEKePDzMW09s3GgODSxSuNq/vwjdXAAAwC2dOyd9+aW5X9L7W1UFNpu55HuNGlJkZOHtL14sWghLTpZOnTLD26lT5vbTT2VTf0HhqzhBrThbXq8VEiLdfLPrr7EM8VMw8tWlixmutm6V7ruvgIYREeYSphcuSL/8YnZ7AQCAymX9enO4m31lPbiGn5/UqJG5FSY72wxVBYWwU6fMnrCsrMK3S5eufg/DMM/PzHT9tRZXixbmatRuhHCFfBV5UQsPD/M3MwkJ5rwrwhUAAJVPVR0SWJF4el6ef9WuXelfzzDMgFWUIGYPY0VtW5rN/j4REaW/xnJGuEK+7OHqxx/NGwr7+BTQuFWry+EqLq48ygMAAOXFMC6HK4YEVh65hwDCJTysLgAVV6NG5oI0WVnSDz8U0pgVAwEAqLx27JCOHTOnAfTsaXU1QIVFuEK+bLZiDA0kXAEAUHnZe6169y5kKAtQtRGuUKDOnc3HIoerPXvMoQMAAKDysN/fiiGBQIEIVyhQkXuumjUzl9A8f75o92gAAADu4dQp6dtvzX0WswAKRLhCgezhKjHRvL1FvqpVMwOWvTEAAKgc1q41R6V06CA1aGB1NUCFRrhCgcLCzH9HDcNcDLBAzLsCAKDyYQl2oMgqRLh67bXX1LhxY/n6+io6OlpbtmwpsP2yZcsUGRkpX19ftWvXTqvtf+n/MHPmTEVGRiogIEA1atRQ79699d1335XlJVRqLGoBAEAVdemS2XMlMd8KKALLw9XSpUs1YcIEzZgxQwkJCerQoYNiY2N14sSJPNtv3rxZQ4cO1X333aft27crLi5OcXFx2rVrl6NNixYtNHfuXO3cuVPffPONGjdurJtvvlknT54sr8uqVOzhauvWQhq2bm0+Eq4AAKgcvv1WOnNGqllT6tbN6mqACs9mGNYu7RYdHa0uXbpo7ty5kqScnBxFRERozJgxmjJlylXthwwZorS0NK1atcpxrFu3boqKitL8+fPzfI/U1FQFBwdr/fr16tWrV6E12dunpKQoKCiohFdWeaxfL910k3TNNdIvvxTQMCFB6tRJqlNHyiccAwAAN/LYY9KsWdLQodKSJVZXA1iiONnA0p6rzMxMbdu2Tb1793Yc8/DwUO/evRUfH5/nOfHx8U7tJSk2Njbf9pmZmVqwYIGCg4PVoUOHPNtkZGQoNTXVacNl9uXYf/1V+v33Ahq2bGk+njxpriwEAADcG0uwA8Viabg6deqUsrOzFRoa6nQ8NDRUSUlJeZ6TlJRUpParVq1SYGCgfH199eKLL2rdunWqXbt2nq85a9YsBQcHO7aIiIhSXFXlExIiNW9u7hc4NDAgQGrUyNxnaCAAAO7tyBHpxx8lm03q08fqagC3YPmcq7Lypz/9STt27NDmzZvVp08f3XHHHfnO45o6dapSUlIc25EjR8q52oqPRS0AAKhi1qwxH7t1k2rVsrYWwE1YGq5q164tT09PJScnOx1PTk5WWFhYnueEhYUVqX1AQICaNWumbt266V//+pe8vLz0r3/9K8/X9PHxUVBQkNMGZ/ahgYQrAACqCIYEAsVmabjy9vZWp06dtGHDBsexnJwcbdiwQTExMXmeExMT49RektatW5dv+9yvm5GRUfqiqyh6rgAAqELS080VrSTCFVAMXlYXMGHCBA0fPlydO3dW165d9dJLLyktLU0jR46UJA0bNkz169fXrFmzJEnjxo1Tz549NWfOHPXv31/vv/++tm7dqgULFkiS0tLS9Mwzz2jgwIGqV6+eTp06pddee01Hjx7V7bffbtl1uruOHSUPD+n4cenoUal+/XwaEq4AAHB/X30lXbgghYdL+SwIBuBqloerIUOG6OTJk5o+fbqSkpIUFRWltWvXOhatOHz4sDw8Lnewde/eXUuWLNHjjz+uxx57TM2bN9eKFSvUtm1bSZKnp6f27Nmjt956S6dOnVKtWrXUpUsXff3112rTpo0l11gZBARIbdpIO3eavVeFhqvDh6Xz56XAwHKrEQAAuIh9SGC/fuaCFgCKxPL7XFVE3Ocqb/fdJ/373+YtL555poCGdeuay7Fv3Wre9woAALgPwzCXCf7lF2n5cikuzuqKAEu5zX2u4F6YdwUAQBWwf78ZrKpVk3r1sroawK0QrlBk9nC1dav5S618Ea4AAHBf9iGBPXtK1atbWwvgZghXKLJ27SRvb+nMGenXXwtoSLgCAMB9sQQ7UGKEKxSZt7cUFWXuFzg0sHVr85FwBQCAezl3zlwpUDIXswBQLIQrFEuR5l3Ze65+/lnKzCzzmgAAgIusXy9lZUnNmkktWlhdDeB2CFcols6dzccCw1X9+uYY7UuXzIAFAADcA0MCgVIhXKFY7D1XCQlSdnY+jWw2KTLS3GdoIAAA7sEwpNWrzX3CFVAihCsUS2SkeUPhtLRCchOLWgAA4F527JCOHzf/o7/hBqurAdwS4QrF4ul5+b7ARZp3RbgCAMA92IcE9u4t+fhYWwvgpghXKLZiLWpBuAIAwD0w3wooNcIViq1Y4WrPHiknp8xrAgAApXDqlPTdd+Z+377W1gK4McIVis0ern74QcrIyKfRNdeYN8a6eFE6fLjcagMAACWwdq25oEWHDlKDBlZXA7gtwhWKrUkTqVYt8zYYO3fm08jLS2re3NxnaCAAABUbQwIBlyBcodhstiLe74p5VwAAVHyXLkmffWbu9+tnbS2AmyNcoURY1AIAgEri22+lM2ekmjWlbt2srgZwa4QrlAjhCgCASsI+JLBPH/OeKwBKjHCFErEPC9y927yhcJ5yhyvDKJe6AABAMa1ebT4yJBAoNcIVSiQ83NxycqSEhHwatWxpTtA6fVo6ebJc6wMAAEVw5Ij044+Sh4fZcwWgVAhXKLFChwb6+ZlLC0pmFxcAAKhY7L1W3bqZSwEDKBXCFUqMeVcAALg5hgQCLkW4QokRrgAAcGPp6dL69eY+97cCXIJwhRKzL2rxyy/mtKo8Ea4AAKiYvvxSunDBnETdoYPV1QCVAuEKJVazptS0qbm/bVs+jQhXAABUTPYl2Pv1MxegAlBqhCuUSqFDA+3h6uhRKTW1XGoCAACFMIzL4YohgYDLEK5QKoWGq5AQKSzM3N+zpzxKAgAAhdm3T/r1V8nbW+rd2+pqgEqDcIVSYVELAADckL3XqmdPKTDQ2lqASoRwhVLp2NG87+DRo9Lx4/k0IlwBAFCxsAQ7UCYIVyiVwMDL2anQeVeEKwAArHfunPTVV+Y+860AlyJcodSKvKgF4QoAAOutWydlZUnNm5sbAJchXKHUihyufvlFysgol5oAAEA+GBIIlBnCFUotd7gyjDwa1KsnBQdLOTnS/v3lWhsAAMjFMC6HK4YEAi5HuEKptW8vVasmnT4tHTiQRwOb7XLv1e7d5VobAADIZft2cwWqgADphhusrgaodAhXKDUfH6lDB3N/69Z8GhGuAACwnr3Xqndv8z9wAC5FuIJLFDrv6tprzceXXyZgAQBgFfv9rRgSCJQJwhVcotBwdd99UkyMdPas1KeP9Ntv5VUaAACQpJMnpe++M/dZzAIoE4QruIQ9XG3bJmVn59HAz0/69FOpZUvpyBGpb18zaAEAgPLx2WfmghYdOkj161tdDVApEa7gEpGRkr+/dP68tHdvPo1q1ZLWrpXCwqRdu6TBg1maHQCA8sKQQKDMEa7gEl5el6dV5Ts0UJIaN5bWrJGqV5c2bpSGDTOXaAcAAGXn0iXzF5wS4QooQ4QruEyh867soqKk5cvN9ds/+ECaODGfG2QBAACX+PZbczh+zZpSdLTV1QCVFuEKLlPkcCVJvXpJixeb+y+9JL3wQhlVBQAAHEMC+/SRPD2trQWoxAhXcBl7uNqxQ8rMLMIJd90lPfecuT9pkrRkSVmVBgBA1cZ8K6BcEK7gMk2bSjVqmMFq584injRxojR+vLk/YoS0YUMZVQcAQBV1+LD5H7OHhxQba3U1QKVGuILL2GxS587mfpGGBtpPmjNHuuMOKSvLXEFwx46yKhEAgKpnzRrzsVs3c+VeAGWGcAWXsg8N3Lq1GCd5eEhvvy3deKN07px5D6yDB8ugOgAAqiCGBALlpkKEq9dee02NGzeWr6+voqOjtWXLlgLbL1u2TJGRkfL19VW7du20evVqx3NZWVmaPHmy2rVrp4CAAIWHh2vYsGE6duxYWV8GVMxFLXLz8TFXEGzXTkpKMifc/v67y+sDAKBKSU+/POSecAWUOcvD1dKlSzVhwgTNmDFDCQkJ6tChg2JjY3XixIk822/evFlDhw7Vfffdp+3btysuLk5xcXHatWuXJOnChQtKSEjQtGnTlJCQoI8//lh79+7VwIEDy/Oyqix7uPrpJ+nChWKeHBJiDl2IiDDvRDxgQAleBAAAOHz5pfl/af36Uvv2VlcDVHo2w7D2BkPR0dHq0qWL5s6dK0nKyclRRESExowZoylTplzVfsiQIUpLS9OqVascx7p166aoqCjNnz8/z/f4/vvv1bVrVx06dEgNGzYstKbU1FQFBwcrJSVFQUFBJbyyqskwpPBws/Ppm2+kHj1K8CK7d5snnj0rDRwoffSReZdiAABQPGPHSq++Kt1/v7RggdXVAG6pONnA0p6rzMxMbdu2Tb1793Yc8/DwUO/evRUfH5/nOfHx8U7tJSk2Njbf9pKUkpIim82mkJCQPJ/PyMhQamqq04aSsdlKMTTQrnVr6dNPzaGCK1dKo0dzk2EAAIrLMJhvBZQzS8PVqVOnlJ2drdDQUKfjoaGhSkpKyvOcpKSkYrVPT0/X5MmTNXTo0HyT5qxZsxQcHOzYIiIiSnA1sCt1uJKk664z73tls0lvvCE984xLagMAoMrYt0/69VfJ21vq1cvqaoAqwfI5V2UpKytLd9xxhwzD0Lx58/JtN3XqVKWkpDi2I0eOlGOVlY9LwpUk/fnP5lAGSZo2Tfr3v0v5ggAAVCH2XquePaXAQGtrAaoISyey1K5dW56enkpOTnY6npycrLCwsDzPCQsLK1J7e7A6dOiQ/ve//xU4PtLHx0c+Pj4lvApcyX6vq/37zWlT+YzGLJpRo6SjR6VZs6QHHpDCwqR+/VxQJQAAlRxDAoFyZ2nPlbe3tzp16qQN9iVCZS5osWHDBsXExOR5TkxMjFN7SVq3bp1Te3uw2r9/v9avX69a3DCvXNWuLTVpYu4X635X+XnmGWnYMCk7W7r9dqmQpfoBAKjyUlOlr7829/mlJFBuLB8WOGHCBC1cuFBvvfWWEhMT9dBDDyktLU0jR46UJA0bNkxTp051tB83bpzWrl2rOXPmaM+ePZo5c6a2bt2q0aNHSzKD1W233aatW7fqvffeU3Z2tpKSkpSUlKTMzExLrrEqctnQQMmcd/Xmm1JsrLmcbP/+0s8/u+CFAQCopNavl7KypObNzQ1AubA8XA0ZMkTPP/+8pk+frqioKO3YsUNr1651LFpx+PBhHT9+3NG+e/fuWrJkiRYsWKAOHTroww8/1IoVK9S2bVtJ0tGjR7Vy5Ur99ttvioqKUr169Rzb5s2bLbnGqsgerlzScyVJ1apJH34odeoknTplBq0rhocCAIA/MCQQsITl97mqiLjPVel9+aV0443m/YAPH3bhCycnS927m6sfdeokbdzIJF0AAHLLfdPJzz+XbrrJ6ooAt+Y297lC5XXtteZoviNHXNzBFBoqrV1rTuzatk267TZz2AMAADBt324Gq4AA6YYbrK4GqFIIVygT1atLrVqZ+y6Zd5Vb8+bmcAd/f+mzz6S//pWbDAMAYGcfEnjTTRKrIQPlinCFMmNfkt3l4UqSunaVPvhA8vSU3n5bevzxMngTAADc0OrV5iOrBALljnCFMuPSFQPz0r+/tGCBuf/ss9Lrr5fRGwEA4CZOnpS++87cJ1wB5Y5whTKTO1yV2ai9e++VnnzS3B89Wlq+vIzeCAAAN7B2rfmfblSUVL++1dUAVQ7hCmWmQwfJy8tcOf3QoTJ8o8cfl/72N/M/k6FDpW++KcM3AwCgArPPt6LXCrAE4QplxtdXat/e3C+zoYGSuSzh3LnSwIFSRob5uHt3Gb4hAAAV0KVL5kJPEve3AixCuEKZKvN5V3ZeXtJ//iPFxEhnzkh9+khHj5bxmwIAUIHEx0tnz0o1a0rR0VZXA1RJhCuUqXILV5K5NPunn0otW5o32OrbV0pJKYc3BgCgArAPCezTx1xNF0C5I1yhTNnD1bZtUk5OObxhrVrmZN6wMGnnTikuzhwqCABAZWdfgp0hgYBlCFcoU61bS35+0rlz0r595fSmjRtLa9aYdzLeuFEaPryckh0AABY5fNj8paKHh9lzBcAShCuUKS8v6dprzf1yGRpoFxVlLsterZq0dKk0aVI5vjkAAOXM3msVE2POuQJgCcIVylznzuZjuYYrSerVS1q82Nx/8UVpzpxyLgAAgHJiD1cswQ5YinCFMleui1pc6a67pOeeM/cnTTJXFAQAoDJJT5c2bDD3mW8FWIpwhTJnD1c7dkhZWRYUMHGiNH68uT98+OX/gAAAqAw2bpQuXJDq1798g0kAliBcocw1ayYFB5u/WNu1y4ICbDZzSOAdd5jpbvBg6YcfLCgEAIAykHtIoM1mbS1AFUe4Qpnz8LBw3lXuIt5+W7rxRnPpwr59pYMHLSoGAAAXMYzL97diSCBgOcIVykXXrubjrFnS1q0WFeHjY64g2K6ddPy4uVTt779bVAwAAC6wd6/066+St7e5kBMASxGuUC4eesi8/dTBg1L37tKrr5q/bCt3ISHmPbAiIsz/kAYOlC5etKAQAABcwD4ksGdPKTDQ2loAEK5QPiIipO3bzelOWVnS2LHS7bdLKSkWFFO/vhmwQkKkzZuloUOl7GwLCgEAoJQYEghUKIQrlJuQEOmjj6SXXjLv7fvRR+YNhhMSLCimTRtp5UpzqOAnn0ijR1vUlQYAQAmlpkpffWXuE66ACoFwhXJls0njxknffCM1amQOE4+JkV5/3YJsc/310pIlZlHz50vPPlvOBQAAUArr10uXLknNm5tL8wKwHOEKluja1RwmOGiQlJkpjRolDRliwTDBP//ZnAAmSY8/Li1aVM4FAABQQgwJBCocwhUsU6OGuXjfCy9IXl7SsmVSp04WDBMcNUqaOtXcv/9+cz4WAAAVWU7O5cUsCFdAhUG4gqVsNumRR8xhgg0bSr/8Yg4TnDevnIcJPvOMNGyYubDFbbdZeEMuAACKYPt2KSlJCggwh7kDqBAIV6gQoqPN/ycGDDCHCT78sLmIX2pqORVgs0lvvinFxkoXLpi/Bfz553J6cwAAisnea3XTTebiTAAqBMIVKoyaNc2F++bMMYcJLl1qDhPcsaOcCqhW7fLYxJMnzZsMnzhRTm8OAEAxMN8KqJAIV6hQbDZpwgRzZdmICLPzqFs36Y03ymmYYPXq5n9YTZqYYxT795fOny+HNwYAoIhOnpS2bDH3+/a1thYATghXqJBiYsweq1tukTIypAcflO66Szp3rhzePDRU+uwzqXZtaetW827HWVnl8MYAABTB2rXmbxyjoqT69a2uBkAuhCtUWPZhgs89J3l6Su+/b47Y++GHcnjz5s3NHix/f/M/sfvv5ybDAICKgSGBQIVFuEKF5uEhTZpkDhNs0EDav99c/GLBgnLIOl27Sh98YCa7t96Spk0r4zcEAKAQly6ZoyskwhVQARGu4Ba6dzeHCfbrZw4T/NvfpL/8pRyGCfbvbyY5yVyufd68Mn5DAAAKEB8vnT0r1apl/hIQQIVCuILbqFVL+vRT6Z//NDuTliyROneWfvyxjN/43nulJ58090eNMu98DACAFexDAvv0Mf8zBFChEK7gVjw8pEcflb780pzDu2+fOUzwzTfLeJjg449LDzxgvsldd0nr1zMHCwBQ/phvBVRohCu4pR49zGGCfftK6enmehPDhpXhquk2m/Taa9LAgeYb3nSTuejFpEnSN99I2dll9MYAAPzh8GFp1y7zN42xsVZXAyAPhCu4rdq1pVWrpFmzzJER775rDhPcubOM3tDLS/rPf6S775Z8fMz7YM2ZI11/vVSvnnTffea4xYsXy6gAAECVtnq1+RgTYy6pC6DCIVzBrXl4SFOmSF98YQ4T3LvXnN/7r3+V0ag9f38zxZ06JX34obmqRkiIeUPHf//b7NmqXVu69Vbp7bel338vgyIAAFUSQwKBCs9mGEwcuVJqaqqCg4OVkpKioKAgq8tBEZ08aQ4NXLvW/Pqee6TXX5cCA8v4jbOypK+/llasMLcjRy4/5+kp3XCDFBcnDRokNWpUxsUAACql9HSzt+riRXNcfIcOVlcEVBnFyQaEqzwQrtxXTo40e7a5/kROjhQZKS1bJrVtW04FGIb5n549aF25lGFUlBm04uKk9u3NuVwAABRm7VpzonGDBubcK/7/AMpNcbIBwwJRqXh4SFOnmsMEw8OlPXvMYYKLFpVTATab1LGj9MQT0g8/mPOyXnhB6tnTLG7HDmnmTDNkNWkijR8vbdxo3hQSAID82IcE9utHsAIqMHqu8kDPVeVw4oQ5NPDzz82vhw83F/wLCLCooFOnzBU4Vqwwi8q98EXNmtItt5g9WjffbGGRAIAKxzCkpk2lAwfM/0MGDbK6IqBKYVhgKRGuKo+cHHM1wenTzf1Wrcxhgm3aWFzYhQvSunXmf5Kffuq88IWvrxmw4uLMwFWnjlVVAgAqgj17zP/AvL3N/y/KfDIxgNwYFgj8wcND+vvfpf/9z1wtPTHRHCb41lsWF+bvb/7mcdEiKSnJHBr4yCNS48bmpOWVK6V775XCwswFMV54wRxiCACoeuxDAm+8kWAFVHCEK1QJPXua051uusnsNBoxQho50ty3nJeXWeALL0i//mrO1XriCenaa83utq+/liZOlJo1k9q1k6ZNk7ZtK6O15gEAFU7u+VYAKjSGBeaBYYGVV3a2OUxwxgwzt7RpI33wgdS6tdWV5ePQIbMXa8UK6csvzQuwa9DA7P2KizPDWbVqVlUJACgrqalSrVrmwkf795u/aANQrtxqWOBrr72mxo0by9fXV9HR0dqyZUuB7ZctW6bIyEj5+vqqXbt2Wm2/W/kfPv74Y918882qVauWbDabduzYUYbVw914eprLtK9fb464++knqUsX836/FVKjRtKYMdKGDeYKHW+/bd6g2N9f+u03c4WOm26S6tY1b2i8bJl07pzVVQMAXGXdOjNYtWhBsALcgKXhaunSpZowYYJmzJihhIQEdejQQbGxsTpx4kSe7Tdv3qyhQ4fqvvvu0/bt2xUXF6e4uDjt2rXL0SYtLU3XXXedZs+eXV6XATf0pz+ZwwR79TKHBg4fLt13XwUZJpifmjXN5Q8//NBcefDTT82i69SRzp6V3ntPuuMOqXZtqX9/aeFCcz4XAMB9MSQQcCuWDguMjo5Wly5dNHfuXElSTk6OIiIiNGbMGE2ZMuWq9kOGDFFaWppWrVrlONatWzdFRUVp/vz5Tm0PHjyoJk2aaPv27YqKiipWXQwLrDqys6VnnjFvPWUY5s2Gly0zbz7sNrKzpW+/NYcOLl/uvPCFzSZ163b5xsUtWlhUJACg2HJypPr1zV+UrVsn9e5tdUVAleQWwwIzMzO1bds29c71D4WHh4d69+6t+Pj4PM+Jj493ai9JsbGx+bYvqoyMDKWmpjptqBo8Pc1l2tevl0JDpV27pM6dpXfftbqyYvD0lHr0kJ57zhyPv2uXmRi7dDETY3y8NHmy1LKlObls6lTpu+/M/7QBABXX9u1msAoMNFeOBVDhWRauTp06pezsbIWGhjodDw0NVVI+Q5mSkpKK1b6oZs2apeDgYMcWERFRqteD+/l//88cJvj//p+UlmaOvrv/fuf7/LoFm81cpeOxx6QtW6QjR8x5WTffbK5KmJgo/eMfZm9WgwbSww9Lmzax8iAAVET2IYE33WTe4wpAhWf5ghYVwdSpU5WSkuLYjhw5YnVJsEBYmPT55+ZKgjab9OabUnS0ee9Gt2UPUJ99Jp08KS1ZYs7Lql5dOn5cmjdPuu46qXlz6cknzaXgAQAVg33RLuZbAW7DsnBVu3ZteXp6Kjk52el4cnKywsLC8jwnLCysWO2LysfHR0FBQU4bqiZPT3P+1bp15gJ8O3eawwSXLLG6MhcICZGGDpWWLjWD1urV5koeAQHmPK0ZM6SmTaXrrzcXwzh71uqKAaDqOnnSHIEgEa4AN2JZuPL29lanTp20YcMGx7GcnBxt2LBBMTExeZ4TExPj1F6S1q1bl297oKR69TKHCf7pT+Ywwbvvlh54wA2HCebHx0fq21davFhKTpbeecccdmKzSd98Y15sWJg0ZIg5LCUry+qKAaBqWbPGHLLdsaMUHm51NQCKyNJhgRMmTNDChQv11ltvKTExUQ899JDS0tI0cuRISdKwYcM0depUR/tx48Zp7dq1mjNnjvbs2aOZM2dq69atGj16tKPN6dOntWPHDu3evVuStHfvXu3YsaPU87JQ9dSrZ/ZgTZ9uZo6FC82pSnv3Wl2ZiwUEmPfI+vxz6fBhafZsc+GLjAzzDsu33GIOL3zkEXNyNfOzAKDsMSQQcEuWLsUuSXPnztVzzz2npKQkRUVF6ZVXXlF0dLQk6cYbb1Tjxo21ePFiR/tly5bp8ccf18GDB9W8eXP985//VL9c//AsXrzYEc5ymzFjhmbOnFmkmliKHVdat87svTp50ly0ado0s1erQ4dKOsfYMMwg9fbb5pjIkycvP9e2rbnix913m0sEAwBc69Kly/cw3LxZYoQOYKniZAPLw1VFRLhCXo4dk+66S/ryy8vHfH2lTp3M//e6dTMfK93ojawss1fr7belTz4xe7Qkszuvd29p2DBp8GCzBwwAUHpffSX17CnVqmUO3fb0tLoioEojXJUS4Qr5uXTJXGBv7Vrzvr2nT1/dJiLCOWx17GhOcaoUzp4177L89tvm3Cy7gADpttvMoHXjjZIHC5ECQIlNmWIO0b77bje78SJQORGuSolwhaIwDPOevfHx5vbtt+bqglfem9fbW7r2WufA1aCB2fHj1n791fxP/+23zdUG7SIizDlc99wjtWplXX0A4K7atTNvCL9kibnKKwBLEa5KiXCFkjp3Ttq69XLYio+XTp26ul14uHPYuvZayc+v/Ot1CcMwL/Ttt81l3nMv4d65s9mbdeed5vwBAEDBDh+WGjUyRwCcPCnVrGl1RUCVR7gqJcIVXMUwzA6e3GHrhx+k7GzndtWqSVFRzoGrUSM37N1KT5dWrTKD1po15jhKSfLyMle8GjbMXH2w0oyTBAAXmzfPvPl7jx7Ow68BWIZwVUqEK5SltDRp2zbnwHXFvbElSaGhzmGrUyc3WzPixAnp/ffNe2ht3Xr5eI0a5v2zhg0zL87tEiQAlKEBA8xfUj37rJTrdjQArEO4KiXCFcqTYUiHDjmHre3bL3f62Hl6mku/28NWt25S06Zukk127zZD1jvvSEePXj7erJk5N+uee6QmTayrDwAqgosXzRUCL140hzm0b291RQBEuCo1whWsdvGilJDgHLiOHbu6Xe3al8NWTIzUpYt5H64KKztb2rjRHDb40UdmN57d9debvVm33y4FB1tWIgBYZs0acwh1gwbm3Cu3+O0ZUPkRrkqJcIWKxjCk335zDlsJCVJmpnM7Dw9zkancvVstWlTQ/5/Pn5eWLzeD1oYN5kVK5s3DBg0yg9bNN5vztQCgKhgzRpo7V3rgAemNN6yuBsAfCFelRLiCO8jIMIcP2sNWfLx05MjV7WrWlKKjL4etrl0rYMfQb7+ZSw6/9ZY5hNCubl3zPi/33GOu+FEhUyIAuIBhmGO9Dxwwb9g+cKDVFQH4A+GqlAhXcFdHj5phyx64tm0zF/DLzWaTWrc2w1bnzua0p2uuMW9PZXknkWGYifHtt82wdfLk5efatjV7s+6+21zLHgAqk8RE8x9nb2/p998r+BhvoGohXJUS4QqVRWamOSfaHra+/db8pWhePD2lhg3NoJV7a9LEfKxZs5w7jrKypM8/N4PWJ5+YXXWSOfaxd28zaMXFudkSigCQjzlzpEmTzOHQn31mdTUAciFclRLhCpVZUpL03XeX77l14IB08ODl7JKfoCDnsJU7fDVuXMa3rjp7Vlq2zAxaue/7Ehgo3Xab9Je/mHdiDglh6CAA9/T//p/0xRfSyy9LY8daXQ2AXAhXpUS4QlWTkyMdP27e8PjXX83AZd//9VfzuYLYbFL9+vmHr7AwF2aeX36R3n3XDFq//ur8XGCg2f0WEeH8aN9v0MBcMAMAKpKUFHP510uXpP37zfHaACoMwlUpEa4AZxcvmr1b+YWv3Cuq58XP73Loyit8lWhkn2FImzeb98765BOzS64oQkOvDl25H0NDzaGHAFBePvrI7IVv0ULau9fqagBcgXBVSoQroOgMQzp1yjls5Q5fR46YPWMFqVs373le11xj9oh5ehahkAsXzFUHDx823/TwYef9I0fMNoWpVs3s4covfDVsaI6RBABXufdeadEi6ZFHpBdesLoaAFcgXJUS4QpwnawsM9vk1+t15kzB51erJjVqlH/4CgkpYiGGIZ0+XXD4Onq08CQomeHqyvCVe79+fXPFLwAoTE6OuQJqcrK0fr3Uq5fVFQG4AuGqlAhXQPk5e9Y5cOXeP3jQDGcFqVHDDFv2KVVXbvXrm8MSi+TSJenYsbzDl33/9OnCX8dmMyea5Re+GjaU6tRh8Q0A5j0zOnc254z+/ju/mAEqoOJkA6vvagOgigsJkTp2NLcrZWebWSe/IYfJyWbP15kzUkJC/u9Rq9bloJVXAGvQQKpeXeaNvuzhp0ePvF8sLa3g8HX4sLn04vHj5vbdd3m/jo+PGbauDF+hoWZiDAkxH2vUkPz9CWJAZfXf/5qPN91EsAIqAXqu8kDPFeAe0tIuL7Rx9Kg55Sr3VtRpVpI50q+wAFajRhEyjn0SWkHh6/hxs11RVat2OWzlDl1F2Q8KKuKkNQCWiI6WtmyR3nxTuu8+q6sBkAeGBZYS4QqoHAzDXOHYHrbyCmC//WYOTSwKP7/CA1idOkVYbDAz0+ySyyt8nTxpFmTvkrt0qXQfgs1mBqySBLOQkDK+gRlQxZ04YQ4hNgzzH6jwcKsrApAHhgUCgMxcERJibm3b5t/u/Hnn4JVXCDt50lySfv9+c8tPtWpm+CoogIWFecurcWPz7ssFMQyz680etHKHrqLsX7hwOWGmpBTvw7Pz8yt5j5mfn/mBMKQRyNvatebf0Y4dCVZAJUG4AlDlBQZKLVuaW37S083OpoIC2PHj5gIcBw+aW348PKR69fLuBQsONqd+VasmeXnZVK1agKpVC5CXVwNVqyV5hdqfMx9z79sfHVkmM/Ny2CosjF157OxZ84e+ixfN7dixkn24Npt542ZfXzNs5bVf2NfFaZv7a4IdKjr7fKv+/a2tA4DLMCwwDwwLBFASWVnmvYxzB64rQ9jRo6Uf6VcYT8+rA1dBYSyv56p55ihIqQrKOavgnDMKzjmjwEtnVT37jAKzzigw66wCMs/IP/OM/DPOyi/9jPzSz8gn/ax8L56R56XMsr3IorDZXBfi/PwK3+ztvL0JdShcVpY5jjglxbwhekyM1RUByAfDAgHAAtWqXV4AMD85OeY0i/zC17lzZvjKyrr8mHv/yse8fj2WnW1uGRmluRoPSSF/bI2Lea4hb2XKV+mOzU8X89z3VbqCvC6qerV0c/O6qECvdAV4psvfM13+tovyt6XL1/ZHe+OivHPSzS37oqplp8vrkrl5Zl6UZ2Z6rjL+GFZZ1FVNXMXDo+BAVtSwVpy2Xvx37nbi481gVbu21LWr1dUAcBH+NQaAcuThYc5fDwszb21TWtnZ+QevgkJZ2T5nU0aGjy5e9NHFi8GOfPP7H4/2kYYOl/7YLuZzkcViBrsrA5yfLirQM10hvukK9r6oIO90BXmnK9DLDHQBnmagC/C4KD9buvycwtxF+WRfVLVL5uZ16aIZ6DIvyjProjwzL8oj46Js9qSbk1P+oc7Ts/AA5uNj9qqV5+blVaxePMMw/0zb/zxd+efLft87f3/zkvz9zfzplh2F9iGBffqwoidQiRCuAMCNeXqam7st6peTY85ju5ArcNn3S3fMpgsXzGB37oKUnDvfZEtK+2NzucuhLvdmD3b2LdDj4h+9c+Z+oOdFR6AzH3Oda/yx5VyUT44Z8rxz0lXt0kWz1+5Srl667GxzZZbz58vi4kol0+atrD+2THkrS97KtHkr0/BWhi4/ZhjmlqmCtwz55IrN5pZTzVeGj6/TsE4Pf1/Z/HzlGeArjwBfVQs0972r+8jP3+YU0HLvF/To4+PCIGcPV/36uegFAVQEhCsAQLnz8Lj8Q21ZMozLIe7KYFbU8JaZaW4ZGc6Pzvtmb11mpo/SM0KU+sfzV82vy5GU+cdWSjblyEcZVwW6vEKdny7Kx4wyZbr55HFh3kamvI0ynoOX9cdWxGyZnkdAy72dka+O53E8Q7665OWrHO8/Nh9fycdXhq+v5Osnm58Z6jz8zSDnGeArr0Bz8w7yVbXqvvIN8lattMPq+9NPMjw89KVPrHL+Z/6SxMPj6se8jpXmOZvNTXv68mEY5i9rrnws6rHcz9lsZmdrfltl+txQdghXAIBKy76mhZ+fNe9vH+JWeDgryfMeysjwU2amX57Pp2ZKJ3Mds9nyWLjE1V97GfL2uGQGLZu5eStT1YzLAayaYW5eRqaq5Zj7ntmZ8sq5vHlkZ8rrUoY8sjPlkZUpW1am8weRkaGci+nKTktXTlq6ci6my/hjs6WnSxnpsmWkyyMzXZ5Z5hDO3MyYlCGpBLcosA9jLcWoz6w/fvz6Jqe7/nRrzZK/UAnZbK4LbPb7+hU1wLjyWHkvyebh4Ry27H/2XbG58rW8vC5/ZtnZ1u6X9jUaNZKWLi3f73NpEa4AACgj9mGbvr5WV1JebJKq/bEFlOk7efyxFYlhmCk3Pf3q7eLFvI/n2rLT0pV1Pl3Z58397AvpyrmQLuNCuoxc7eyBzh7qPLPMxVa8s9Odyqkms0tzY4N71K5G/j+QFvTDan4/kBb14yjrVUvdgYeHGTTtj/Y5f/l9jjk5lzM+ysfZs1ZXUHyEKwAAULnZbJcX2SjBLVY8/9hKzDDMn8hzhzYvL02rX1/TSvO6ebxN7oBQmqBW1Oeys50Dir0368pjFe25gob42a/t0qW8N/tCK67YyuK1srMvX3thPZDF3S/v86pXd+FfkHJCuAIAAChLNpu5GoaPj3mn8DJ8G3uAQMnZf8CvVs3qSuCO+OsHAAAAAC5AuAIAAAAAFyBcAQAAAIALEK4AAAAAwAUIVwAAAADgAoQrAAAAAHABwhUAAAAAuADhCgAAAABcgHAFAAAAAC5AuAIAAAAAFyBcAQAAAIALEK4AAAAAwAUIVwAAAADgAoQrAAAAAHCBChGuXnvtNTVu3Fi+vr6Kjo7Wli1bCmy/bNkyRUZGytfXV+3atdPq1audnjcMQ9OnT1e9evXk5+en3r17a//+/WV5CQAAAACqOMvD1dKlSzVhwgTNmDFDCQkJ6tChg2JjY3XixIk822/evFlDhw7Vfffdp+3btysuLk5xcXHatWuXo80///lPvfLKK5o/f76+++47BQQEKDY2Vunp6eV1WQAAAACqGJthGIaVBURHR6tLly6aO3euJCknJ0cREREaM2aMpkyZclX7IUOGKC0tTatWrXIc69atm6KiojR//nwZhqHw8HBNnDhRkyZNkiSlpKQoNDRUixcv1p133nnVa2ZkZCgjI8PxdWpqqiIiIpSSkqKgoCBXXzIAAAAAN5Gamqrg4OAiZQNLe64yMzO1bds29e7d23HMw8NDvXv3Vnx8fJ7nxMfHO7WXpNjYWEf7AwcOKCkpyalNcHCwoqOj833NWbNmKTg42LFFRESU9tIAAAAAVDFeVr75qVOnlJ2drdDQUKfjoaGh2rNnT57nJCUl5dk+KSnJ8bz9WH5trjR16lRNmDDB8XVKSooaNmyo1NTU4l0QAAAAgErFngmKMuDP0nBVUfj4+MjHx8fxtf0DpAcLAAAAgCSdO3dOwcHBBbaxNFzVrl1bnp6eSk5OdjqenJyssLCwPM8JCwsrsL39MTk5WfXq1XNqExUVVaS6wsPDdeTIEVWvXl02m62ol4NC2OeyHTlyhLlsFQDfj4qH70nFw/ekYuH7UfHwPalY+H6UDcMwdO7cOYWHhxfa1tJw5e3trU6dOmnDhg2Ki4uTZC5osWHDBo0ePTrPc2JiYrRhwwaNHz/ecWzdunWKiYmRJDVp0kRhYWHasGGDI0ylpqbqu+++00MPPVSkujw8PNSgQYMSXxcKFhQUxF/4CoTvR8XD96Ti4XtSsfD9qHj4nlQsfD9cr7AeKzvLhwVOmDBBw4cPV+fOndW1a1e99NJLSktL08iRIyVJw4YNU/369TVr1ixJ0rhx49SzZ0/NmTNH/fv31/vvv6+tW7dqwYIFkiSbzabx48fr6aefVvPmzdWkSRNNmzZN4eHhjgAHAAAAAK5mebgaMmSITp48qenTpyspKUlRUVFau3atY0GKw4cPy8Pj8qKG3bt315IlS/T444/rscceU/PmzbVixQq1bdvW0eb//u//lJaWpgceeEBnz57Vddddp7Vr18rX17fcrw8AAABA1WB5uJKk0aNH5zsMcOPGjVcdu/3223X77bfn+3o2m01PPvmknnzySVeVCBfw8fHRjBkznBYPgXX4flQ8fE8qHr4nFQvfj4qH70nFwvfDepbfRBgAAAAAKgNLbyIMAAAAAJUF4QoAAAAAXIBwBQAAAAAuQLgCAAAAABcgXKFMzZo1S126dFH16tVVt25dxcXFae/evVaXhVz+8Y9/OO4PB2scPXpUf/nLX1SrVi35+fmpXbt22rp1q9VlVVnZ2dmaNm2amjRpIj8/PzVt2lRPPfWUWP+p/Hz11VcaMGCAwsPDZbPZtGLFCqfnDcPQ9OnTVa9ePfn5+al3797av3+/NcVWEQV9T7KysjR58mS1a9dOAQEBCg8P17Bhw3Ts2DHrCq7kCvs7ktuDDz4om82ml156qdzqq8oIVyhTX375pUaNGqVvv/1W69atU1ZWlm6++WalpaVZXRokff/993rjjTfUvn17q0upss6cOaMePXqoWrVqWrNmjXbv3q05c+aoRo0aVpdWZc2ePVvz5s3T3LlzlZiYqNmzZ+uf//ynXn31VatLqzLS0tLUoUMHvfbaa3k+/89//lOvvPKK5s+fr++++04BAQGKjY1Venp6OVdadRT0Pblw4YISEhI0bdo0JSQk6OOPP9bevXs1cOBACyqtGgr7O2K3fPlyffvttwoPDy+nysBS7ChXJ0+eVN26dfXll1/qhhtusLqcKu38+fO69tpr9frrr+vpp59WVFQUv9WywJQpU7Rp0yZ9/fXXVpeCP9xyyy0KDQ3Vv/71L8exW2+9VX5+fnr33XctrKxqstlsWr58ueLi4iSZvVbh4eGaOHGiJk2aJElKSUlRaGioFi9erDvvvNPCaquGK78nefn+++/VtWtXHTp0SA0bNiy/4qqg/L4fR48eVXR0tD777DP1799f48ePZ5RKOaDnCuUqJSVFklSzZk2LK8GoUaPUv39/9e7d2+pSqrSVK1eqc+fOuv3221W3bl117NhRCxcutLqsKq179+7asGGD9u3bJ0n64Ycf9M0336hv374WVwZJOnDggJKSkpz+7QoODlZ0dLTi4+MtrAy5paSkyGazKSQkxOpSqqScnBzdc889evTRR9WmTRury6lSvKwuAFVHTk6Oxo8frx49eqht27ZWl1Olvf/++0pISND3339vdSlV3q+//qp58+ZpwoQJeuyxx/T9999r7Nix8vb21vDhw60ur0qaMmWKUlNTFRkZKU9PT2VnZ+uZZ57R3XffbXVpkJSUlCRJCg0NdToeGhrqeA7WSk9P1+TJkzV06FAFBQVZXU6VNHv2bHl5eWns2LFWl1LlEK5QbkaNGqVdu3bpm2++sbqUKu3IkSMaN26c1q1bJ19fX6vLqfJycnLUuXNnPfvss5Kkjh07ateuXZo/fz7hyiIffPCB3nvvPS1ZskRt2rTRjh07NH78eIWHh/M9AQqRlZWlO+64Q4ZhaN68eVaXUyVt27ZNL7/8shISEmSz2awup8phWCDKxejRo7Vq1Sp98cUXatCggdXlVGnbtm3TiRMndO2118rLy0teXl768ssv9corr8jLy0vZ2dlWl1il1KtXT61bt3Y61qpVKx0+fNiiivDoo49qypQpuvPOO9WuXTvdc889euSRRzRr1iyrS4OksLAwSVJycrLT8eTkZMdzsIY9WB06dEjr1q2j18oiX3/9tU6cOKGGDRs6/p8/dOiQJk6cqMaNG1tdXqVHzxXKlGEYGjNmjJYvX66NGzeqSZMmVpdU5fXq1Us7d+50OjZy5EhFRkZq8uTJ8vT0tKiyqqlHjx5X3Z5g3759atSokUUV4cKFC/LwcP7do6enp3JyciyqCLk1adJEYWFh2rBhg6KioiRJqamp+u677/TQQw9ZW1wVZg9W+/fv1xdffKFatWpZXVKVdc8991w1nzo2Nlb33HOPRo4caVFVVQfhCmVq1KhRWrJkiT755BNVr17dMR4+ODhYfn5+FldXNVWvXv2qOW8BAQGqVasWc+Es8Mgjj6h79+569tlndccdd2jLli1asGCBFixYYHVpVdaAAQP0zDPPqGHDhmrTpo22b9+uF154Qffee6/VpVUZ58+f188//+z4+sCBA9qxY4dq1qyphg0bavz48Xr66afVvHlzNWnSRNOmTVN4eHiBq9ehdAr6ntSrV0+33XabEhIStGrVKmVnZzv+v69Zs6a8vb2tKrvSKuzvyJXhtlq1agoLC1PLli3Lu9SqxwDKkKQ8t0WLFlldGnLp2bOnMW7cOKvLqLI+/fRTo23btoaPj48RGRlpLFiwwOqSqrTU1FRj3LhxRsOGDQ1fX1/jmmuuMf7+978bGRkZVpdWZXzxxRd5/t8xfPhwwzAMIycnx5g2bZoRGhpq+Pj4GL169TL27t1rbdGVXEHfkwMHDuT7//0XX3xhdemVUmF/R67UqFEj48UXXyzXGqsq7nMFAAAAAC7AghYAAAAA4AKEKwAAAABwAcIVAAAAALgA4QoAAAAAXIBwBQAAAAAuQLgCAAAAABcgXAEAAACACxCuAAAAAMAFCFcAAJSSzWbTihUrrC4DAGAxwhUAwK2NGDFCNpvtqq1Pnz5WlwYAqGK8rC4AAIDS6tOnjxYtWuR0zMfHx6JqAABVFT1XAAC35+Pjo7CwMKetRo0akswhe/PmzVPfvn3l5+ena665Rh9++KHT+Tt37tT/+3//T35+fqpVq5YeeOABnT9/3qnNv//9b7Vp00Y+Pj6qV6+eRo8e7fT8qVOnNHjwYPn7+6t58+ZauXKl47kzZ87o7rvvVp06deTn56fmzZtfFQYBAO6PcAUAqPSmTZumW2+9VT/88IPuvvtu3XnnnUpMTJQkpaWlKTY2VjVq1ND333+vZcuWaf369U7had68eRo1apQeeOAB7dy5UytXrlSzZs2c3uOJJ57QHXfcoR9//FH9+vXT3XffrdOnTzvef/fu3VqzZo0SExM1b9481a5du/w+AABAubAZhmFYXQQAACU1YsQIvfvuu/L19XU6/thjj+mxxx6TzWbTgw8+qHnz5jme69atm6699lq9/vrrWrhwoSZPnqwjR44oICBAkrR69WoNGDBAx44dU2hoqOrXr6+RI0fq6aefzrMGm82mxx9/XE899ZQkM7AFBgZqzZo16tOnjwYOHKjatWvr3//+dxl9CgCAioA5VwAAt/enP/3JKTxJUs2aNR37MTExTs/FxMRox44dkqTExER16NDBEawkqUePHsrJydHevXtls9l07Ngx9erVq8Aa2rdv79gPCAhQUFCQTpw4IUl66KGHdOuttyohIUE333yz4uLi1L179xJdKwCg4iJcAQDcXkBAwFXD9FzFz8+vSO2qVavm9LXNZlNOTo4kqW/fvjp06JBWr16tdevWqVevXho1apSef/55l9cLALAOc64AAJXet99+e9XXrVq1kiS1atVKP/zwg9LS0hzPb9q0SR4eHmrZsqWqV6+uxo0ba8OGDaWqoU6dOho+fLjeffddvfTSS1qwYEGpXg8AUPHQcwUAcHsZGRlKSkpyOubl5eVYNGLZsmXq3LmzrrvuOr333nvasmWL/vWvf0mS7r77bs2YMUPDhw/XzJkzdfLkSY0ZM0b33HOPQkNDJUkzZ87Ugw8+qLp166pv3746d+6cNm3apDFjxhSpvunTp6tTp076/+3cLY7CQACG4Q9DQjWmJyApGskdSMDXY2owXAKOQR0GATdBcgxwKzYhWbdisj/N88gRkxn5Zn7m83ler1cul8s77gAYDnEFwL93vV5T1/WXsdlslvv9nuTzJ7++77PdblPXdU6nU5qmSZJUVZXb7Zau67JYLFJVVdbrdQ6Hw3uutm3zfD5zPB6z2+0ynU6z2Wy+vb7xeJz9fp/H45HJZJLlcpm+7wvsHIC/xG+BAAzaaDTK+XzOarX67aUAMHDeXAEAABQgrgAAAArw5gqAQXP7HYCf4uQKAACgAHEFAABQgLgCAAAoQFwBAAAUIK4AAAAKEFcAAAAFiCsAAIACxBUAAEABHy9HY+csBqd4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss1 = history1.history['loss']\n",
        "loss2 = history2.history['loss']\n",
        "\n",
        "# Plotting the loss values\n",
        "epochs = range(1, len(loss1) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting model1 loss\n",
        "plt.plot(epochs, loss1, 'b-', label='Training Loss - Existing')\n",
        "\n",
        "# Plotting model2 loss\n",
        "plt.plot(epochs, loss2, 'r-', label='Training Loss - Proposed')\n",
        "\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLJBK8TX8ABE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "cbe31c8e-b332-47a0-f61f-b7df3511782f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "val_loss1 = history1.history['val_loss']\n",
        "val_loss2 = history2.history['val_loss']\n",
        "\n",
        "# Plotting the validation loss values\n",
        "epochs = range(1, len(val_loss1) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting model1 validation loss\n",
        "plt.plot(epochs, val_loss1, 'b-', label='Validation Loss - Existing')\n",
        "\n",
        "# Plotting model2 validation loss\n",
        "plt.plot(epochs, val_loss2, 'r-', label='Validation Loss - Proposed')\n",
        "\n",
        "plt.title('Validation Loss Comparison')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx9dzT1cztop"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def iou_metric(y_true_in, y_pred_in):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "\n",
        "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
        "\n",
        "    intersection = temp1[0]\n",
        "\n",
        "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
        "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    intersection[intersection == 0] = 1e-9\n",
        "\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    iou = intersection / union\n",
        "    return iou\n",
        "\n",
        "def dice_metric(y_true_in, y_pred_in):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "\n",
        "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
        "\n",
        "    intersection = temp1[0]\n",
        "\n",
        "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
        "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    intersection[intersection == 0] = 1e-9\n",
        "\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    dice_m = (2*intersection) / union\n",
        "    return dice_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2gbybWx7JTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "886645c9-cf98-4637-8e7c-76df480e6ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting the masks ===========>\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Joining the segmented patches to original sized masks ===========>\n",
            "Writing segmented masks to image files ===========>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 540.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented images are saved in /content/results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for the segmented output ===========>\n",
            "ID-4  IOU: 0.764, DICE: 0.866\n",
            "ID-4  IOU: 0.758, DICE: 0.862\n",
            "ID-4  IOU: 0.673, DICE: 0.805\n",
            "mean of jaccard:  0.7316506413218972\n",
            "mean of dice:  0.8443593690851073\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "import cv2\n",
        "import warnings\n",
        "import tensorflow\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.callbacks import *\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "warnings.filterwarnings('ignore')\n",
        "# Path for the stain normalized image patches normalized image\n",
        "test_data_path = '/content/TestData/'\n",
        "# Path to the full sized test mask for score computation\n",
        "gt_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Test/label/'\n",
        "# Path to model weight and weight name\n",
        "model_path = '/content/checkpoint'\n",
        "weight_name = 'nuclei_seg_og.h5'\n",
        "# Path to save the segmented masks\n",
        "if not os.path.exists(\"/content/results\"):\n",
        "    os.mkdir(\"/content/results\")\n",
        "sv_path = '/content/results'\n",
        "\n",
        "# used height and widht for patch\n",
        "img_width_p = 256\n",
        "img_height_p = 256\n",
        "# Full image size\n",
        "img_width_f = 512\n",
        "img_height_f = 512\n",
        "\n",
        "test_generator = DataGeneratorFolder(root_dir = test_data_path,\n",
        "                                    image_folder = 'tis/',\n",
        "                                    mask_folder = 'Bin/',\n",
        "                                    batch_size=1,augmentation = None,\n",
        "                                    image_size=img_width_p,\n",
        "                                    nb_y_features = 1)\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "model.load_weights(os.path.join(model_path,weight_name))\n",
        "\n",
        "out_im = []\n",
        "\n",
        "print('Predicting the masks ===========>')\n",
        "for tes in test_generator:\n",
        "    # Xtest_n, y_test_n  = test_generator.__getitem__(tes)\n",
        "    Xtest_n, y_test_n = tes[0], tes[1]\n",
        "    predicted = model.predict(np.expand_dims(Xtest_n[0], axis=0)).reshape(img_width_p, img_height_p)\n",
        "    predicted1= predicted.flatten()\n",
        "    predicted1[predicted1>=0.5]=1\n",
        "    predicted1[predicted1<0.5]=0\n",
        "    predicted2 = predicted1.reshape((img_width_p, img_height_p))\n",
        "    predicted2 = np.expand_dims(predicted2, -1)\n",
        "    out_im.append(predicted2)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Creating full sized segmented image (actual size) from segmented patches\n",
        "print('Joining the segmented patches to original sized masks ===========>')\n",
        "out_full,ids_test = patch_join(out_im)\n",
        "\n",
        "# Writing the masks as image filee to folder\n",
        "print('Writing segmented masks to image files ===========>')\n",
        "for n, id_ in tqdm(enumerate(ids_test), total=len(ids_test)):\n",
        "\n",
        "    imgs = np.reshape(out_full[n]*255,(img_width_f,img_height_f))\n",
        "    filename = '{}/{}.png'.format(sv_path,os.path.splitext(id_)[0])\n",
        "    cv2.imwrite(filename, imgs)\n",
        "\n",
        "print('Segmented images are saved in {}'.format(sv_path))\n",
        "\n",
        "cv2_imshow(out_full[0]*255)\n",
        "\n",
        "# Computing scores (DICE and IOU)\n",
        "print('Scores for the segmented output ===========>')\n",
        "scr_met = {'IOU':[],'DICE':[]}\n",
        "\n",
        "for _,i in enumerate(ids_test):\n",
        "\n",
        "    gt = gt_path+os.path.splitext(i)[0]+'.png'\n",
        "    plabel = os.path.join(sv_path,os.path.splitext(i)[0]+'.png')\n",
        "\n",
        "    true   = cv2.imread(gt,0)\n",
        "    _, true = cv2.threshold(true, 128, 255, cv2.THRESH_BINARY)\n",
        "    true = true.astype(bool)\n",
        "    pred_1 = cv2.imread(plabel,0).astype(bool)\n",
        "\n",
        "    dice_coeff = dice_metric(true,pred_1)\n",
        "    jacc_f = iou_metric(true,pred_1)\n",
        "\n",
        "    scr_met['IOU'].append(jacc_f.item())\n",
        "    scr_met['DICE'].append(dice_coeff.item())\n",
        "    print('ID-{}  IOU: {:.3}, DICE: {:.3}'.format(os.path.splitext(id_)[0],jacc_f.item(),dice_coeff.item()))\n",
        "\n",
        "\n",
        "print(\"mean of jaccard: \",mean(scr_met['IOU']))\n",
        "print(\"mean of dice: \",mean(scr_met['DICE']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWTcbC2_8IL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf7ea31b-e7fe-45e5-dba4-c78bae6c5174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"patches_9/ExtractImagePatches:0\", shape=(None, 32, 32, 192), dtype=float32)\n",
            "(None, 1024, 192)\n",
            "(None, 32, 32, 256)\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_320 (Conv2D)         (None, 256, 256, 32)         896       ['input_15[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_248 (B  (None, 256, 256, 32)         128       ['conv2d_320[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " separable_conv2d_32 (Separ  (None, 256, 256, 32)         1344      ['batch_normalization_248[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_249 (B  (None, 256, 256, 32)         128       ['separable_conv2d_32[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_321 (Conv2D)         (None, 256, 256, 32)         9248      ['batch_normalization_249[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_250 (B  (None, 256, 256, 32)         128       ['conv2d_321[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.concat_64 (TFOpLambda)   (None, 256, 256, 35)         0         ['input_15[0][0]',            \n",
            "                                                                     'batch_normalization_250[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_322 (Conv2D)         (None, 256, 256, 32)         10112     ['tf.concat_64[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_251 (B  (None, 256, 256, 32)         128       ['conv2d_322[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_32 (MaxPooli  (None, 128, 128, 32)         0         ['batch_normalization_251[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " conv2d_323 (Conv2D)         (None, 128, 128, 64)         18496     ['max_pooling2d_32[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_252 (B  (None, 128, 128, 64)         256       ['conv2d_323[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " separable_conv2d_33 (Separ  (None, 128, 128, 64)         4736      ['batch_normalization_252[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_253 (B  (None, 128, 128, 64)         256       ['separable_conv2d_33[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_324 (Conv2D)         (None, 128, 128, 64)         36928     ['batch_normalization_253[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_254 (B  (None, 128, 128, 64)         256       ['conv2d_324[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.concat_65 (TFOpLambda)   (None, 128, 128, 96)         0         ['max_pooling2d_32[0][0]',    \n",
            "                                                                     'batch_normalization_254[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_325 (Conv2D)         (None, 128, 128, 64)         55360     ['tf.concat_65[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_255 (B  (None, 128, 128, 64)         256       ['conv2d_325[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " patches_9 (Patches)         (None, 1024, 192)            0         ['input_15[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_33 (MaxPooli  (None, 64, 64, 64)           0         ['batch_normalization_255[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " patch_encoder_9 (PatchEnco  (None, 1024, 256)            311552    ['patches_9[0][0]']           \n",
            " der)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_326 (Conv2D)         (None, 64, 64, 128)          73856     ['max_pooling2d_33[0][0]']    \n",
            "                                                                                                  \n",
            " layer_normalization_38 (La  (None, 1024, 256)            512       ['patch_encoder_9[0][0]']     \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_256 (B  (None, 64, 64, 128)          512       ['conv2d_326[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_18 (M  (None, 1024, 256)            2103552   ['layer_normalization_38[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_34 (Separ  (None, 64, 64, 128)          17664     ['batch_normalization_256[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " add_92 (Add)                (None, 1024, 256)            0         ['multi_head_attention_18[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'patch_encoder_9[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_257 (B  (None, 64, 64, 128)          512       ['separable_conv2d_34[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization_39 (La  (None, 1024, 256)            512       ['add_92[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_327 (Conv2D)         (None, 64, 64, 128)          147584    ['batch_normalization_257[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_76 (Dense)            (None, 1024, 512)            131584    ['layer_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_258 (B  (None, 64, 64, 128)          512       ['conv2d_327[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_68 (Dropout)        (None, 1024, 512)            0         ['dense_76[0][0]']            \n",
            "                                                                                                  \n",
            " tf.concat_66 (TFOpLambda)   (None, 64, 64, 192)          0         ['max_pooling2d_33[0][0]',    \n",
            "                                                                     'batch_normalization_258[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_77 (Dense)            (None, 1024, 256)            131328    ['dropout_68[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_328 (Conv2D)         (None, 64, 64, 128)          221312    ['tf.concat_66[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_69 (Dropout)        (None, 1024, 256)            0         ['dense_77[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_259 (B  (None, 64, 64, 128)          512       ['conv2d_328[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add_93 (Add)                (None, 1024, 256)            0         ['dropout_69[0][0]',          \n",
            "                                                                     'add_92[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_34 (MaxPooli  (None, 32, 32, 128)          0         ['batch_normalization_259[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " layer_normalization_40 (La  (None, 1024, 256)            512       ['add_93[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_329 (Conv2D)         (None, 32, 32, 256)          295168    ['max_pooling2d_34[0][0]']    \n",
            "                                                                                                  \n",
            " multi_head_attention_19 (M  (None, 1024, 256)            2103552   ['layer_normalization_40[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_260 (B  (None, 32, 32, 256)          1024      ['conv2d_329[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " add_94 (Add)                (None, 1024, 256)            0         ['multi_head_attention_19[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_93[0][0]']              \n",
            "                                                                                                  \n",
            " separable_conv2d_35 (Separ  (None, 32, 32, 256)          68096     ['batch_normalization_260[0][0\n",
            " ableConv2D)                                                        ]']                           \n",
            "                                                                                                  \n",
            " layer_normalization_41 (La  (None, 1024, 256)            512       ['add_94[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_261 (B  (None, 32, 32, 256)          1024      ['separable_conv2d_35[0][0]'] \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_78 (Dense)            (None, 1024, 512)            131584    ['layer_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_330 (Conv2D)         (None, 32, 32, 256)          590080    ['batch_normalization_261[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_70 (Dropout)        (None, 1024, 512)            0         ['dense_78[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_262 (B  (None, 32, 32, 256)          1024      ['conv2d_330[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_79 (Dense)            (None, 1024, 256)            131328    ['dropout_70[0][0]']          \n",
            "                                                                                                  \n",
            " tf.concat_67 (TFOpLambda)   (None, 32, 32, 384)          0         ['max_pooling2d_34[0][0]',    \n",
            "                                                                     'batch_normalization_262[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_71 (Dropout)        (None, 1024, 256)            0         ['dense_79[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_331 (Conv2D)         (None, 32, 32, 256)          884992    ['tf.concat_67[0][0]']        \n",
            "                                                                                                  \n",
            " add_95 (Add)                (None, 1024, 256)            0         ['dropout_71[0][0]',          \n",
            "                                                                     'add_94[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_263 (B  (None, 32, 32, 256)          1024      ['conv2d_331[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_50 (Reshape)        (None, 32, 32, 256)          0         ['add_95[0][0]']              \n",
            "                                                                                                  \n",
            " add_96 (Add)                (None, 32, 32, 256)          0         ['reshape_50[0][0]',          \n",
            "                                                                     'batch_normalization_263[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_35 (MaxPooli  (None, 16, 16, 256)          0         ['batch_normalization_263[0][0\n",
            " ng2D)                                                              ]']                           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 256)                  0         ['add_96[0][0]']              \n",
            " 2 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " conv2d_332 (Conv2D)         (None, 16, 16, 512)          1180160   ['max_pooling2d_35[0][0]']    \n",
            "                                                                                                  \n",
            " dense_80 (Dense)            (None, 512)                  131584    ['global_average_pooling2d_12[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " batch_normalization_264 (B  (None, 16, 16, 512)          2048      ['conv2d_332[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_72 (Dropout)        (None, 512)                  0         ['dense_80[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_333 (Conv2D)         (None, 16, 16, 512)          2359808   ['batch_normalization_264[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dense_81 (Dense)            (None, 256)                  131328    ['dropout_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_265 (B  (None, 16, 16, 512)          2048      ['conv2d_333[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_73 (Dropout)        (None, 256)                  0         ['dense_81[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_334 (Conv2D)         (None, 16, 16, 512)          2359808   ['batch_normalization_265[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_44 (TFOpLa  (None, 256)                  0         ['dropout_73[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_266 (B  (None, 16, 16, 512)          2048      ['conv2d_334[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_51 (Reshape)        (None, 1, 1, 256)            0         ['tf.math.sigmoid_44[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_56 (Multiply)      (None, 32, 32, 256)          0         ['reshape_50[0][0]',          \n",
            "                                                                     'reshape_51[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_57 (Multiply)      (None, 32, 32, 256)          0         ['batch_normalization_263[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_335 (Conv2D)         (None, 16, 16, 256)          131328    ['batch_normalization_266[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_97 (Add)                (None, 32, 32, 256)          0         ['multiply_56[0][0]',         \n",
            "                                                                     'multiply_57[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_337 (Conv2D)         (None, 16, 16, 128)          295040    ['conv2d_335[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_336 (Conv2D)         (None, 32, 32, 128)          295040    ['add_97[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_32 (UpSampli  (None, 32, 32, 128)          0         ['conv2d_337[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_104 (Add)               (None, 32, 32, 128)          0         ['conv2d_336[0][0]',          \n",
            "                                                                     'up_sampling2d_32[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_32 (TFOpLambda)  (None, 32, 32, 128)          0         ['add_104[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_338 (Conv2D)         (None, 32, 32, 256)          33024     ['tf.nn.relu_32[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_267 (B  (None, 32, 32, 256)          1024      ['conv2d_338[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_41 (Conv2  (None, 64, 64, 128)          295040    ['reshape_50[0][0]']          \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_48 (TFOpLa  (None, 32, 32, 256)          0         ['batch_normalization_267[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_98 (Add)                (None, 64, 64, 128)          0         ['conv2d_transpose_41[0][0]', \n",
            "                                                                     'batch_normalization_259[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_44 (Conv2  (None, 32, 32, 256)          524544    ['batch_normalization_266[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_55 (Reshape)        (None, 32, 32, 256)          0         ['tf.math.sigmoid_48[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 128)                  0         ['add_98[0][0]']              \n",
            " 3 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " tf.slice_32 (TFOpLambda)    (None, 32, 32, 256)          0         ['conv2d_transpose_44[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_64 (Multiply)      (None, 32, 32, 256)          0         ['reshape_55[0][0]',          \n",
            "                                                                     'add_97[0][0]']              \n",
            "                                                                                                  \n",
            " dense_82 (Dense)            (None, 256)                  33024     ['global_average_pooling2d_13[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.concat_68 (TFOpLambda)   (None, 32, 32, 512)          0         ['tf.slice_32[0][0]',         \n",
            "                                                                     'multiply_64[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)        (None, 256)                  0         ['dense_82[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_339 (Conv2D)         (None, 32, 32, 256)          1179904   ['tf.concat_68[0][0]']        \n",
            "                                                                                                  \n",
            " dense_83 (Dense)            (None, 128)                  32896     ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_268 (B  (None, 32, 32, 256)          1024      ['conv2d_339[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)        (None, 128)                  0         ['dense_83[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_340 (Conv2D)         (None, 32, 32, 256)          590080    ['batch_normalization_268[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_45 (TFOpLa  (None, 128)                  0         ['dropout_75[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_269 (B  (None, 32, 32, 256)          1024      ['conv2d_340[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_52 (Reshape)        (None, 1, 1, 128)            0         ['tf.math.sigmoid_45[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_58 (Multiply)      (None, 64, 64, 128)          0         ['conv2d_transpose_41[0][0]', \n",
            "                                                                     'reshape_52[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_59 (Multiply)      (None, 64, 64, 128)          0         ['batch_normalization_259[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_341 (Conv2D)         (None, 32, 32, 128)          32896     ['batch_normalization_269[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_99 (Add)                (None, 64, 64, 128)          0         ['multiply_58[0][0]',         \n",
            "                                                                     'multiply_59[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_343 (Conv2D)         (None, 32, 32, 64)           73792     ['conv2d_341[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_342 (Conv2D)         (None, 64, 64, 64)           73792     ['add_99[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_33 (UpSampli  (None, 64, 64, 64)           0         ['conv2d_343[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_105 (Add)               (None, 64, 64, 64)           0         ['conv2d_342[0][0]',          \n",
            "                                                                     'up_sampling2d_33[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_33 (TFOpLambda)  (None, 64, 64, 64)           0         ['add_105[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_344 (Conv2D)         (None, 64, 64, 128)          8320      ['tf.nn.relu_33[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_270 (B  (None, 64, 64, 128)          512       ['conv2d_344[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_42 (Conv2  (None, 128, 128, 64)         73792     ['conv2d_transpose_41[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_49 (TFOpLa  (None, 64, 64, 128)          0         ['batch_normalization_270[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_100 (Add)               (None, 128, 128, 64)         0         ['conv2d_transpose_42[0][0]', \n",
            "                                                                     'batch_normalization_255[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_45 (Conv2  (None, 64, 64, 128)          131200    ['batch_normalization_269[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_56 (Reshape)        (None, 64, 64, 128)          0         ['tf.math.sigmoid_49[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['add_100[0][0]']             \n",
            " 4 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " tf.slice_33 (TFOpLambda)    (None, 64, 64, 128)          0         ['conv2d_transpose_45[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_65 (Multiply)      (None, 64, 64, 128)          0         ['reshape_56[0][0]',          \n",
            "                                                                     'add_99[0][0]']              \n",
            "                                                                                                  \n",
            " dense_84 (Dense)            (None, 128)                  8320      ['global_average_pooling2d_14[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.concat_69 (TFOpLambda)   (None, 64, 64, 256)          0         ['tf.slice_33[0][0]',         \n",
            "                                                                     'multiply_65[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)        (None, 128)                  0         ['dense_84[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_345 (Conv2D)         (None, 64, 64, 128)          295040    ['tf.concat_69[0][0]']        \n",
            "                                                                                                  \n",
            " dense_85 (Dense)            (None, 64)                   8256      ['dropout_76[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_271 (B  (None, 64, 64, 128)          512       ['conv2d_345[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)        (None, 64)                   0         ['dense_85[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_346 (Conv2D)         (None, 64, 64, 128)          147584    ['batch_normalization_271[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_46 (TFOpLa  (None, 64)                   0         ['dropout_77[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_272 (B  (None, 64, 64, 128)          512       ['conv2d_346[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_53 (Reshape)        (None, 1, 1, 64)             0         ['tf.math.sigmoid_46[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_60 (Multiply)      (None, 128, 128, 64)         0         ['conv2d_transpose_42[0][0]', \n",
            "                                                                     'reshape_53[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_61 (Multiply)      (None, 128, 128, 64)         0         ['batch_normalization_255[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_53[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_347 (Conv2D)         (None, 64, 64, 64)           8256      ['batch_normalization_272[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_101 (Add)               (None, 128, 128, 64)         0         ['multiply_60[0][0]',         \n",
            "                                                                     'multiply_61[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_349 (Conv2D)         (None, 64, 64, 32)           18464     ['conv2d_347[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_348 (Conv2D)         (None, 128, 128, 32)         18464     ['add_101[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_34 (UpSampli  (None, 128, 128, 32)         0         ['conv2d_349[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_106 (Add)               (None, 128, 128, 32)         0         ['conv2d_348[0][0]',          \n",
            "                                                                     'up_sampling2d_34[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_34 (TFOpLambda)  (None, 128, 128, 32)         0         ['add_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_350 (Conv2D)         (None, 128, 128, 64)         2112      ['tf.nn.relu_34[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_273 (B  (None, 128, 128, 64)         256       ['conv2d_350[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_43 (Conv2  (None, 256, 256, 32)         18464     ['conv2d_transpose_42[0][0]'] \n",
            " DTranspose)                                                                                      \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_50 (TFOpLa  (None, 128, 128, 64)         0         ['batch_normalization_273[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " add_102 (Add)               (None, 256, 256, 32)         0         ['conv2d_transpose_43[0][0]', \n",
            "                                                                     'batch_normalization_251[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_46 (Conv2  (None, 128, 128, 64)         32832     ['batch_normalization_272[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_57 (Reshape)        (None, 128, 128, 64)         0         ['tf.math.sigmoid_50[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 32)                   0         ['add_102[0][0]']             \n",
            " 5 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " tf.slice_34 (TFOpLambda)    (None, 128, 128, 64)         0         ['conv2d_transpose_46[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_66 (Multiply)      (None, 128, 128, 64)         0         ['reshape_57[0][0]',          \n",
            "                                                                     'add_101[0][0]']             \n",
            "                                                                                                  \n",
            " dense_86 (Dense)            (None, 64)                   2112      ['global_average_pooling2d_15[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " tf.concat_70 (TFOpLambda)   (None, 128, 128, 128)        0         ['tf.slice_34[0][0]',         \n",
            "                                                                     'multiply_66[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_78 (Dropout)        (None, 64)                   0         ['dense_86[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_351 (Conv2D)         (None, 128, 128, 64)         73792     ['tf.concat_70[0][0]']        \n",
            "                                                                                                  \n",
            " dense_87 (Dense)            (None, 32)                   2080      ['dropout_78[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_274 (B  (None, 128, 128, 64)         256       ['conv2d_351[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dropout_79 (Dropout)        (None, 32)                   0         ['dense_87[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_352 (Conv2D)         (None, 128, 128, 64)         36928     ['batch_normalization_274[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_47 (TFOpLa  (None, 32)                   0         ['dropout_79[0][0]']          \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_275 (B  (None, 128, 128, 64)         256       ['conv2d_352[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " reshape_54 (Reshape)        (None, 1, 1, 32)             0         ['tf.math.sigmoid_47[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_62 (Multiply)      (None, 256, 256, 32)         0         ['conv2d_transpose_43[0][0]', \n",
            "                                                                     'reshape_54[0][0]']          \n",
            "                                                                                                  \n",
            " multiply_63 (Multiply)      (None, 256, 256, 32)         0         ['batch_normalization_251[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'reshape_54[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_353 (Conv2D)         (None, 128, 128, 32)         2080      ['batch_normalization_275[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_103 (Add)               (None, 256, 256, 32)         0         ['multiply_62[0][0]',         \n",
            "                                                                     'multiply_63[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_355 (Conv2D)         (None, 128, 128, 16)         4624      ['conv2d_353[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_354 (Conv2D)         (None, 256, 256, 16)         4624      ['add_103[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_35 (UpSampli  (None, 256, 256, 16)         0         ['conv2d_355[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " add_107 (Add)               (None, 256, 256, 16)         0         ['conv2d_354[0][0]',          \n",
            "                                                                     'up_sampling2d_35[0][0]']    \n",
            "                                                                                                  \n",
            " tf.nn.relu_35 (TFOpLambda)  (None, 256, 256, 16)         0         ['add_107[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_356 (Conv2D)         (None, 256, 256, 32)         544       ['tf.nn.relu_35[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_276 (B  (None, 256, 256, 32)         128       ['conv2d_356[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " tf.math.sigmoid_51 (TFOpLa  (None, 256, 256, 32)         0         ['batch_normalization_276[0][0\n",
            " mbda)                                                              ]']                           \n",
            "                                                                                                  \n",
            " conv2d_transpose_47 (Conv2  (None, 256, 256, 32)         8224      ['batch_normalization_275[0][0\n",
            " DTranspose)                                                        ]']                           \n",
            "                                                                                                  \n",
            " reshape_58 (Reshape)        (None, 256, 256, 32)         0         ['tf.math.sigmoid_51[0][0]']  \n",
            "                                                                                                  \n",
            " tf.slice_35 (TFOpLambda)    (None, 256, 256, 32)         0         ['conv2d_transpose_47[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_67 (Multiply)      (None, 256, 256, 32)         0         ['reshape_58[0][0]',          \n",
            "                                                                     'add_103[0][0]']             \n",
            "                                                                                                  \n",
            " tf.concat_71 (TFOpLambda)   (None, 256, 256, 64)         0         ['tf.slice_35[0][0]',         \n",
            "                                                                     'multiply_67[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_357 (Conv2D)         (None, 256, 256, 32)         18464     ['tf.concat_71[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_277 (B  (None, 256, 256, 32)         128       ['conv2d_357[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_358 (Conv2D)         (None, 256, 256, 32)         9248      ['batch_normalization_277[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_278 (B  (None, 256, 256, 32)         128       ['conv2d_358[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_359 (Conv2D)         (None, 256, 256, 1)          33        ['batch_normalization_278[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18188929 (69.39 MB)\n",
            "Trainable params: 18179137 (69.35 MB)\n",
            "Non-trainable params: 9792 (38.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting the masks ===========>\n",
            "Tensor(\"model_14/patches_9/ExtractImagePatches:0\", shape=(None, 32, 32, 192), dtype=float32)\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "Joining the segmented patches to original sized masks ===========>\n",
            "Writing segmented masks to image files ===========>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 350.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented images are saved in /content/results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAADEUlEQVR4nO3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBvArQAAVkUTe8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores for the segmented output ===========>\n",
            "ID-4  IOU: 6.03e-14, DICE: 1.21e-13\n",
            "ID-4  IOU: 6.69e-14, DICE: 1.34e-13\n",
            "ID-4  IOU: 7.11e-14, DICE: 1.42e-13\n",
            "mean of jaccard:  6.610035104432106e-14\n",
            "mean of dice:  1.322007020886421e-13\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "import cv2\n",
        "import warnings\n",
        "import tensorflow\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.callbacks import *\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "warnings.filterwarnings('ignore')\n",
        "# Path for the stain normalized image patches normalized image\n",
        "test_data_path = '/content/TestData/'\n",
        "# Path to the full sized test mask for score computation\n",
        "gt_path = '/content/drive/MyDrive/NucleiSegNet/KMC_LIverSegmentation/Test/label/'\n",
        "# Path to model weight and weight name\n",
        "model_path = '/content/checkpoint'\n",
        "weight_name = 'nuclei_seg_modified.h5'\n",
        "# Path to save the segmented masks\n",
        "if not os.path.exists(\"/content/results\"):\n",
        "    os.mkdir(\"/content/results\")\n",
        "sv_path = '/content/results'\n",
        "\n",
        "# used height and widht for patch\n",
        "img_width_p = 256\n",
        "img_height_p = 256\n",
        "# Full image size\n",
        "img_width_f = 512\n",
        "img_height_f = 512\n",
        "\n",
        "test_generator = DataGeneratorFolder(root_dir = test_data_path,\n",
        "                                    image_folder = 'tis/',\n",
        "                                    mask_folder = 'Bin/',\n",
        "                                    batch_size=1,augmentation = None,\n",
        "                                    image_size=img_width_p,\n",
        "                                    nb_y_features = 1)\n",
        "\n",
        "\n",
        "model = create_model_modified()\n",
        "model.load_weights(os.path.join(model_path,weight_name))\n",
        "\n",
        "out_im = []\n",
        "\n",
        "print('Predicting the masks ===========>')\n",
        "for tes in test_generator:\n",
        "    # Xtest_n, y_test_n  = test_generator.__getitem__(tes)\n",
        "    Xtest_n, y_test_n = tes[0], tes[1]\n",
        "    predicted = model.predict(np.expand_dims(Xtest_n[0], axis=0)).reshape(img_width_p, img_height_p)\n",
        "    predicted1= predicted.flatten()\n",
        "    predicted1[predicted1>=0.5]=1\n",
        "    predicted1[predicted1<0.5]=0\n",
        "    predicted2 = predicted1.reshape((img_width_p, img_height_p))\n",
        "    predicted2 = np.expand_dims(predicted2, -1)\n",
        "    out_im.append(predicted2)\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Creating full sized segmented image (actual size) from segmented patches\n",
        "print('Joining the segmented patches to original sized masks ===========>')\n",
        "out_full,ids_test = patch_join(out_im)\n",
        "\n",
        "# Writing the masks as image filee to folder\n",
        "print('Writing segmented masks to image files ===========>')\n",
        "for n, id_ in tqdm(enumerate(ids_test), total=len(ids_test)):\n",
        "\n",
        "    imgs = np.reshape(out_full[n]*255,(img_width_f,img_height_f))\n",
        "    filename = '{}/{}.png'.format(sv_path,os.path.splitext(id_)[0])\n",
        "    cv2.imwrite(filename, imgs)\n",
        "\n",
        "print('Segmented images are saved in {}'.format(sv_path))\n",
        "\n",
        "cv2_imshow(out_full[0]*255)\n",
        "\n",
        "# Computing scores (DICE and IOU)\n",
        "print('Scores for the segmented output ===========>')\n",
        "scr_met = {'IOU':[],'DICE':[]}\n",
        "\n",
        "for _,i in enumerate(ids_test):\n",
        "\n",
        "    gt = gt_path+os.path.splitext(i)[0]+'.png'\n",
        "    plabel = os.path.join(sv_path,os.path.splitext(i)[0]+'.png')\n",
        "\n",
        "    true   = cv2.imread(gt,0)\n",
        "    _, true = cv2.threshold(true, 128, 255, cv2.THRESH_BINARY)\n",
        "    true = true.astype(bool)\n",
        "    pred_1 = cv2.imread(plabel,0).astype(bool)\n",
        "\n",
        "    dice_coeff = dice_metric(true,pred_1)\n",
        "    jacc_f = iou_metric(true,pred_1)\n",
        "\n",
        "    scr_met['IOU'].append(jacc_f.item())\n",
        "    scr_met['DICE'].append(dice_coeff.item())\n",
        "    print('ID-{}  IOU: {:.3}, DICE: {:.3}'.format(os.path.splitext(id_)[0],jacc_f.item(),dice_coeff.item()))\n",
        "\n",
        "\n",
        "print(\"mean of jaccard: \",mean(scr_met['IOU']))\n",
        "print(\"mean of dice: \",mean(scr_met['DICE']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q7ARM0RHUBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c77478-6f08-4bb2-d936-ce46778275be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/NucleiSegNet/overlay_mask.py\", line 16, in <module>\n",
            "    test_path_ids1 = next(os.walk(Test_image_path))[2]\n",
            "StopIteration\n"
          ]
        }
      ],
      "source": [
        "!python overlay_mask.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HSrc-OJ_X3H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}